\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage[UKenglish]{babel}
\usepackage[UKenglish]{isodate}
\usepackage{tikz}
\usepackage{listings}
\usepackage{complexity}
\usepackage{mathtools}
\usepackage{booktabs}

\beamertemplatenavigationsymbolsempty
\usetheme{Rochester}
\usecolortheme{orchid}

\usetikzlibrary{arrows}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes}

\newboolean{future}
\setboolean{future}{true}

\author{Paulius Dilkas}
\title{Probabilistic Inference via Weighted Model Counting}
\subtitle{Algorithms, Encodings, and Random Instances}
\date{15th June 2021}

\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}

\begin{document}

\maketitle

\begin{frame}[fragile]{The Problem of Computing Probability}
  \vspace{-0.75cm}
  \begin{columns}[t]
    \begin{column}{0.65\textwidth}
      \centering
      \begin{block}{ProbLog}
        \vspace{-0.2cm}
        \begin{lstlisting}[basicstyle=\tiny]
0.001 :: burglary.
0.002 :: earthquake.
0.95  :: alarm     :- burglary, earthquake.
0.94  :: alarm     :- burglary, \+ earthquake.
0.29  :: alarm     :- \+ burglary, earthquake.
0.001 :: alarm     :- \+ burglary, \+ earthquake.
0.9   :: johnCalls :- alarm.
0.05  :: johnCalls :- \+ alarm.
0.7   :: maryCalls :- alarm.
0.01  :: maryCalls :- \+ alarm.
        \end{lstlisting}
        \vspace{-0.2cm}
      \end{block}
      \vspace{-0.25cm}
      \begin{block}{BLOG}
        \vspace{-0.2cm}
        \begin{lstlisting}[escapeinside={(*}{*)},basicstyle=\tiny]
random Boolean Burglary (*$\sim$*) BooleanDistrib(0.001);
random Boolean Earthquake (*$\sim$*) BooleanDistrib(0.002);
random Boolean Alarm (*$\sim$*)
  if Burglary then
    if Earthquake then BooleanDistrib(0.95)
    else BooleanDistrib(0.94)
  else
    if Earthquake then BooleanDistrib(0.29)
    else BooleanDistrib(0.001);
random Boolean JohnCalls (*$\sim$*)
  if Alarm then BooleanDistrib(0.9)
  else BooleanDistrib(0.05);
random Boolean MaryCalls (*$\sim$*)
  if Alarm then BooleanDistrib(0.7)
  else BooleanDistrib(0.01);
        \end{lstlisting}
        \vspace{-0.2cm}
      \end{block}
    \end{column}
    \begin{column}{0.35\textwidth}
      \begin{block}{Bayesian Network}
        \centering
        \begin{tikzpicture}[node distance=2cm,scale=0.5,every node/.style={scale=0.5}]
          \node[draw,ellipse] (alarm) {Alarm};
          \node[draw,ellipse,above left of=alarm] (burglary) {Burglary};
          \node[draw,ellipse,above right of=alarm] (earthquake) {Earthquake};
          \node[draw,ellipse,below left of=alarm] (johnCalls) {JohnCalls};
          \node[draw,ellipse,below right of=alarm] (maryCalls) {MaryCalls};
          \draw[-Latex] (burglary) -- (alarm);
          \draw[-Latex] (earthquake) -- (alarm);
          \draw[-Latex] (alarm) -- (johnCalls);
          \draw[-Latex] (alarm) -- (maryCalls);
        \end{tikzpicture}
      \end{block}
      \vspace{1cm}
      \begin{block}{Markov Random Field}
        \centering
        \begin{tikzpicture}[node distance=2cm,scale=0.5,every node/.style={scale=0.5}]
          \node[draw,ellipse] (alarm) {Alarm};
          \node[draw,ellipse,above left of=alarm] (burglary) {Burglary};
          \node[draw,ellipse,above right of=alarm] (earthquake) {Earthquake};
          \node[draw,ellipse,below left of=alarm] (johnCalls) {JohnCalls};
          \node[draw,ellipse,below right of=alarm] (maryCalls) {MaryCalls};
          \draw (burglary) -- (earthquake);
          \draw (burglary) -- (alarm);
          \draw (earthquake) -- (alarm);
          \draw (alarm) -- (johnCalls);
          \draw (alarm) -- (maryCalls);
        \end{tikzpicture}
      \end{block}
    \end{column}
  \end{columns}
  \onslide<2>{
    \begin{tikzpicture}[remember picture,overlay]
      \node[draw,star,fill=red!10] (wmc) at (current page.center) {WMC};
      \coordinate[xshift=-0.25\linewidth,yshift=-0.25\textheight] (p1) at (current page.center);
      \coordinate[xshift=0.25\linewidth,yshift=-0.25\textheight] (p2) at (current page.center);
      \coordinate[xshift=-0.25\linewidth,yshift=0.25\textheight] (p3) at (current page.center);
      \coordinate[xshift=0.25\linewidth,yshift=0.25\textheight] (p4) at (current page.center);
      \draw[-latex,line width=2pt,color=red!50] (p1) -- (wmc);
      \draw[-latex,line width=2pt,color=red!50] (p2) -- (wmc);
      \draw[-latex,line width=2pt,color=red!50] (p3) -- (wmc);
      \draw[-latex,line width=2pt,color=red!50] (p4) -- (wmc);
    \end{tikzpicture}
  }
\end{frame}

\begin{frame}[fragile]{Weighted Model Counting (WMC)}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \begin{itemize}
      \item Generalises propositional model counting ($\#\SAT{}$)
      \item Applications:
        \begin{itemize}
        \item graphical models
        \item probabilistic programming
        \item neural-symbolic artificial intelligence
        \end{itemize}
      \item Main types of algorithms:
        \begin{itemize}
        \item using knowledge compilation
        \item using a \SAT{} solver
        \item manipulating pseudo-Boolean functions
        \end{itemize}
      \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
      \begin{example}
      $w(x) = 0.3$, $w(\neg x) = 0.7$, $w(y) = 0.2$, $w(\neg y) = 0.8$
      \vspace{1cm}

      $\mathsf{WMC}(\alert{x \lor y}) = w(x)w(y) + w(x)w(\neg y) + w(\neg x)w(y)
      = 0.44$
      \end{example}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Outline}
  \tableofcontents
\end{frame}

\section{The UAI Paper: Weighted Model Counting with Conditional Weights for Bayesian Networks}

\begin{frame}{An Alternative Way to Think About WMC}
  \begin{itemize}
  \item Let \structure{$V$} be the set of variables.
  \item Then \structure{$2^{2^V}$} is the Boolean algebra of propositional
    formulas.
  \end{itemize}
  \begin{definition}
    A \alert{measure} is a function \structure{$\mu\colon 2^{2^V} \to
      \mathbb{R}_{\ge 0}$} such that:
    \begin{itemize}
    \item \structure{$\mu(\bot) = 0$};
    \item \structure{$\mu(x \lor y) = \mu(x) + \mu(y)$} whenever \structure{$x
        \land y = \bot$}.
    \end{itemize}
  \end{definition}
  \begin{block}{Observation}
    WMC corresponds to the process of calculating the value of
    \structure{$\mu(x)$} for some \structure{$x \in 2^{2^V}$}.
  \end{block}
\end{frame}

\begin{frame}{The Limitations and Capabilities of WMC}
  \begin{alertblock}{Observation}
    Classical WMC is only able to evaluate \structure{factorable} measures
    (c.f., a collection of mutually independent random variables).
  \end{alertblock}
  \begin{theorem}[Informal Version]
    It is always possible to add more variables to turn a non-factorable measure
    into a factorable measure.
  \end{theorem}
  However, that is not necessarily a good idea!
\end{frame}

\begin{frame}{Experimental Results}
  \centering
  \input{../../../published/wmc-without-parameters/doc/long_talk/cumulative2}
\end{frame}

\section{The SAT Paper: Weighted Model Counting Without Parameter Variables}

\begin{frame}{Formalising the Intuition from Before}
  For any propositional formula \structure{$\phi$} over a set of variables
  \structure{$X$} and \structure{$p, q \in \mathbb{R}$}, let
  \structure{$[\phi]^p_q\colon 2^X \to \mathbb{R}$} be the pseudo-Boolean
  function defined as
  \[
    [\phi]^p_q(Y) \coloneqq
    \begin{cases}
      p & \text{if } Y \models \phi \\
      q & \text{otherwise}
    \end{cases}
  \]
  for any \structure{$Y \subseteq X$}.

  \begin{definition}[Pseudo-Boolean Projection (PBP)]
    A \alert{PBP instance} is a tuple \structure{$(F, X, \omega)$}, where
    \structure{$X$} is the set of variables, \structure{$F$} is a set of
    two-valued pseudo-Boolean functions \structure{$2^X \to \mathbb{R}$}, and
    \structure{$\omega \in \mathbb{R}$} is the scaling factor.
  \end{definition}
\end{frame}

\begin{frame}{From WMC to PBP}
  The WMC instance has \structure{$x$} as the only \alert{indicator} variable
  and \structure{$p$}, \structure{$q$} as \alert{parameter} variables with
  weights \structure{$w(p) = 0.2$}, \structure{$w(q) = 0.8$}, and
  \structure{$w(\neg p) = w(\neg q) = 1$}.
  \begin{center}
    \begin{tabular}{llll}
      \toprule
      WMC Clause & \onslide<2->{In CNF} & \onslide<3->{Pseudo-Boolean Function} & \\
      \midrule
      $\neg x \Rightarrow p$ & \onslide<2->{$x \lor p$} & \onslide<3->{$[\neg x]_1^{0.2}$} & \\
      $p \Rightarrow \neg x$ & \onslide<2->{$\neg x \lor \neg p$} & & \onslide<4->{$[x]^{0.8}_{0.2}$} \\
      $x \Rightarrow q$ & \onslide<2->{$\neg x \lor q$} & \onslide<3->{$[x]_1^{0.8}$} & \\
      $q \Rightarrow x$ & \onslide<2->{$x \lor \neg q$} & & \\
      $\neg x$ & \onslide<2->{$\neg x$} & \onslide<3->{$[\neg x]_0^1$} & \onslide<4->{$[\neg x]_0^1$} \\
      \bottomrule
    \end{tabular}
  \end{center}
\end{frame}

\begin{frame}{Experimental Results}
  \input{../../../published/wmc-without-parameters/doc/SAT_talk/cumulative}
\end{frame}

\section{The Next Paper: Parameterized Complexity of Weighted Model Counting in
  Theory and Practice}

\begin{frame}{Plan for the Next Paper}
  \begin{block}{Parameterized Complexity}
    \begin{description}
    \item[Cachet:] \alert{$2^{\mathcal{O}(w_b)}n^{\mathcal{O}(1)}$}
      (\structure{$n$} is the number of variables, and \structure{$w_b$} is the
      branch width).
    \item[c2d:] \alert{$\mathcal{O}(mw2^w)$} (\structure{$m$} is the number
      of clauses, and \structure{$w$} is the primal treewidth).
    \item[DPMC:] \alert{$\mathcal{O}(4^knm)$} (my result, and the
      \structure{$4^k$} part is tight).
    \end{description}
  \end{block}
  \begin{block}{Empirical Study on Random Instances}
  \begin{itemize}
  \item New random model for 3-CNF formulas (done)
  \item Running experiments (almost done)
  \item Plots and writing (some disorganised notes)
  \end{itemize}
  \end{block}
\end{frame}

\section{Future Plans More Generally}

\begin{frame}{Future Plans}
  \begin{itemize}
  \item TODO: how everything (i.e., all the papers) fit together
  \item TODO: finish writing this slide later
  \end{itemize}
\end{frame}

\end{document}