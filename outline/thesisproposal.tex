\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[UKenglish]{babel}
\usepackage[UKenglish]{isodate}
\usepackage{fullpage}
\usepackage{complexity}
\usepackage{amsmath}
\usepackage{cleveref}

\begin{document}
\title{Explainability in Autonomous Agents: Interpretable Models, Abstraction,
  and Beyond}
\author{Paulius Dilkas}
\maketitle

% 15 pages
% problem, methods, justification, evaluation, scheduled work plan
\section{Introduction}

As black-box machine learning algorithms become more powerful, an important
issue emerges: how much are we willing to trust a man-made tool without knowing
how it works, and why it suggest the answer that it does? Thus, the topics of
explainability and interpretability gather importance. Perhaps information is
more interpretable when expressed in a richer language or representation.
Perhaps possible interpretations become obvious after eliminating unnecessary
detail. These ideas form the foundation of the work presented in this proposal.

We begin by considering abstraction in a relatively general setting: we
review what has been accomplished so far and the broad strokes of the work
envisioned in this proposal. \Crefrange{sec:1}{sec:3} then outline three
specific projects that are under way. \Cref{sec:methodology} then divides the
work into executable work packages, and we use \Crefrange{sec:7}{sec:9} to
briefly consider outcomes, risks, and impact.

\section{Abstraction in First-Order Probabilistic Inference}

\emph{Abstraction} can be broadly defined as the process (and result) of
omitting detail \cite{doi:10.1086/670300}. Sometimes the omitted information is
irrelevant in answering the questions we are interested in, and sometimes an
abstraction provides a simplified (and approximately correct) view of a
situation that originally was too complex to be reasoned about. While areas such
as planning and verification have benefited from abstraction in various ways
\cite{saitta2013abstraction}, research into abstraction in FOPI has just begun
and awaits significant contributions
\cite{DBLP:journals/corr/abs-1810-02434,DBLP:conf/icml/HoltzenBM18,DBLP:conf/uai/HoltzenMB17}.

Our goal is to develop new types of abstractions, find efficient
algorithms for constructing an abstraction from a given model, and investigate
how abstraction can be integrated into both inference and learning algorithms.
Simplification and abstraction can benefit us in both efficiency and
interpretability, i.e, simpler models are likely to result in faster inference,
while at the same time being easier to understand by the user. Finally, the
quest for abstraction algorithms is likely to lead to a better theoretical
understanding of what properties can be preserved by an abstraction, what error
bounds can be established when abstraction approximates the answer, and upper
and lower bounds on the complexity of performing abstraction and providing the
desired guarantees.

\paragraph{Objectives.}
\begin{itemize}
\item To further the theoretical understanding of abstraction in FOPI.
\item To improve inference speed by investigating abstraction as a separate
  process as well as a component of inference.
\item To make models learned from data simpler and more transferable.
\item To increase the interpretability of FOPI models.
\end{itemize}

\subsection{Literature Review}

Logical approaches to reasoning have dominated the fields of AI and computing
for many decades. They have resulted in expert systems that can use reasoning to
make predictions and diagnose problems \cite{hayes1983building}, logic
programming languages that allow the user to declaratively describe the problem
and trust the inference algorithm to find the answer efficiently
\cite{DBLP:books/sp/Lloyd87}, and automated (interactive) theorem proving and
proof checking software that assists mathematicians in constructing correct
proofs \cite{DBLP:books/el/RobinsonV01}. Probabilistic methods, on the other
hand, have particularly flourished with the arrival of big data and access to
more data in general, transforming areas such as natural language processing and
pattern recognition \cite{DBLP:series/sci/BrazAR08}.

While probabilistic models are great at handling uncertainty, their
simplistic representations can be hard to interpret. On the other hand, systems
based on logic have rich representations, but cannot handle uncertainty.
\emph{First-order probabilistic inference} (FOPI) (also known as
\emph{statistical relational AI}) attempts to bridge the gap
between the two and suggests a range of representations\footnote{ We will
  sometimes refer to FOPI models as \emph{probabilistic relational models},
  since relations play an important part in this richer representational
  structure.} capable of handling probabilities as well as (parts of)
first-order logic \cite{DBLP:series/sci/BrazAR08}. The models can be constructed
manually or learned from data, and the process of computing the probability of a
query---usually in the form of a random variable, possibly conditioned on other
random variables---is called \emph{inference}.

Most of these models are based either on adding probabilities to programming
languages or on adding richer representational structure to probabilistic
graphical models (PGMs). The former kind is called \emph{probabilistic
  programming} \cite{DBLP:conf/icse/GordonHNR14} and is an active area of
research with many implementations. A well-known example is \emph{ProbLog}
\cite{DBLP:conf/ijcai/RaedtKT07}---a language that extends the logic programming
language Prolog by attaching a probability to every clause in the program. A
prominent example of the latter is a \emph{Markov logic network} (MLN)
\cite{DBLP:journals/ml/RichardsonD06}, which is simply a collection of
first-order statements (formulas), with a weight attached to each statement.
MLNs were proposed as a first-order generalisation of \emph{Markov random
  fields}---an undirected PGM. We will use MLNs to provide concrete examples,
but we do not commit ourselves to a specific FOPI model just yet.

As an area of research, FOPI is a subfield of AI and can be thought as the
probabilistic cousin of automated reasoning. The problem of learning a FOPI
model from data draws the attention of researchers not only from the machine
learning community, but also data mining and knowledge discovery. Due to how
many of the models are formulated, there is also significant overlap with
research in programming languages and, specifically, logic programming.

In the last decade, we have seen applications of FOPI in a wide range of areas,
ranging from toy problems in probability one might find in a textbook
\cite{DBLP:conf/ijcai/DriesKDBR17} all the way to genetics
\cite{DBLP:journals/jcb/SakhanenkoG12} and cancer research
\cite{DBLP:conf/ilp/Corte-RealD017}. For instance, probabilistic relational
structures have been integrated into recommendation systems
\cite{DBLP:journals/corr/YangKAGN16} and stream mining software
\cite{DBLP:conf/icdm/ChandraSKTA14}, and various FOPI models have been used to
predict the remaining lifetime of hardware components
\cite{vlasselaer2012statistical} as well as patterns of criminal and terrorist
activity \cite{DBLP:conf/sdm/DelaneyFCWJ10}. Moreover, one type of probabilistic
logic has been extended to explicitly deal with changes over time and has been
used to model virtual spaces such as online chat rooms and massively multiplayer
online games \cite{DBLP:conf/pkdd/ThonLR08,DBLP:journals/ml/ThonLR11}.

\subsubsection{State of the Art: Inference}

Recall that a ProbLog program is a set of clauses, where each clause has an
associated probability. The ProbLog inference rule
\cite{DBLP:series/synthesis/2016Raedt,DBLP:conf/iclp/Sato95} for calculating the
probability of an arbitrary query $Q$ being true is
\[
  P(Q) = \sum_{F \models Q} \prod_{f \in F} P(f) \prod_{f \not\in F} 1 -
  P(f).
\]
Here, we are summing over all instantiations of variables (called \emph{possible
worlds}) that satisfy the query, where $F$ denotes a set of clauses that are
evaluated as true. For each world, we calculate its probability by multiplying
probabilities associated with clauses or their negations. With this
definition, the inference problem becomes an instance of weighted model
counting \cite{DBLP:series/synthesis/2016Raedt}.

\emph{Weighted model counting} (WMC) is an extension of model counting, which is
an extension of the \emph{Boolean satisfiability problem} (SAT)
\cite{DBLP:journals/ai/ChaviraD08}. SAT asks whether one can assign values to
variables so that a given formula evaluates to true. Model counting asks to
count the number of ways that can be done. Weighted model counting further
extends this problem by assigning a weight to each possible world (in whatever
way is appropriate for the problem) and asks for the sum of the weights
corresponding to all possible worlds where the formula (or query) is true. In
the case of ProbLog, the weight of a world is the product of probabilities of
all literals (whether evaluated/instantiated to true or false)
\cite{DBLP:series/synthesis/2016Raedt}. The WMC instance is then compiled to
some type of logical circuit for efficient inference. \emph{Knowledge
  compilation} \cite{DBLP:conf/ijcai/BroeckTMDR11} is the state-of-the-art
inference technique for PGMs as well as many FOPI models
\cite{DBLP:series/synthesis/2016Raedt}.

Inference for MLNs works in a similar way. We still sum over all possible
worlds where the query is true, but the probability of a world $x$ is now
defined as
\[
  P(x) = \frac{1}{Z} \exp \left( \sum_{i=1}^F w_i n_i(x) \right),
\]
where $Z$ is the normalising constant more commonly known as the \emph{partition
function}, $F$ is the number of formulas in the MLN, $w_i$ is the weight of the
$i$th formula, and $n_i(x)$ is the number of ways that formula $i$ can be
grounded in order to satisfy world $x$. Here, \emph{grounding} a formula refers
to replacing each variable with a value so that the formula evaluates to true.

A commonly used inference algorithm for MLNs relies on \emph{probabilistic
  theorem proving}
\cite{DBLP:journals/cacm/GogateD16,DBLP:journals/cib/Venugopal17}
which is an example of a \emph{lifted inference} algorithm, i.e., an algorithm
that attempts to work directly with variables without having to consider every
possible value \cite{DBLP:conf/ijcai/Poole03}. The underlying problem, however,
is still WMC, and is solved using a combination of techniques well established
in the SAT community, e.g., unit propagation and clause learning
\cite{DBLP:journals/cib/Venugopal17}.

\subsubsection{State of the Art: Abstraction}

Abstraction is an important tool in human cognition and a well-studied subject
in cognitive science. For example, Gentner and Hoyos \cite{Gentner2017-GENAAA-2}
investigate how children learn abstract patterns from observing several
objects with a common property, while Bransford and Franks
\cite{BRANSFORD1971331} show how the idea conveyed by a sentence is abstracted
away from the particulars of its syntactic expression.

Abstraction is also well-known in the AI community,
where the main goal of abstraction is to reduce the computational complexity of
a task, while ensuring that the process of abstraction itself is reasonably
efficient \cite{saitta2013abstraction}. For instance, abstraction plays a key
part in modern approaches to planning, where compound tasks are used to abstract
away the details of how those tasks can be implemented
\cite{DBLP:journals/amai/ErolHN96}. More specifically, abstraction is essential
in developing explainable AI \cite{DBLP:journals/access/AdadiB18}, where
it has been used to create interpretable abstractions of observed behaviour
\cite{DBLP:journals/corr/PenkovR17} and model the domain knowledge of the user
as an abstraction of the system, thus producing explanations that are at the
level of detail corresponding to the user's knowledge
\cite{DBLP:conf/ijcai/SreedharanSK18}.

Model checking and verification benefit from abstraction as well, particularly
in the area of software verification, where a complete model of the program
might be too big to be handled by even the most efficient methods, in which
case an abstract model could be developed. Depending on how it is created,
sometimes properties of the system can be verified using the abstraction
\cite{DBLP:journals/toplas/ClarkeGL94}, while other times the abstract model
might produce a false positive, i.e., signal about a possible problem where
there is none. If the occurrence of a false positive is suspected, parts of the
abstraction can be refined to provide the necessary level of detail, while
keeping other parts as they were
\cite{DBLP:conf/cav/ClarkeGJLV00,DBLP:conf/popl/HenzingerJMS02}.

Probabilistic abstractions have been used in the context of software
verification, where probabilities can help the verification algorithm choose
which part of the abstract model needs to be refined
\cite{DBLP:conf/pldi/ZhangSN17}. Meanwhile, in the probabilistic programming
community, abstractions have been used to determine the required number of Monte
Carlo samples in order to compute a probability within a required level of
precision \cite{DBLP:conf/popl/Monniaux01}.

However, only recently has the general case of abstraction for FOPI models been
formalised, and the work is mostly limited to defining several key properties
that an abstraction may have and showing how those properties interact with each
other \cite{DBLP:journals/corr/abs-1810-02434}. While the work on probabilistic
programming considers specific examples of abstractions
\cite{DBLP:conf/uai/HoltzenMB17} and presents an algorithm for performing
predicate abstraction \cite{DBLP:conf/icml/HoltzenBM18}, significant work is
required to achieve the full generality outlined in this proposal.

\subsection{Our Solution} \label{section:our_solution}

While some theoretical groundwork for abstraction in FOPI has recently been
developed by Belle \cite{DBLP:journals/corr/abs-1810-02434}, there are many
questions left to be answered:
\begin{enumerate}
\item How to efficiently create an abstraction of an already-existing
  model? \label{q:1}
\item When is the correct time to stop? What is the right balance between
  simplicity and information? \label{q:2}
\item What makes one abstraction preferable to another? \label{q:3}
\item How to incorporate abstraction steps into learning a model from
  data? \label{q:4}
\item How to provide guarantees about an abstraction? For example, we may want
  to bound the error of an answer to any query, or to ensure that all answers
  remain exact for a selected set of queries. \label{q:5}
\end{enumerate}

In order to answer these questions and develop the required algorithms and
techniques, we can draw inspiration from the theory of abstraction for reasoning
in formal systems developed by Giunchiglia and Walsh
\cite{DBLP:journals/ai/GiunchigliaW92} and recent work on abstraction for
structural equation models \cite{DBLP:conf/uai/RubensteinWBMJG17}. In
particular, an abstraction is often defined as a transformation of the
representation into a different form. One way to create such a transformation is
via a composition of atomic operations. For example:
\begin{itemize}
\item In some cases, $a \rightarrow b$ and $b \rightarrow c$ can be simplified
  to $a \rightarrow c$.
\item If a statement $S$ is true with high probability, perhaps that probability
  can be rounded up to $1$, eliminating the need to consider the case where $S$
  is false.
\item If a statement is true for all values of a variable, barring a few
  exceptions, perhaps the exceptions can be discarded.
\end{itemize}

Consider a specific query $Q$. Applying such an abstraction rule may or may not
change the answer to $Q$, depending on whether the removed information
is relevant to the query. Even if the answer becomes less precise, it might be
an acceptable approximation, given that the error is bounded to a reasonable
degree. Either way, the abstraction can reduce the search space the inference
algorithm has to explore in order to produce an answer.

It becomes clear that it is important to consider creating abstractions with
respect to a specific set of queries. Question \ref{q:5} can then be answered by
considering how each abstraction rule affects different types of queries.
Sometimes we may get a reasonable numerical upper bound on the error, while
other times it may be too time-consuming (or impossible) to bound the error to
any reasonable degree, forcing us to reject the abstraction rule altogether.

Thus, we will develop a comprehensive list of abstraction rules
(transformations) and define a way to categorise all queries answerable by a
FOPI model such that we could answer the following set of questions for each
abstraction rule:
\begin{itemize}
\item What types of queries can no longer be answered exactly after applying the
  abstraction rule?
\item What is the error bound? Can it be calculated in constant time?
\item What is the complexity of applying the abstraction?
\end{itemize}

Questions \ref{q:2} and \ref{q:3} delve deeper into how an abstraction algorithm
could work. If the set of rules is extensive enough, any model might
eventually be oversimplified into something trivial. We need to measure two
things: the amount of (relevant) information preserved by an abstraction, and
the complexity of the model. The two metrics would provide a systematic way to
answer both questions, while being easily adaptable to different needs (e.g.,
how much precision are we willing to sacrifice? What queries do we want to
support?).

Lastly, we will integrate abstraction steps into both inference and learning
algorithms, resulting in faster inference as well as simpler and more robust
models.

\subsubsection{Innovative Aspects}

We aim to innovate by expanding the idea of abstraction in AI to new domains as
well as enhancing both inference and learning of probabilistic relational
models.

\paragraph{Abstraction in AI.} The work on abstraction so far has focused almost
exclusively on deterministic systems. We will extend previous work to target
rich probabilistic models, resulting in new theoretical ideas and definitions as
well as algorithms for transforming models into their abstractions.

\paragraph{FOPI.} As FOPI subsumes both probabilistic inference (often
$\#\P$-complete) and logical inference (\NP-complete)
\cite{DBLP:journals/ml/RichardsonD06}, it is unlikely that a useful variation of
FOPI can ever be tractable. Thus, improvements in inference speed are highly
desirable. We will integrate abstraction steps into inference algorithms,
making the algorithm recognise opportunities to reduce the complexity of the
model before continuing the search. This is likely to yield significant benefits
to inference speed.

\paragraph{Statistical relational learning.} Abstraction can also be integrated
into learning a FOPI model from data. This is likely to make the model more
understandable to the user as well as increase the transferability of the model
to previously unseen data.

\section{Equivalence of Constants in Logic Programs} \label{sec:1}

The overarching goal of this project is to formalise how logic programs act on
constants and, in particular, to define what it means for constants to be
equivalent. The main contributions are as follows:
\begin{itemize}
\item We show that a relational knowledge base is fundamentally defined by its
  induced equivalence relation over tuples of constants by establishing an
  isomorphism between logic programs that translate knowledge bases and
  refinement relations over equivalence classes.
\item We characterise acyclic logic programs as morphisms in a category where
  relational knowledge bases act as objects. We show how this new category
  relates to the category of partitions of a set.
\item We formalise the semantics of an arbitrary formula as a composition of
  functions between sets, where each atom is interpreted as a composition of two
  functions: a new type of function based on the idea of \emph{arrangements with
    repetition} in combinatorics, and the predicate itself.
\end{itemize}

\subsection{Related Work}

While equivalence between logic programs has received a fair amount of attention
\cite{DBLP:journals/tocl/LifschitzPV01,DBLP:conf/ecai/OikarinenJ06,DBLP:conf/iclp/EiterF03},
the idea to formally consider equivalence of constants seems to be new. However,
informal observations that it is useful to identify sets of constants with which
the program's behaviour is identical can be seen in recent literature on domain
abstractions \cite{DBLP:conf/uai/HoltzenMB17}.

There have been other categorical approaches to logic programming where logic
programs are characterised as indexed categories
\cite{DBLP:conf/elp/KinoshitaP96}, indexed monoidal categories
\cite{corradini1992categorical}, and $\tau$-categories
\cite{DBLP:conf/csl/FinkelsteinFL94}. We provide a fresh perspective by thinking
of logic programs as transformations between Herbrand universes, and so programs
become morphisms rather than categories.

Rajan and Muhammed \cite{rajan2015normal} define the category of partitions of a
set where objects are defined as all partitions of a set (except the identity
partition that partitions the set into one cell), and there is an arrow from
object $A$ to object $B$ if, for every cell $a$ of partition $A$, one can find a
cell $b$ of partition $B$ such that $a \subseteq b$. As equivalences are
`equivalent' to partitions by the fundamental theorem of equivalence relations
\cite{dummit2004abstract}, it is likely that one can establish a formal
connection between the category of partitions and the category of knowledge
bases and logic programs.

\section{Using Constraint Programming to Generate Random Logic Programs} \label{sec:2}

We present a novel approach to generate random logic programs using constraint
programming. The constraint programming approach to the problem has a major
advantage in that one can easily add additional conditions for the generated
programs. Some of these conditions can be expressed using constraints native to
the constraint solver Choco \cite{choco}, while novel propagation and entailment
checking algorithms have been developed for ensuring independence and/or
conditional independence amongst predicates. A constraint programming approach
also benefits from many years of research into efficient constraint propagation
algorithms which makes it likely that our model can generate larger programs
relatively quickly.

The main disadvantage of this approach is that we have no control over what
probability distribution is being sampled. However, we can avoid generating
programs that are very similar to each other by regularly restarting the solver,
which makes it forget decisions that have already been made and guess/infer new
ones. Preliminary experiments show that restarting after every solution might be
time-consuming, but regular restarts are still feasible.

While the model generates logic programs, it can be easily extended to generate
probabilistic logic programs by adding probabilities to clauses and an
additional constraint for avoiding negative cycles in the program.

\subsection{Related Work}

\paragraph{Previous approaches.} Logic programs have been generated before. Some
approaches are quite restrictive, e.g., restricted to clauses with only two
literals \cite{DBLP:conf/lpnmr/NamasivayamT09}, or to clauses of the form $a
\gets \neg b$ \cite{DBLP:journals/tocl/WenWSL16}, but others are more
expressive \cite{DBLP:journals/tplp/WangWM15}, e.g., defining a program only by
the (maximum) number of atoms in the body and the total number of rules
\cite{DBLP:conf/iclp/ZhaoL03,zhao2004answer}. Our advantages over previous work
are twofold: our model can generate different syntactic representations of the
same underlying probability distribution (which can be a blessing or a curse
depending on the needs of the user), and our model allows us to integrate
additional constraints on the program in an efficient (i.e., non-brute-force)
manner.

\paragraph{Inference algorithms and their evaluation.} How confidently can we
claim that an algorithm works well if it is only tested on a couple types of
problems? Perhaps the `inferior' algorithm is actually better in some specific
circumstances. Perhaps there are clearly identifiable types of programs that
make every algorithm default to exponential behaviour that could be easily
overcome with the right strategy. At present, most inference algorithms for
probabilistic (logic) programs are only evaluated on 1--4 different problems:
sometimes just a single network
\cite{DBLP:journals/tplp/KimmigDRCR11,DBLP:journals/corr/abs-1112-3785,DBLP:conf/iclp/KimmigCRDR08},
sometimes two
\cite{DBLP:journals/corr/abs-1009-3798,DBLP:conf/ecai/BruynoogheMKGVJR10} or
even four networks \cite{DBLP:conf/ijcai/VlasselaerBKMR15} coming from a range
of areas such as social networks and citation/genetic/biological data sets. In
order to better understand the strengths and weaknesses of these algorithms,
along with real data they should also be evaluated on a range of synthetic
problems that accurately represent the potential complexities that have to be
handled by a well-designed solver.

\paragraph{Complexity and empirical hardness.} Research in computer science has
a long history of both theoretical and empirical approaches towards
characterising the difficulty of a problem irrespectively of its solutions. In
both cases, many attempts have been made to discover parameters that can be used
to predict or ensure the difficulty of the problem. On the theory side, this has
resulted in an entire subfield of complexity theory called parameterised
complexity \cite{DBLP:series/mcs/DowneyF99} and well-known parameters such as
clique-width \cite{DBLP:journals/jcss/CourcelleER93,DBLP:journals/dam/Wanke94}
and treewidth \cite{diestel2005graph}. On the empirical side, parameters were
used to identify phase transitions---peaks in the empirical hardness of decision
problems between problems that are so `easy' that the answer is obviously `yes'
and problems that are so `easy' that the answer is obviously `no'
\cite{DBLP:conf/ijcai/CheesemanKT91}. This approach has been successfully
applied on a wide range of problems, ranging from the travelling salesman
\cite{DBLP:journals/ai/GentW96} to voting systems
\cite{DBLP:conf/ijcai/Walsh09}. More recently, empirical approaches to hardness
estimation have used machine learning techniques to unveil a more detailed
picture of the hardness landscape \cite{DBLP:journals/cacm/Leyton-BrownHHX14}
and tackled optimisation problems by running billions of experiments to
eliminate noise and randomness \cite{DBLP:conf/cp/McCreeshPP19}. Being able to
generate benchmarking instances for a problem is the crucial first step towards
a better understanding of empirical hardness and will allow us to characterise
which (probabilistic) logic programs are easy, and which ones are hard.

\paragraph{Data generation.} As probabilistic logic programs have been used to
generate random data \cite{DBLP:conf/soict/Dries15}, one could combine random
data generation with random program generation to generate random relational
data that is generalisable across generative models and only satisfies some
basic independence conditions. The results could unveil important biases in how
the programs are generated as well as biases inherent in encoding a probability
distribution as a probabilistic logic program.

\paragraph{Learning.} Learning the structure of a probabilistic logic program
from data remains a challenging problem. While some approaches only consider
ground programs \cite{riguzzi2007learning,DBLP:journals/ml/Riguzzi08}, and some
consider the problem of identifying a near-optimal subset of clauses from an
existing program \cite{DBLP:conf/ilp/RaedtKKRT06}, there have been no successful
attempts to tackle the problem in its full generality. Generating suitable
structures and testing them against the data would serve as a baseline algorithm
for structure learning.

\section{Predicate Invention for Probabilistic Logic Programs} \label{sec:3}

Different syntactic representations of the same program can certainly differ in
interpretability. This is especially important when the program is learned from
data. Can they differ in inference speed? How much can a program be transformed
without changing any of its answers to a set of relevant questions?

This project is most closely related to the initial topic of the proposal and
examines one particular type of transformation, namely creating a new predicate
that can replace a formula. We propose a number of transformations (depending on
the underlying formula), prove their correctness, and examine their empirical
implications and composability.

\subsection{Related Work}

This project is related to predicate invention as it is known in the context of
inductive logic programming and meta-interpretive learning
\cite{DBLP:conf/ruleml/Muggleton17,DBLP:journals/ml/MuggletonLT15}, but there
are several key differences. First, predicate invention is typically considered
in the context of learning a first-order representation from data
\cite{kramer1995predicate,DBLP:journals/jetai/Muggleton94}, while my work
invents new predicates in order to transform an already existing program.
Second, situating the work in probabilistic logic means that my arguments for
the correctness of the transformations are expressed primarily in a
probabilistic rather than logical setting.

Besold et al. \cite{DBLP:conf/ilp/SchmidZBTM16} identify an issue with predicate
invention: the newly invented predicate is often left without an interpretable
name. In our setting, however, this is less of a problem because the new
predicate can be named after its underlying structure (as long as it is not too
complicated), e.g., the new predicate meant to replace $\mathsf{father}(X, Y)
\lor \mathsf{mother}(X, Y)$, for lack of a better automatically-identifiable
alternative, could be called $\mathsf{fatherORmother}(X, Y)$.

The idea to use predicate invention for interpretability is similar to the idea
of splitting a logic program into a `top' part and a `bottom' part
\cite{DBLP:conf/iclp/LifschitzT94,DBLP:conf/aaai/JiWHY15}. In
both cases, the goal is to identify a high-level structure that is mostly
independent from the low-level details, as observed from the perspective of
either interpretability or inference.

\section{Methodology} \label{sec:methodology}

\subsection{Theory Paper: On the Equivalence of Constants in Logic Programs
  (WP1)}

While the main results of the paper have already been developed, they need to be
revised to ensure a sufficient level of mathematical rigour, good (and
well-explained) use of terminology, an inviting and understandable explanation,
and a convincing motivation for why the results are not only interesting but
also impactful and valuable. \textbf{Duration:} two months.
\textbf{Deliverables:} a paper submitted for publication.

\subsection{Using Constraint Programming to Generate Random Logic Programs
  (WP2)}

While a custom propagation algorithm for independence has already been
implemented, it needs to be extended to support an arbitrary number of
predicates. The algorithm for conditional independence, while designed, still
needs to be implemented and tested. As this would be useful for many
applications, there should also be a constraint to ensure that the model does
not generate two or more programs with different syntactic expressions that are
also clearly logically equivalent. This could be achieved by restricting the
format of each clause.

The model should be primarily evaluated on the basis of its speed as measured by
the time it takes to produce the first program and the time between subsequent
programs as a function of various parameters of the model. Having generated a
set of programs, we can then further motivate the work by running multiple
inference algorithms on a range of synthetic problems and outlining the types of
programs that cause difficulty to all algorithms and the types of programs that
are easy for some but difficult for others. \textbf{Duration:} six months.
\textbf{Deliverables:} a software product as well as a paper describing the
model, empirical results, and observations.

\subsection{Predicate Invention: Implementation and Theory (WP3)}

The predicate invention project, while under way, requires significantly more
work on both the theoretical and the empirical aspects:
\begin{itemize}
\item A number of important theorems have been defined but still need to be
  proven.
\item When looking for formulas that could be abstracted, the algorithm should
  take into account rules such as De Morgan's laws.
\item While the theory is formulated to work on any number of predicates, the
  implementation is only able to handle two predicates at a time.
\end{itemize}
\textbf{Duration:} three months. \textbf{Deliverables:} a list of theorems with
proofs and software that can execute the transformations suggested by the
theorems.

\subsection{Greedy Algorithms (WP4)}

At this point, we can reason about applying multiple abstraction rules in
sequence. We will aim to answer two key questions:
\begin{itemize}
\item How to choose which abstraction rule should be applied first?
\item When is the correct time to stop simplifying things?
\end{itemize}
Exploring different answers to these questions will result in a set of
abstraction algorithms. As we expect most abstraction rules to commute with one
another, making the order the rules are applied in immaterial, we will focus on
\emph{greedy} algorithms, where we choose which abstraction rule should be
applied on a model based solely on the current state of the model.

Each algorithm will take a model, a description of a set of queries that need to
be supported, and an indication of how much loss in precision (if any) the user
is willing to tolerate. We will explore a variety of heuristics that establish
preferences over which abstraction rule should be applied first as well as
termination conditions. For instance, we could always pick an abstraction rule
that results in a model with highest entropy (similar ideas have been very
successful in reinforcement learning \cite{DBLP:conf/aaai/ZiebartMBD08}), or
prefer rules that have little effect on precision. While a natural termination
condition could be an inability to apply an abstraction rule without losing too
much precision, the process could also be terminated because either the loss in
precision or the expected running time of applying the abstraction is too high
for the predicted benefits in inference speed. \textbf{Duration:} six months.
\textbf{Deliverables:} implementations of the algorithms as well as one or more
papers detailing the reasoning behind design decisions, observed empirical
performance, and the differences in inference speed before and after running
each algorithm.

\subsection{Abstraction During Inference (WP5)}

There is no reason to limit abstraction to the intermediate stage between
constructing (or learning) a model and performing inference. Thus, we will
investigate how the state-of-the-art inference algorithm for our chosen FOPI
model can benefit from performing abstraction steps throughout its execution.
For example, a common way to compute a conditional probability $P(Q \mid E)$
inside a model $\Delta$ using WMC is by calculating the WMC of $\Delta \land Q
\land E$ and $\Delta \land E$ separately, and then dividing one by the other
\cite{DBLP:journals/ai/ChaviraD08}. It is likely that the two computations would
benefit from different abstractions. \textbf{Duration:} six months.
\textbf{Deliverables:} an implementation of a new inference algorithm with
abstraction, and a report describing its design and performance.

\subsection{Abstraction in Learning (WP6)}

A learned model is, in a way, an abstraction of the training data. Performing
abstraction afterwards is suboptimal, since the algorithm would attempt to
stay close to the learned model rather than the underlying data itself. While
learning algorithms already measure goodness of fit, the measure will have to be
combined with a meaningful measure of simplicity in order to provide a
reasonable balance between the two. The abstraction rules themselves will need
to be rethought in the context of data, as abstraction ought not to be added at
the end as an extra step, but rather a fully integrated part of the learning
process that concerns itself primarily with a meaningful and accurate
representation of data. The abstraction ideas developed in previous work
packages will help ensure that the learned models are both more explainable and
transferable to new kinds of data. \textbf{Duration:} six months.
\textbf{Deliverables:} an implementation of a learning algorithm with integrated
abstraction, and a report describing the rationale for its design as well as
observed performance.

\section{Measurable Outcomes} \label{sec:7}

\begin{itemize}
\item A thoroughly-described landscape of probabilistic logic programs,
  identifying programs that are challenging to some or all of the inference
  algorithms. (WP2).
\item Demonstrated increase in exact and approximate inference speed (WP5).
\item Demonstrated improvement in models learned from data in terms of
  simplicity and transferability without (significant) loss in precision (WP6).
\end{itemize}

\section{Risks} \label{sec:8}

Creating a new algorithm always carries a risk that the algorithm may not
perform well compared to what has already been achieved. Fortunately, previous
work, which features a very limited version of abstraction, shows promising
results in terms of reduction in inference speed
\cite{DBLP:conf/icml/HoltzenBM18}. We are confident that we can observe
similarly successful results with a much broader range of abstractions. In any
case, the project will result in valuable theoretical contributions regardless
of how well the ideas perform in practice.

Another risk is related to integrating abstraction into inference. Namely, it
might take too much time to create the abstraction compared to the time saved
during inference. Even if this turns out to be the case, the developed
abstraction algorithms would still be useful for models that are constructed
once and used to perform many inferences. However, the observed reductions in
inference speed seem to reduce the complexity of the task
\cite{DBLP:conf/icml/HoltzenBM18}, while at least some abstraction rules can
definitely be implemented in linear time. This suggests that with a big enough
model the gains in inference speed should eventually overtake the time taken to
construct the abstraction.

\section{Impact and National Importance} \label{sec:9}

\paragraph{National Importance.} Our proposal covers an EPSRC growth area for
statistics and applied probability as well as several maintenance areas such as
AI technologies, logic and combinatorics, and theoretical computer science.
Furthermore, our work will contribute to areas such as big data (as more
scalable inference will allow expressive probabilistic models to be used with
more data) as well as other scientific disciplines (as both abstraction and
richness of representation are important topics in social sciences and
medicine). Moreover, abstraction for FOPI models is a new yet promising research
area \cite{DBLP:conf/icml/HoltzenBM18} which is likely to see many major
developments.

\paragraph{Impact.} The survey will highlight the weaknesses of current
approaches and direct future research towards open problems. Furthermore, many
of the basic ideas behind abstraction for a particular model are likely to be
transferable to many others, perhaps even inspiring a unifying theory behind all
representations. Moreover, making the models more efficient and explainable
should also make them more attractive to a larger user base, both academic and
industrial.

\bibliographystyle{acm}
\bibliography{thesisproposal}
\end{document}
