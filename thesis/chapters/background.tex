% 11-45 pages (27 on average)
% aim for 2-5 pages for each major section
\chapter{Background}

TODO: outside of specific sections, have a one-paragraph introduction before and a one-paragraph summary at the end.

\section{Propositional Logic} \label{sec:proplogic}

In this section, we briefly introduce the fundamentals of propositional logic and describe some logic-based computational problems. We refer the reader to the book by \cite{DBLP:books/daglib/0029942} for a more detailed introduction to logic and its role in computer science.

An \emph{atomic proposition} (also known as \emph{atom} and Boolean/logical variable) is a variable with two possible (truth) values: true and false. Unless specified otherwise, we will refer to atoms as \emph{variables}. A \emph{formula} is any well-formed expression that connects variables using the following Boolean/logical operators (and parentheses): negation ($\neg$), disjunction ($\lor$), conjunction ($\land$), (material) implication ($\Rightarrow$), and equivalence (i.e., material biconditional) ($\Leftrightarrow$). A \emph{literal} is either a variable or its negation, respectively called \emph{positive} and \emph{negative} literal. A \emph{clause} is a disjunction of literals.\footnote{In the context of logic programs, the word \emph{clause} is used differently (see \cref{sec:lp,chapter:randomlps}).} A formula is in \emph{conjunctive normal form} (CNF) if it is a conjunction of clauses, and it is in $k$-CNF if every clause has exactly $k$ literals. Many other normal forms and ways to represent propositional formulas are covered in \cref{sec:kc}.

An \emph{interpretation} (also known as a \emph{variable assignment}) of a formula $\phi$ is a map from the variables of $\phi$ to the set $\{\, \text{true}, \text{false} \,\}$. A \emph{model} is an interpretation under which $\phi$ evaluates to true. A formula is \emph{satisfiable} if it has at least one model.

Throughout the thesis, we use set-theoretic notation for many concepts in logic such as clauses and formulas in CNF (e.g., we write $c \in \phi$ to mean that clause $c$ is one of the clauses of formula $\phi$). However, this does not automatically mean that we assume no duplicates---whether or not that is the case is clarified on a case-by-case basis.

\begin{example} \label{example:logic}
  Formula $\phi \coloneqq (\neg a \lor b) \land a$ has two variables $a$ and $b$, is in CNF, and contains two clauses. The first clause $\neg a \lor b$ has a negative literal $\neg a$ and a positive literal $b$. Since $\phi$ has two variables, it also has four interpretations. Interpretation $\{\, a \mapsto \text{true}, b \mapsto \text{true} \,\}$ is a model, so $\phi$ is satisfiable. An equivalent set-theoretic representation of $\phi$ is $\{\, \{\, \neg a, b \,\}, \{\, a \,\} \,\}$.
\end{example}

\subsection{Logic-Based Computational Problems} \label{sec:logicproblems}

We begin with a description of \SAT{} and some of its extensions. Given a propositional formula\footnote{Unless stated otherwise, formulas for \SAT{} and other similar problems are assumed to be in CNF.}, \SAT{} asks whether the formula is satisfiable. \SAT{} (also known as \emph{propositional/Boolean satisfiability}) is the first problem shown to be \NP-complete \citep{DBLP:conf/stoc/Cook71,levin1973universal}. Motivated by many real-life problems that were found to be reducible to \SAT{}, research in \SAT{} solving produced algorithms that can efficiently tackle large instances despite the exponential worst-case time complexity \citep{DBLP:series/faia/2009-185}.

Instead of satisfying all clauses, one can attempt to find an interpretation that satisfies the maximum number of clauses---this problem is called Max\SAT{} \citep{bacchus2021maximum,DBLP:series/faia/LiM09}. It is an \NP-hard optimisation problem that (in its most general form) attaches a (potentially infinite) cost for failing to satisfy each clause and seeks to minise total cost.

\#\SAT{}, or \emph{(propositional) model counting}, asks to count the number of models of a formula \citep{DBLP:series/faia/GomesSS09}. \#\SAT{} is the canonical \#\P-complete problem with many applications in areas such as planning and probabilistic reasoning. $\#\exists\SAT{}$, or \emph{projected model counting}, selects a subset of variables called \emph{priority variables} \citep{DBLP:conf/sat/AzizCMS15}. The task is then to count the number of assignments of values to priority variables that can be extended to models. The extension of \#\SAT{} most relevant to our work is called \emph{weighted model counting} (WMC). Given a propositional formula $\phi$ and a \emph{weight function} $w$ from the literals of $\phi$ to non-negative real numbers, WMC asks to compute
\[
\mathrm{WMC}(\phi) = \sum_{\omega \models \phi} \prod_{\omega \models l} w(l),
\]
where the summation is over all models $\omega$ of $\phi$, and the product is over all literals of $\omega$ \citep{DBLP:journals/ai/ChaviraD08}. Lastly, both \#\SAT{} and WMC have been extended to first-order logic \citep{DBLP:conf/ijcai/BroeckTMDR11}---this is the topic of \cref{chapter:wfomc}.

\begin{example} \label{example:wmc1}
  The model count of the formula in \cref{example:logic} is equal to one. With a weight function $w \coloneqq \{\, a \mapsto 0.7, \neg a \mapsto 0.2, b \mapsto 0.8, \neg b \mapsto 0.7 \,\}$, the WMC of the same formula is $0.7 \times 0.8 = 0.56$.
\end{example}

\begin{example}
  With the same weight function $w$ as in \cref{example:wmc1}, the WMC of formula $a \lor b$ is $w(a)w(b) + w(a)w(\neg b) + w(\neg a)w(b) = 0.7 \times 0.8 + 0.7 \times 0.7 + 0.2 \times 0.8 = 1.21$, and the model count of this formula is 3.
\end{example}

There are a number of other computational problems that similarly use logical or algebraic constructs to encode problems from various domains. First, a propositional formula with prepended quantifiers for all of its variables is known as a \emph{quantified Boolean formula} \citep{DBLP:series/faia/BuningB09}. One can then ask whether the formula is true or false. \emph{Satisfiability module theories} considers \SAT{} in the context of a background theory \citep{DBLP:series/faia/BarrettSST09}. These theories can describe the properties of integer arithmetic, sets, trees, strings, and many commonly-used abstract data structures. \emph{Pseudo-Boolean} solvers consider decision and optimisation problems that can be expressed as linear inequalities over Boolean variables \citep{DBLP:series/faia/RousselM09}. \emph{Integer (linear) programming} instances encode integer optimisation problems under inequality constraints of a certain linear-algebraic form \citep{wolsey2020integer}. Finally, \emph{constraint programming} is a powerful paradigm for solving combinatorial search and optimisation problems with a much more expressive syntax \citep{DBLP:reference/fai/2}---we discuss constraint programming in more detail in \cref{sec:cp,chapter:randomlps}.

\section{Declarative Programming}

In a declarative programming language, one describes \emph{what} is to be computed but not \emph{how}. Here we describe two declarative programming paradigms pertinent to our work: logic programming and constraint programming.

\subsection{Logic Programming} \label{sec:lp}

\paragraph{Complete sentences.}
\begin{itemize}
\item Our description of logic programming focusses on Prolog---the most popular logic programming language to date. This section does not, however, cover all (or even most) of the capabilities of Prolog but rather the main concepts and ideas in logic programming relevant to our work in \cref{chapter:randomlps}. For more details on logic programming and Prolog, we refer the reader to some of the numerous books on the subject \citep{DBLP:books/daglib/0041598,DBLP:books/daglib/0067951}.
\item Logic programs can also be equipped with probabilities as a way to represent probability distributions---see [TODO] for an overview of \emph{probabilistic} logic programming.
\item Our description of logic programming here (and in \cref{chapter:randomlps}) generalises what is known in the literature as \emph{normal} logic programs by allowing arbitrary well-formed formulas as bodies of clauses (as opposed to conjunctions of literals). This change also propagates to our definitions of stratification and dependency graph.
\item Footnote: In some logic programming literature, the word \emph{atom} refers to a non-numeric constant, and atoms are called either \emph{compound terms} or \emph{goals} instead.
\item this is more in line with the terminology for predicate logic and less in line with logic programming
\end{itemize}

A \emph{logic program} is a finite sequence\footnote{Although it is common to define logic programs as sets, the order is important for efficiency and can be the difference between finite and infinite running time.} of clauses. A \emph{clause} consists of a head and a body. If a clause has an empty body, it is a \emph{fact}, otherwise it is a \emph{rule}. The Prolog syntax for a fact and a rule is \verb+h.+ and \verb+h :- b.+, respectively, where \texttt{h} is the head and \texttt{b} is the body, although we often write $\texttt{h} \gets \texttt{b}$ instead. Informally, clauses can be read as implications: if \texttt{b} is true, then \texttt{h} must be true.

The \emph{head} of a clause is an atom. An \emph{atom} (i.e., atomic formula) has the form $P(t_1, \dots, t_n)$, where $P$ is a \emph{predicate (symbol)}, and $(t_i)_{i=1}^n$ are terms. A \emph{term} is either a \emph{(logical) variable} or a \emph{constant}. Here, $n \in \mathbb{N}_0$ is the \emph{arity} of $P$. Some built-in predicates such as equality can be written in infix notation and without parentheses, i.e., as $a = b$ instead of $=(a, b)$.

The \emph{body} of a clause is a formula.\footnote{In the literature, it is common to define clause bodies as conjunctions, but support for arbitrary formulas is also available.} A \emph{formula} is any well-formed expression that connects atoms using conjunction, disjunction, and negation (as well as parentheses). Prolog syntax for these operators is different from the standard notation used in logic: we write `\verb+,+' instead of $\land$, `\verb+;+' instead of $\lor$, and `\verb#\+#' instead of $\neg$. Just like with the syntax for clauses, in most cases we continue to use logic-based syntax for convenience.

\paragraph{Things to mention.}
\begin{itemize}
\item Stratification
  \begin{itemize}
  \item \emph{Stratification} is a condition necessary for probabilistic logic programs
    \citep{DBLP:conf/padl/MantadelisR17} and often enforced on logic programs
    \citep{DBLP:journals/tcs/Bidoit91} that helps to ensure a unique answer to every
    query. This is achieved by restricting the use of negation so that any program
    $\mathscr{P}$ can be partitioned into a sequence of programs $\mathscr{P} =
    \bigsqcup_{i=1}^n \mathscr{P}_i$ such that, for all $i$, the negative literals
    in $\mathscr{P}_i$ can only refer to predicates defined in $\mathscr{P}_j$ for
    $j \le i$ \citep{DBLP:journals/tcs/Bidoit91}.
  \item include the formal definition from the original paper \citep{DBLP:books/mk/minker88/AptBW88}
  \item also include a good example
  \item consider including the definition of a (predicate) dependency graph and the lemma that follows. I think the original definition is slightly different: it allows edges to be positive and negative at the same time.
  \item (the original paper) shown that stratified programs are always consistent (i.e., avoid paradoxical situations such as $p \gets \neg p$) \citep{DBLP:books/mk/minker88/AptBW88}
  \item only a sufficient condition for consistency
  \end{itemize}
\item A \emph{query} is a formula. Queries are evaluated to produce either truth values (if the query has no variables) or maps from variables to constants that are consistent with the logic program.
\item have an example of Prolog execution with recursion
\end{itemize}

\subsection{Constraint Programming} \label{sec:cp}

\begin{itemize}
\item emphasise why it's useful to have constraint models
\item search and heuristics
\item symmetry breaking
\item propagation and entailment
\end{itemize}

\section{Representations of Probability Distributions}

(including the ideas behind inference)
\begin{itemize}
\item define what a distribution is
\item Probabilistic Graphical Models
  \begin{itemize}
  \item Bayesian Networks
  \item Markov Random Fields
  \item Relational
    \begin{itemize}
    \item Markov Logic Networks
    \end{itemize}
  \end{itemize}
\item Probabilistic Programming
  \begin{itemize}
  \item Imperative and (Maybe) Functional, e.g., BLOG
  \item Probabilistic Logic Programming
    \begin{itemize}
    \item ProbLog (including some detail about how inference is defined)
    \end{itemize}
  \end{itemize}
\end{itemize}

\section{Knowledge Compilation} \label{sec:kc}

(including lots of detail about all the data structures)
\begin{itemize}
\item Boolean and Pseudo-Boolean Functions
\item NNF
\item d-DNNF
\item SDDs
\item BDDs
\item ADDs (with a brief mention of AADDs, XDDs, etc.)
\end{itemize}

\section{Applications}

of WMC?

\begin{itemize}
\item Statistical Relational Learning
\item Neuro-Symbolic Artificial Intelligence
\item Natural Language Processing
\item Robotics
\end{itemize}
