\SetKw{KwRet}{yield}
\SetKwProg{Fn}{Function}{:}{}

\SetKwFunction{applyAllRules}{applyAllRules}
\SetKwFunction{applyGreedyRules}{applyGreedyRules}
\SetKwFunction{applyGreedyRulesToFormulas}{applyGreedyRulesToFormulas}

\SetKwFunction{emptyy}{empty}
\SetKwFunction{get}{get}
\SetKwFunction{put}{put}

\SetKwFunction{constructDomainMap}{constructDomainMap}
\SetKwFunction{identifyRecursion}{identifyRecursion}
\SetKwFunction{generateMaps}{generateMaps}
\SetKwFunction{mergeFcgs}{mergeFcgs}
\SetKwFunction{updateCache}{updCache}

\chapter{Recursive Solutions to FOMC}\label{chapter:wfomc}

\section{Introduction}

% 1. What is the problem?
% 2. Why is it interesting and important?
% 1) the latest first-order variable elimination algorithm \citep{DBLP:journals/jair/TaghipourFDB13}
% 2) other approaches to lifted inference  \citep{DBLP:conf/uai/BrazO17,DBLP:conf/nips/JhaGMS10,DBLP:journals/ijar/RiguzziBZCL17}
% 3) Unlike most early algorithms for lifted inference that were adaptations of probabilistic inference algorithms such as AND/OR search \citep{DBLP:conf/aaai/GogateD10} and variable elimination \citep{DBLP:conf/ijcai/BrazAR05,DBLP:conf/aaai/MilchZKHK08}, WFOMC is an approach grounded in logic.

\emph{First-order model counting} (FOMC) is the problem of computing the number
of models of a sentence in first-order logic (FOL) given the size(s) of its
domain(s) \citep{DBLP:conf/pods/BeameBGS15}. \emph{Symmetric weighted FOMC}
(WFOMC) extends FOMC with (pairs of) weights on predicates and asks for a
weighted sum across all models instead. By fixing the sizes of the domains, a
WFOMC instance can be rewritten as a WMC instance. WFOMC emerged as the dominant
approach to \emph{lifted (probabilistic) inference}. Lifted inference techniques
exploit symmetries in probabilistic models by reasoning about sets rather than
individuals \citep{DBLP:conf/ecai/Kersting12}. By doing so, many instances
become solvable in polynomial time \citep{DBLP:conf/nips/Broeck11}. Lifted
inference algorithms are typically used on probabilistic models such as
probabilistic programming languages
\citep{DBLP:journals/ml/RaedtK15,DBLP:journals/ijar/RiguzziBZCL17}, Markov logic
networks
\citep{DBLP:conf/ijcai/BroeckTMDR11,DBLP:journals/cacm/GogateD16,DBLP:journals/ml/RichardsonD06},
and other lifted graphical \citep{DBLP:journals/ml/KimmigMG15} and statistical
relational \citep{DBLP:series/synthesis/2016Raedt} models. Lifted inference
techniques for probabilistic databases, while developed somewhat independently,
have also been inspired by WFOMC
\citep{DBLP:journals/pvldb/GatterbauerS15,DBLP:journals/debu/GribkoffSB14}.
While WFOMC tends to receive more attention in the literature, FOMC is an
interesting problem in an of itself because of its connections to finite model
theory \citep{DBLP:conf/kr/BremenK21} and applications in enumerative
combinatorics \citep{DBLP:conf/ilp/BarvinekB0ZK21}.

% 3. Why is it hard? (E.g., why do naive approaches fail?)
% complexity/liftability -> murky boundary

Traditionally in computational complexity theory, a problem is \emph{tractable}
if it can be solved in time polynomial in the instance size. The equivalent
notion in (W)FOMC is liftability. A (W)FOMC instance is \emph{(domain-)liftable}
if it can be solved in time polynomial in the size(s) of the domain(s)
\citep{jaeger2012liftability}. Over more than a decade, many classes of
instances were shown to be liftable
\citep{DBLP:conf/kr/BremenK21,DBLP:conf/nips/KazemiKBP16,DBLP:conf/lics/KuusistoL18,DBLP:journals/jair/Kuzelka21}.
First, \citet{DBLP:conf/nips/Broeck11} showed that the class of all sentences of
FOL with up to two variables (denoted \FOtwo{}) is liftable. Then
\citet{DBLP:conf/pods/BeameBGS15} proved that there exists a sentence with three
variables for which FOMC is $\#\P_{1}$-complete (i.e., \FOthree{} is not
liftable). Since these two results came out, most of the research on (W)FOMC
focused on developing faster solutions for the \FOtwo{} fragment
\citep{DBLP:conf/uai/BremenK21,DBLP:conf/aaai/MalhotraS22} and defining new
liftable fragments. These fragments include \SFO{} and \SRU{}
\citep{DBLP:conf/nips/KazemiKBP16}, \Uone{} \citep{DBLP:conf/lics/KuusistoL18},
\FOtwo{} with tree axioms \citep{DBLP:conf/kr/BremenK21}, and \Ctwo{} (i.e., the
two-variable fragment with counting quantifiers)
\citep{DBLP:journals/jair/Kuzelka21,DBLP:conf/aaai/MalhotraS22}. On the
empirical front, there are several open-source implementations of exact WFOMC
algorithms: \textsc{ForcLift} \citep{DBLP:conf/ijcai/BroeckTMDR11},
probabilistic theorem proving \citep{DBLP:journals/cacm/GogateD16}, and
\textsc{L2C} \citep{DBLP:conf/kr/KazemiP16}. Approximate counting is supported
by \textsc{ApproxWFOMC} \citep{DBLP:conf/ijcai/BremenK20} as well as
\textsc{ForcLift} \citep{DBLP:conf/uai/BroeckCD12} and probabilistic theorem
proving \citep{DBLP:journals/cacm/GogateD16}.

% 4. Why hasn't it been solved before? (Or, what's wrong with previous proposed
% solutions? How does mine differ?)
% simple unliftable instances -> recursion

However, none of the publicly available exact (W)FOMC algorithms can efficiently
compute functions as simple as a factorial.\footnote{The problem of computing
  the factorial can be described using two variables and counting quantifiers,
  so it is known to be liftable in principle
  \citep{DBLP:journals/jair/Kuzelka21}, but an algorithm that can lift such an
  instance in practice does not exist.} We claim that this shortcoming is due to
the inability of these algorithms to construct recursive solutions. The topic of
recursion in the context of WFOMC has been studied before but in limited ways.
\Citet{DBLP:conf/ilp/BarvinekB0ZK21} use WFOMC to generate numerical data that
is then used to conjecture recurrence relations that explain that data.
\Citet{DBLP:conf/nips/Broeck11} introduced the idea of \emph{domain recursion}.
Intuitively, domain recursion partitions a domain of size $n$ into a single
explicitly named constant and the remaining domain of size $n-1$. However, many
stringent conditions are enforced to ensure that the search for a tractable
solution always terminates.

% 5. What are the key components of my approach and results? Also include any
% specific limitations.

% 5.1) An overview of how ForcLift/Crane work.

In this work, we show how to relax these restrictions in a way that results in a
stronger (W)FOMC algorithm, capable of handling more instances (e.g., counting
various injective mappings) in a lifted manner. The ideas presented in this
chapter are implemented in \textsc{Crane}---an extension of the arguably most
well-known WFOMC algorithm \textsc{ForcLift}. \textsc{ForcLift} works in two
stages: compilation and evaluation/propagation.\footnote{There is also an
  intermediate stage called \emph{smoothing} that takes place between
  compilation and evaluation. As our changes to smoothing are rather elementary,
  we do not discuss them to not distract the reader from the main contributions
  of this chapter.} In the first stage, various \emph{(compilation) rules} are
applied to the input (or some derivative) formula, gradually constructing a
circuit. In the second stage, the weights of the instance are propagated through
the circuit, computing the WMC\@. Along with new compilation rules,
\textsc{Crane} introduces changes to both stages of the process. First, while
\textsc{ForcLift} applies compilation rules via greedy\footnote{The algorithm is
  not described in any paper on \textsc{ForcLift} but can be found in its source
  code at \url{https://dtai.cs.kuleuven.be/drupal/wfomc}} search, \textsc{Crane}
uses a hybrid search algorithm that applies some rules greedily and some using
breadth-first search. Second, the product of compilation is not directly
evaluated but rather interpreted as a collection of functions on domain sizes.

\begin{figure}[t]
  \centering
  \begin{subfigure}{0.50\textwidth}
    \centering
    \begin{tikzpicture}[triangle/.style = {regular polygon, regular polygon
        sides=3},edge from parent/.style={draw,-Latex}]
      \node[draw,circle] {}
      child {
        node[draw,ellipse] (b) {$\phi(n)$}
        child {node[draw,triangle] {}}
      }
      child {
        node[draw,circle] {}
        child {node[draw,ellipse] (a) {$\phi(n)$}}
      };
      \draw[-Latex,ultra thick,blue] (a) -- (b);
    \end{tikzpicture}
    \caption{The kind of non-tree-like edges that are supported by both
      \textsc{ForcLift} and \textsc{Crane}, i.e., those that create cycles in
      the undirected version of the graph but not directed
      cycles}\label{fig:before}
  \end{subfigure}
  \hspace{0.08\textwidth}
  \begin{subfigure}{0.40\textwidth}
    \centering
    \begin{forest}
      for tree={ellipse,draw,edge={-Latex}}
      [$\phi(n)$, name=n1,
      [$\psi(n)$, edge label={node[midway,left] {GDR}},
      [$\phi(n-1)$, edge label={node[midway,left] {CR}}, name=n3]
      ]
      ]
      \draw[-Latex,ultra thick,blue] (n3) to [bend right=45] node [midway,xshift=30] () {$n \mapsto n-1$} (n1);
    \end{forest}
    \caption{The kind of non-tree-like edges that are only supported by
      \textsc{Crane}, i.e., those that create directed cycles}\label{fig:after}
  \end{subfigure}
  \caption{Non-tree-like edges in first-order knowledge
    compilation (highlighted in blue)}\label{fig:intuition}
\end{figure}

% 5.2) The main idea: cycles that represent recursive calls.

The main conceptual difference between \textsc{Crane} and \textsc{ForcLift} is
that we utilise labelled directed graphs instead of circuits. The cycles in
these graphs represent recursive calls. See \cref{fig:after} for an illustration
of an example scenario. Suppose the original formula $\phi$ depends on a domain
of size $n \in \mathbb{N}$. \emph{Generalised domain recursion} (GDR)---one of
the new compilation rules---transforms $\phi$ into a different formula $\psi$
that has an additional constant and some new \emph{constraints}. After some
additional transformations, the constraints in $\psi$ become `uniform' and can
be removed, replacing the domain of size $n$ with a new domain of size
$n-1$---this is the responsibility of the \emph{constraint removal} (CR)
compilation rule. Afterwards, another compilation rule recognizes that the
resulting formula $\phi(n-1)$ is just like the input formula $\phi(n)$ except it
refers to a different domain. This observation allows us to add a cycle-forming
edge to the graph (highlighted in blue in \cref{fig:after}), which can be
interpreted as function $f$ relying on $f(n-1)$ to compute $f(n)$. To construct
such graphs, we also introduce a novel search algorithm that replaces the greedy
search used by \textsc{ForcLift}.

% 1. GDR: We assume that some form of domain recursion seems like a natural first step (moreso than any of the other compilation rules used by \textsc{ForcLift}). We relax the restrictions and see what kind of formulas we end up with.
% 2. CR: A recursive solution to a computational problem always has some notion of 'this subproblem is just like the original problem but smaller'. In the case of first-order knowledge compilation, the canonical choice for such notion is when two formulas are isomorphic up to domains. To make this notion work with GDR, we need a way to undo the inequality constraints introduced by GDR while checking whether the constraints can be removed uniformly.
% 3. Ref: 'to solve a problem, we need to solve a smaller instance of the same problem' <- that's just a recursive call.
% 4. Search: Greedy search is not enough. There is no reason for it to be enough. That's juts an implicit assumption in previous work.

% \begin{itemize}
%   \item a generalisation of domain recursion by \citet{DBLP:conf/nips/Broeck11},
%   \item \emph{constraint removal} (CR)---a formula transformation rule that removes
%         the constraints introduced by generalised domain recursion (GDR),
%         introducing a new (smaller) domain instead,
%   \item and a rule for creating recursive calls.
% \end{itemize}

% 5.3) contributions, references to sections, shortcomings

\Cref{sec:recprelims} defines the representation used for sentences in FOL as
well as discusses caching and some notational conventions. At the beginning of
\cref{sec:methods}, we formally define the graphs that replace circuits in
representing a solution to a (W)FOMC problem and discuss some related notions.
\Cref{sec:rules} introduces the new compilation rules. \Cref{sec:search} then
describes our new search algorithm that makes fewer assumptions than
\textsc{ForcLift} about the right order in which compilation rules should be
applied. In \cref{sec:interpret}, we discuss how a graph can be interpreted as a
collection of (potentially recursive) functions. Finally, in \cref{sec:results}
we compare \textsc{ForcLift} and \textsc{Crane} on a range of function-counting
problems. We show that \textsc{Crane} performs as well as \textsc{ForcLift} on
the instances that were already solvable by \textsc{ForcLift} but is also able
to handle most of the instances that \textsc{ForcLift} fails on.

% In a typical solution produced by \textsc{Crane}, these rules are executed in
% exactly this order (interspersed with some other rules), with the edge that
% represents a recursive call pointing back to the node introduced by GDR\@.

\section{Preliminaries}\label{sec:recprelims}

In this section, we describe our format for FOMC instances, introduce some
notation, and discuss our caching scheme, which is used to identify
possibilities for a recursive call. Note that although the focus of this chapter
is on unweighted model counting, \textsc{ForcLift}'s
\citep{DBLP:conf/ijcai/BroeckTMDR11} support for weights trivially transfers to
\textsc{Crane} as well.

Our representation of FOMC instances is largely based on the format used
internally by \textsc{ForcLift}, some aspects of which are described by
\citet{DBLP:conf/ijcai/BroeckTMDR11}. \textsc{ForcLift} can translate sentences
in a variant of function-free many-sorted FOL with equality to this internal
format. We use lowercase Latin letters for predicates and constants, uppercase
Latin letters for variables, and uppercase Greek letters for domains. An
\emph{atom} is $p(t_1, \dots, t_n)$ for some predicate $p$ and terms
$t_{1}, \dots, t_{n}$. A \emph{term} is either a constant or a variable. A
\emph{literal} is either an atom or the negation of an atom (denoted by
$\neg p(t_1, \dots, t_n)$). Let $\mathcal{D}$ be the set of all (finite)
domains. Initially, $\mathcal{D}$ contains all domains mentioned by the input
(W)FOMC instance. During compilation, new domains are added to $\mathcal{D}$ by
some of the compilation rules. Each such new domain is interpreted as a subset
of some element of $\mathcal{D}$.

\begin{definition}[Constraint]\label{def:constraint}
  An \emph{(inequality) constraint} is a pair $(a, b)$, where $a$ is a variable,
  and $b$ is either a variable or a constant.
\end{definition}

\begin{definition}[Clause]\label{def:clause}
  A \emph{clause}\footnote{\citet{DBLP:conf/ijcai/BroeckTMDR11} refer to clauses
    as c-clauses.} is a triple $c = (L, C, \delta_c)$, where $L$ is a set of
  literals, $C$ is a set of constraints, and $\delta_c$ is the domain map of
  $c$. Let $\Vars$ be the function that maps clauses and sets of either literals
  or constraints to the set of variables contained within. In particular,
  $\Vars(c) \coloneqq \Vars(L) \cup \Vars(C)$. \emph{Domain map}
  $\delta_{c}\colon \Vars(c) \to \mathcal{D}$ is a function that maps all
  variables in $c$ to their domains such that (s.t.) if $(X, Y) \in C$ for some
  variables $X$ and $Y$, then $\delta_c(X) = \delta_c(Y)$. For convenience, we
  sometimes write $\delta_c$ for the domain map of $c$ without unpacking $c$
  into its three constituents.
\end{definition}

Similarly to variables in \cref{def:clause}, all constants are (implicitly)
mapped to domains, and each $n$-ary predicate is implicitly mapped to a sequence
of $n$ domains. For constant or variable $x$, predicate $p$, and domains
$\Gamma$ and $\Delta$, we write, e.g., $x \in \Gamma$ and
$p \in \Gamma \times \Delta$ to denote that $x$ is associated with $\Gamma$, and
$p$ is associated with $\Gamma$ and $\Delta$ (in that order).

\begin{definition}[Formula]\label{def:formula}
  A \emph{formula} (called a c-theory by \citet{DBLP:conf/ijcai/BroeckTMDR11})
  is a set of clauses s.t.\ all constraints and atoms `type check' with respect
  to domains.
\end{definition}

\begin{example}\label{example:first}
  Let $\phi \coloneqq \{\, c_1, c_2 \,\}$ be a formula with clauses
  \begin{align*}
    c_1 &\coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\}),\\
    c_2 &\coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Gamma \,\})
  \end{align*}
  for some predicate $p$, variables $X$, $Y$, $Z$, and domains $\Gamma$ and
  $\Delta$. Then $\Vars(\{\, (Y, Z) \,\}) = \{\, Y, Z \,\}$, and
  $\Vars(c_{1}) = \Vars(c_{2}) = \{\, X, Y, Z \,\}$. Based on the domain maps of
  $c_{1}$ and $c_{2}$, we can infer that $p \in \Gamma \times \Delta$. All
  variables (in both clauses) that occur as the first argument to $p$ are in
  $\Gamma$, and, likewise, all variables that occur as the second argument to
  $p$ are in $\Delta$. Therefore, $\phi$ `type checks' as a valid formula.
\end{example}

There are two major differences between
\cref{def:constraint,def:clause,def:formula} and the corresponding concepts
introduced by \citet{DBLP:conf/ijcai/BroeckTMDR11}. First, we decouple
variable-to-domain assignments from constraints and move them to a separate
function $\delta_{c}$ in \cref{def:clause}. Formalising these assignments as a
function unveils the (previously implicit) assumption that each variable must be
assigned to a domain. Second, while \citet{DBLP:conf/ijcai/BroeckTMDR11} allow
for equality constraints and constraints of the form $X \not\in \Delta$ for some
variable $X$ and domain $\Delta$, we exclude such constraints simply because
they are not needed.

One can read a formula from \cref{def:formula} as a sentence in a FOL\@. All
variables in a clause are implicitly universally quantified (but note that
variables are never shared among clauses), and all clauses in a formula are
implicitly linked by a conjunction. Thus, formula $\phi$ from
\cref{example:first} reads as
\begin{align*}
  (\forall X \in \Gamma\text{. }\forall Y \in \Delta\text{. }\forall Z \in \Delta\text{. }Y \ne Z &\implies \neg p(X, Y) \lor \neg p(X, Z)) \land \\
  (\forall X \in \Gamma\text{. }\forall Y \in \Delta\text{. }\forall Z \in \Gamma\text{. }X \ne Z &\implies \neg p(X, Y) \lor \neg p(Z, Y)).
\end{align*}

Once domains are mapped to finite sets and constants to specific (and different)
elements in those sets, a formula can be viewed as a set of conditions that the
predicates (interpreted as relations) have to satisfy.\footnote{If some domain
  is not big enough to contain all of its constants, the formula is
  unsatisfiable.} Hence, FOMC is the problem of counting the number of
combinations of relations that satisfy these conditions.

\begin{example}
  Let $\phi$ be as in \cref{example:first} and let $|\Gamma| = |\Delta| = 2$.
  There are $2^{2 \times 2} = 16$ possible relations between $\Gamma$ and
  $\Delta$. Let us count how many of them satisfy the conditions imposed on
  predicate $p$. The empty relation does. All four relations of cardinality one
  do too. Finally, there are two relations of cardinality two that satisfy the
  conditions as well. Thus, the FOMC of $\phi$ (when $|\Gamma| = |\Delta| = 2$)
  is 7. Incidentally, the FOMC of $\phi$ counts partial injections. We will
  continue to use the problem of counting partial injections (and the formula
  from \cref{example:first} specifically) as the main running example throughout
  the chapter.
\end{example}

\paragraph*{Notation for functions.}
We write $\to$ for functions, $\pfun$ for partial functions,
$\twoheadrightarrowtail$ for bijections, and $\hookrightarrow$ for set
inclusion. Let $\id$ denote the identity function (on any domain). For any
function $f$, let $\dom(f)$ be its domain, and $\Imm f$ be its image.

\paragraph*{Notation for lists.}
Let $\langle\rangle$ and $\langle x \rangle$ denote an empty list and a list
with one element $x$, respectively. We write $\in$ for (in-order) enumeration,
$\mdoubleplus$ for concatenation, and $|\cdot|$ for the length of a list. Let
$h : t$ denote a list with the first element (i.e., head) $h$ and the remaining
list (i.e., tail) $t$. We also use list comprehensions written equivalently to
set comprehensions. For example, let $L \coloneqq \langle 1 \rangle$ and
$M \coloneqq \langle 2 \rangle$ be two lists. Then
$M = \langle 2x \mid x \in L \rangle$,
$L \mdoubleplus M = 1 : \langle 2 \rangle$, and $|M| = 1$.

\paragraph*{Hashing.}
We use (integer-valued) hash functions to efficiently discard pairs of formulas
that are too different for recursion to be established. The hash code of a
clause $c = (L, C, \delta)$ (denoted by $\# c$) combines the hash codes of the
sets of constants and predicates in $c$, the numbers of positive and negative
literals, the number of inequality constraints $|C|$, and the number of
variables $|\Vars(c)|$. The hash code of a formula $\phi$ combines the hash
codes of all its clauses and is denoted by $\#\phi$.

\paragraph*{Caching.}
\citet{DBLP:conf/ijcai/BroeckTMDR11} use a cache to check if a formula is
identical to one of the formulas that have already been fully compiled. If that
is the case, then the circuit already contains the subcircuit for this formula.
Instead of duplicating this subcircuit, one would draw an edge that creates an
undirected (but not a directed) cycle (as in \cref{fig:before}). To facilitate
recursion, we extend the caching scheme to include formulas that have been
encountered but not fully compiled yet. Hence, the same procedure can now create
directed cycles in the FCG\@. Formally, we define a \emph{cache} to be a map
from integers (e.g., hash codes) to sets of pairs of the form $(\phi, v)$, where
$\phi$ is a formula, and $v$ is an FCG node.

\section{Methods}\label{sec:methods}

We begin this section by formally defining the graphs that \textsc{Crane} uses
as a generalisation of circuits. Then, \cref{sec:rules} describes three new
compilation rules, and \cref{sec:search} outlines the hybrid search algorithm
that replaces the greedy search used by \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11}.

\begin{figure}[t]
  \centering
  \begin{tikzpicture}[every node/.style={draw,ellipse},edge from
    parent/.style={draw,-Latex},sibling distance=2cm,level 2/.style={sibling
      distance=6cm}]
    \node (dr) {$\GDR_{\Gamma \gets \Gamma \setminus \{\, x \,\}}$}
    child {node {$\bigvee_{\Delta^\top \subseteq \Delta}$}
      child {node {$\CR_{\Gamma \mapsto \Gamma'}$}
        child {
          node[circle] {$\wedge$}
          child {node {$\bot_{(\emptyset, \{\, (X, Y) \,\}, \{\, X \mapsto \Delta^\top, Y \mapsto \Delta^\top \,\})}$}}
          child {node (ref) {$\Reff_{\{\, \Gamma \mapsto \Gamma', \Delta \mapsto \Delta^{\bot} \,\}}$}}
        }}};
    \draw[-Latex, bend right] (ref) to (dr);
  \end{tikzpicture}
  \caption{A simplified version of an FCG constructed by \textsc{Crane} for the
    problem of counting partial injections from \cref{example:first}. Label
    $\bigvee_{\Delta^\top \subseteq \Delta}$ denotes set-disjunction, $\land$
    denotes conjunction, and $\bot$ denotes a contradiction---see the work by
    \citet{DBLP:conf/ijcai/BroeckTMDR11} for the descriptions of these node
    types. Here we omit nodes whose only arithmetic effect is multiplication by
    one. Some of these nodes play an important role in the weighted version of
    the problem, whereas others are remnants of the interaction between
    compilation rules and the way in which \textsc{ForcLift} handles existential
    quantifiers.}\label{fig:examplefcg}
\end{figure}

% From circuits to graphs.
A \emph{first-order deterministic decomposable negation normal form
  computational graph} (FCG) is a (weakly connected) directed graph with a
single source, node labels, and ordered outgoing edges.\footnote{Imposing an
  ordering on outgoing edges is just a limited version of edge labelling.} We
denote an FCG as $G = (V, s, N^+, \tau)$, where $V$ is the set of nodes, and
$s \in V$ is the unique source. Function $N^+$ maps each node in $V$ to a
\emph{list} of its direct successors. Node labels consist of two parts: the
\emph{type} and the \emph{parameters}. To avoid clutter, we leave the parameters
implicit and let $\tau$ denote the node-labelling function that maps each node
in $V$ to its type. For each node $v \in V$, the length of list $N^+(v)$ (i.e.,
the out-degree of $v$) is determined by its type $\tau(v)$. Most node types are
as in previous work
\citep{DBLP:conf/nips/Broeck11,DBLP:conf/ijcai/BroeckTMDR11}. The type for
non-tree-like edges (denoted by $\Reff$), while used before, is extended to
contain the information necessary to support recursive calls. We also add three
new types:
\begin{itemize}
  \item a type for constraint removal denoted by $\CR$,
  \item a type for generalised domain recursion denoted by $\GDR$ (both with
        out-degree one),
  \item and $\star$---a placeholder type (with out-degree zero) for nodes that
        are going to be replaced.
\end{itemize}
When drawing an FCG, we order outgoing edges from left to right, write node
labels directly on the nodes, and omit irrelevant labels and/or parameters. See
\cref{fig:examplefcg} for an example of an FCG\@. Its source node has out-degree
1 (i.e., $|N^+(s)| = 1$), label
$\GDR_{\Gamma \gets \Gamma \setminus \{\, x \,\}}$, and type $\GDR$ (i.e.,
$\tau(s) = \GDR$).

%\paragraph*{Notation.}
Similarly to \citet{DBLP:conf/ijcai/BroeckTMDR11}, we write $T_p$ for an FCG
that has a node with the label $T_p$ (i.e., type $T$ and parameter(s) $p$) and
$\star$'s as all of its direct successors. In particular, as an FCG, $\star$
denotes
$(\{\, s \,\}, s, \{\, s \mapsto \langle\rangle \,\}, \{\, s \mapsto \star \,\})$,
i.e., an FCG with just one node of type $\star$ and no edges. We write $T_p(v)$
for an FCG with one edge from a node labelled $T_{p}$ to some other node $v$
(and no other nodes or edges).

\begin{figure}[t]
  \centering
  \begin{subfigure}{0.49\textwidth}
    \centering
    \begin{tikzpicture}[edge from parent/.style={draw,-Latex}]
      \node[draw,circle,label={[text=blue]1}] (top) {}
      child {
        node[draw,circle,label={[text=blue,xshift=-1mm]2}] {}
        child {node[draw,ellipse] (ref) {$\Reff$}}
        child {node[draw,circle,label={[text=blue,xshift=1mm,yshift=-1mm]3}] {$\star$}}
      }
      child {node[draw,circle,label={[text=blue,xshift=1mm,yshift=-1mm]4}] {$\star$}};
      \draw[-Latex] (ref) to [bend left=45] (top);
    \end{tikzpicture}
    \caption{An example of an FCG}\label{fig:smallexample1}
  \end{subfigure}
  \begin{subfigure}{0.49\textwidth}
    \centering
    \begin{tikzpicture}[edge from parent/.style={draw,-Latex}]
      \node[draw,circle,label={[text=blue]1}] (top) {}
      child {
        node[draw,circle,label={[text=blue,xshift=-1mm]2}] {}
        child {node[draw,circle,label={[text=blue,xshift=2mm,yshift=-1mm]3}] {$\star$}}
      }
      child {node[draw,circle,label={[text=blue,xshift=1mm,yshift=-1mm]4}] {$\star$}};
    \end{tikzpicture}
    \caption{The underlying tree of
      \cref{fig:smallexample1}}\label{fig:smallexample2}
  \end{subfigure}
  \caption{An FCG and its underlying tree. The integers in blue denote the
    pre-order traversal of the underlying tree.}\label{fig:ordering}
\end{figure}

%\paragraph*{Connecting FCGs with formulas.}
Finally, we introduce a structure that represents a solution to a (W)FOMC
problem while it is still being built. A \emph{chip} is a pair $(G, L)$, where
$G$ is an FCG, and $L$ is a list of formulas, s.t. $|L|$ is equal to the number
of $\star$'s in $G$. $L$ contains formulas that still need to be compiled. Once
a formula is compiled, it replaces one of the $\star$'s in $G$. We say that an
FCG is \emph{complete} (i.e., it represents a \emph{complete solution}) if it
has no $\star$'s. Similarly, a chip is complete if its FCG is complete (or,
equivalently, the list of formulas is empty). Let the \emph{underlying tree} of
$G$ be the induced subgraph of $G$ that omits all $\Reff$
nodes.\footnote{Subsequently presented algorithms ensure that the underlying
  tree is guaranteed to be a tree.} Then we can define an implicit bijection
between the formulas in $L$ and the $\star$'s in $G$ according to the order in
which elements of $L$ are listed and the pre-order traversal of the underlying
tree of $G$. For example, if $G$ is as in \cref{fig:smallexample1} (with its
underlying tree in \cref{fig:smallexample2}), then $|L| = 2$. Moreover, the
first element of $L$ is associated with the $\star$ labelled 3, and the second
with the one labelled 4.

\subsection{New Compilation Rules}\label{sec:rules}

A \emph{(compilation) rule} takes a formula and returns a set of chips. The
cardinality of this set is the number of different ways in which the rule can be
applied to the input formula. While \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11} heuristically chooses one of them, in an
attempt to not miss a solution, \textsc{Crane} returns them all. In particular,
if a rule returns an empty set, then that rule does not apply to the formula.

\subsubsection{Generalised Domain Recursion}\label{sec:dr}
% 1. Note that the total number of such possibilities is not necessarily
% exponential: some combinations produce clearly unsatisfiable formulas that can
% be immediately discarded.
% 2. We can combine all of these possibilities into a single formula equivalent
% to the original one.
% 3. \begin{itemize}
%   \item the formula is shattered,
%   \item the formula has no independent subformulas,
%   \item and there exists a root binding class.
% \end{itemize}
% 4. During evaluation, $v$ is ignored, and the WMCs of $x$ and $r$ can be
% computed independently. Note that the WMC of $x$ is independent of the size of
% $D$---this further simplifies the matters.

\paragraph*{Notation.}
Let $S$ be a set of constraints or literals, $V$ a set of variables, and $x$ a
variable or a constant. We write $S[x/V]$ to denote $S$ with all occurrences of
all variables in $V$ replaced with $x$.\footnote{If $(X, Y)$ is a two-variable
  constraint, substituting a constant $c$ for $X$ would result in $(c, Y)$,
  which would have to be rewritten as $(Y, c)$ to fit the definition of a
  constraint.}

% Main idea
The main idea behind domain recursion (both the original version by
\citet{DBLP:conf/nips/Broeck11} and the one presented here) is as follows. Let
$\Omega \in \mathcal{D}$ be a domain. Assuming that $\Omega \ne \emptyset$, pick
some $x \in \Omega$. Then, for every variable $X \in \Omega$ that occurs in a
literal, consider two possibilities: $X = x$ and $X \ne x$.

\begin{example}\label{example:dr}
  Let $\phi$ be a formula with a single clause
  \[
    (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\}).
  \]
  Then we can introduce constant $x \in \Gamma$ and rewrite $\phi$ as
  $\phi' = \{\, c_{1}, c_{2} \,\}$, where
  \begin{align*}
    c_{1} &= (\{\, \neg p(x, Y), \neg p(x, Z) \,\}, \{\, (Y, Z) \,\}, \{\, Y \mapsto \Delta, Z \mapsto \Delta \,\}), \\
    c_{2} &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (X, x), (Y, Z) \,\}, \{\, X \mapsto \Gamma', Y \mapsto \Delta, Z \mapsto \Delta \,\}),
  \end{align*}
  and $\Gamma' = \Gamma \setminus \{\, x \,\}$.
\end{example}

% Original domain recursion
\citet{DBLP:conf/nips/Broeck11} imposes stringent preconditions on the input
formula to ensure that the expanded version of the formula (as in
\cref{example:dr}) can be handled efficiently. For example, at least one clause
must contain a variable that occurs in all of its atoms. The clauses in this
expanded formula are then partitioned into three parts based on whether the
transformation introduced constants or constraints or both. The aforementioned
conditions ensure that these parts can be treated independently.

\begin{algorithm}[t]
  \caption{The compilation rule for $\GDR$ nodes.}\label{alg:domainrecursion}
  \KwIn{formula $\phi$, set of all relevant domains $\mathcal{D}$}
  \KwOut{set of chips $S$}
  $S \gets \emptyset$\;
  \ForEach{domain $\Omega \in \mathcal{D}$ s.t.\ there is $c \in \phi$ and $X \in \Vars(L_c)$ s.t. $\delta_c(X) = \Omega$\label{line:condition}}{
    $\phi' \gets \emptyset$\;
    $x \gets \text{a new constant in domain } \Omega$\;
    \ForEach{clause $c = (L, C, \delta) \in \phi$\label{line:forclause}}{
      $V \gets \{\, X \in \Vars(L) \mid \delta(X) = \Omega \,\}$\;
      \ForEach{subset $W \subseteq V$ s.t. $W^2 \cap C = \emptyset$ {\bf and} $W \cap \{\, X \in \Vars(C) \mid (X, y) \in C \text{ for some constant } y \,\} = \emptyset$\label{line:conditions}}{
        \tcc{$\delta'$ restricts $\delta$ to the new set of variables}
        $\phi' \gets \phi' \cup \{\, (L[x/W], C[x/W] \cup \{\, (X, x) \mid (X \in V \setminus W) \,\}, \delta') \,\}$\;\label{line:generation}
      }
    }
    $S \gets S \cup \{\, (\GDR_{\Omega \gets \Omega \setminus \{\, x \,\}}, \langle\phi'\rangle) \,\}$\;
  }
\end{algorithm}

% Description of GDR, in contrast to DR
In contrast, GDR has only one precondition: for GDR to be applicable on domain
$\Omega \in \mathcal{D}$, there must be at least one variable with domain
$\Omega$ that is featured in a literal (and not just in constraints). Without
such variables, GDR would have no effect on the formula. GDR is also simpler in
that the expanded formula is left as-is to be handled by other compilation
rules. Typically, after a few more rules are applied, a combination of $\CR$ and
$\Reff$ nodes introduces a cycle-inducing edge back to the $\GDR$ node, thus
completing the definition of a recursive function. The GDR compilation rule is
summarised as \cref{alg:domainrecursion} and explained in more detail using the
example below.

\begin{example}
  Let $\phi \coloneqq \{\, c_1, c_2 \,\}$ be the formula from
  \cref{example:first} with clauses
  \begin{align*}
    c_1 &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\}), \\
    c_2 &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Gamma \,\}).
  \end{align*}
  While GDR is possible on both domains, here we illustrate how it works on
  $\Gamma$. Having chosen a domain, the algorithm iterates over the clauses of
  $\phi$. Suppose \cref{line:forclause} picks $c = c_1$ as the first clause.
  Then, set $V$ is constructed to contain all variables with domain
  $\Omega = \Gamma$ that occur in the literals of clause $c$. In this case,
  $V = \{\, X \,\}$.

  \Cref{line:conditions} iterates over all subsets $W \subseteq V$ of variables
  that can be replaced by a constant without resulting in evidently
  unsatisfiable formulas. We impose two restrictions on $W$. First,
  $W^2 \cap C = \emptyset$ ensures that there are no pairs of variables in $W$
  that are constrained to be distinct, since that would result in an $x \ne x$
  constraint after substitution. Similarly, we want to avoid variables in $W$
  that have inequality constraints with constants: after the substitution, such
  constraints would transform into inequality constraints between two constants.
  In this case, both subsets of $V$ satisfy these conditions, and
  \cref{line:generation} generates two clauses for the output formula:
  \[
    (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z), (X, x) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\}),
  \]
  from $W = \emptyset$ and
  \[
    (\{\, \neg p(x, Y), \neg p(x, Z) \,\}, \{\, (Y, Z) \,\}, \{\, Y \mapsto \Delta, Z \mapsto \Delta \,\})
  \]
  from $W = V$.

  When \cref{line:forclause} picks $c = c_2$, then $V = \{\, X, Z \,\}$. The
  subset $W = V$ fails to satisfy the conditions on \cref{line:conditions}
  because of the $X \ne Z$ constraint. The other three subsets of $V$ all
  generate clauses for $\phi'$. Indeed, $W = \emptyset$ generates
  \[
    (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z), (X, x), (Z, x) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Gamma \,\}),
  \]
  $W = \{\, X \,\}$ generates
  \[
    (\{\, \neg p(x, Y), \neg p(Z, Y) \,\}, \{\, (Z, x) \,\}, \{\, Y \mapsto \Delta, Z \mapsto \Gamma \,\}),
  \]
  and $W = \{\, Z \,\}$ generates
  \[
    (\{\, \neg p(X, Y), \neg p(x, Y) \,\}, \{\, (X, x) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta \,\}).
  \]
\end{example}

\subsubsection{Constraint Removal}\label{sec:cr}

\begin{algorithm}[t]
  \caption{The compilation rule for $\CR$ nodes.}\label{alg:constraintremoval}
  \KwIn{formula $\phi$, set of all relevant domains $\mathcal{D}$}
  \KwOut{set of chips $S$}
  $S \gets \emptyset$\;
  \ForEach{domain $\Omega \in \mathcal{D}$ and element $x \in \Omega$ s.t. $x$ does not occur in any literal of any clause of $\phi$ {\bf and} for each clause $c = (L, C, \delta_c) \in \phi$ and variable $X \in \Vars(c)$, either $\delta_c(X) \ne \Omega$ or $(X, x) \in C$\label{line:crconditions}}{
    add a new domain $\Omega'$ to $\mathcal{D}$\;
    $\phi' \gets \emptyset$\;
    \ForEach{clause $(L, C, \delta) \in \phi$}{
      $C' \gets \{\, (a, b) \in C \mid b \ne x \,\}$\;\label{line:constraintremoval}
      \nosemic$\delta' \gets X \mapsto
      \begin{cases}
        \Omega' & \text{if } \delta(X) = \Omega\\
        \delta(X) & \text{otherwise;}
      \end{cases}$\;\label{line:newdelta}
      $\phi' \gets \phi' \cup \{\, (L, C', \delta') \,\}$\;
    }
    $S \gets S \cup \{\, (\CR_{\Omega \mapsto \Omega'}, \langle\phi'\rangle) \,\}$\;
  }
\end{algorithm}

Recall that GDR on a domain $\Omega$ creates constraints of the form $X_i \ne x$
for some constant $x \in \Omega$ and family of variables $X_i \in \Omega$. Once
certain conditions are satisfied, \cref{alg:constraintremoval} can eliminate
these constraints and replace $\Omega$ with a new domain $\Omega'$, which can be
interpreted as $\Omega \setminus \{\, x \,\}$. These conditions (on
\cref{line:crconditions} of the algorithm) are that a constraint of the form
$X \ne x$ exists for all variables $X \in \Omega$ across all clauses, and such
constraints are the only place where $x$ occurs. The algorithm then proceeds to
construct the new formula by removing constraints (on
\cref{line:constraintremoval}) and constructing a new domain map $\delta'$ that
replaces $\Omega$ with $\Omega'$ (on \cref{line:newdelta}).

\begin{example}
  Let $\phi = \{\, c_1, c_2 \,\}$ be a formula with clauses
  \begin{align*}
    c_1 &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (X, x), (Y, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\}), \\
    c_2 &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, x), (Z, X), (Z, x) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Gamma \,\}).
  \end{align*}
  Domain $\Gamma$ and its element $x \in \Gamma$ satisfy the preconditions for
  CR\@. The rule introduces a new domain $\Gamma'$ and transforms $\phi$ to
  $\phi' = (c_1', c_2')$, where
  \begin{align*}
    c_1' &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto \Gamma', Y \mapsto \Delta, Z \mapsto \Delta \,\}), \\
    c_2' &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (Z, X) \,\}, \{\, X \mapsto \Gamma', Y \mapsto \Delta, Z \mapsto \Gamma' \,\}).
  \end{align*}
\end{example}

\subsubsection{Identifying Opportunities for Recursion}\label{sec:ref}

\paragraph*{Notation.}
First, for partial functions $\alpha, \beta\colon A \pfun B$ s.t.
$\alpha|_{\dom(\alpha) \cap \dom(\beta)} = \beta|_{\dom(\alpha) \cap \dom(\beta)}$,
we write $\alpha \cup \beta$ for the unique partial function s.t.
$\alpha \cup \beta|_{\dom(\alpha)} = \alpha$, and
$\alpha \cup \beta|_{\dom(\beta)} = \beta$. Second, let $\Doms$ be a function
that maps any clause or formula to the set of domains used within. Specifically,
$\Doms(c) \coloneqq \Imm \delta_c$ for any clause $c$, and
$\Doms(\phi) \coloneqq \bigcup_{c \in \phi} \Doms(c)$ for any formula $\phi$.
Third, for any clause $c = (L, C, \delta_c)$, bijection
$\beta\colon \Vars(c) \twoheadrightarrowtail V$ (for some set of variables $V$),
and function $\gamma\colon \Doms(c) \to \mathcal{D}$, let $c[\beta, \gamma] = d$
be the clause $c$ with all occurrences of any variable $X \in \Vars(c)$ in $L$
and $C$ replaced with $\beta(X)$ (so $\Vars(d) = V$) and
$\delta_d\colon V \to \mathcal{D}$ defined as
$\delta_d \coloneqq \gamma \circ \delta_c \circ \beta^{-1}$. In other words,
$\delta_d$ is the unique function that makes
\[
  \begin{tikzcd}
    \Vars(c) \ar[r, tail, two heads, "\beta"] \arrow[d, swap, "\delta_c"] & V = \Vars(d) \ar[d, dashed, "\exists!\delta_d"] \\
    \Doms(c) \ar[r, swap, "\gamma"] & \mathcal{D}
  \end{tikzcd}
\]
commute. For example, if clause
\[
  c_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\})
\]
is as in \cref{example:first}, then
\begin{multline*}
  c_1[\{\, X \mapsto A, Y \mapsto B, Z \mapsto C \,\}, \{\, \Gamma \mapsto \Delta, \Delta \mapsto \Lambda \,\}] = \\
  (\{\, \neg p(A, B), \neg p(A, C) \,\}, \{\, (B, C) \,\}, \{\, A \mapsto \Delta, B \mapsto \Lambda, C \mapsto \Lambda \,\}).
\end{multline*}

% Everything Else

\begin{algorithm}[t]
  \caption{The compilation rule for $\Reff$ nodes.}\label{alg:trycache}
  \KwIn{formula $\phi$, cache $C$}
  \KwOut{a set of chips}

  \ForAll{pairs of formulas and nodes $(\psi, v) \in C(\#\phi)$}{
    $\rho \gets \identifyRecursion{$\phi$, $\psi$}$\;
    \lIf{$\rho \ne {\normalfont \texttt{null}}$}{\Return{$\{\, (\Reff_\rho(v), \langle\rangle) \,\}$}}
  }
  \Return{$\emptyset$}\;

  \Fn{\identifyRecursion{formula $\phi$, formula $\psi$, map $\rho = \emptyset$}}{
    \lIf{$|\phi| \ne |\psi|$ {\bf or} $\#\phi \ne \#\psi$}{\Return{\normalfont\texttt{null}}}
    \lIf{$\phi = \emptyset$}{\Return{$\rho$}}
    \ForEach{clause $c \in \psi$\label{line:for1}}{
      \ForEach{clause $d \in \phi$ s.t. $\#d=\#c$\label{line:for2}}{
        \ForAll{$(\beta, \gamma) \in \generateMaps{$c$, $d$, $\rho$}$ s.t. $c[\beta, \gamma] = d$\label{line:generateMaps}}{
          $\rho' \gets \identifyRecursion{$\phi\setminus\{\, d \,\}$, $\psi\setminus\{\, c \,\}$, $\rho\cup\gamma$}$\;\label{line:recursion}
          \lIf{$\rho' \ne {\normalfont \texttt{null}}$}{\Return{$\rho'$}}
        }
      }
      \Return{\normalfont\texttt{null}}\;
    }
  }

  \Fn{\generateMaps{clause $c$, clause $d$, map $\rho$}}{
    \ForEach{bijection $\beta\colon \Vars(c) \twoheadrightarrowtail \Vars(d)$\label{line:bijection}}{
      $\gamma \gets \constructDomainMap{$\Vars(c)$, $\delta_c$, $\delta_d$, $\beta$, $\rho$}$\;
      \lIf{$\gamma \ne {\normalfont \texttt{null}}$}{\KwRet{$(\beta, \gamma)$}}
    }
  }

  \Fn{\constructDomainMap{set of variables $V$, maps $\delta_c$, $\delta_d$, $\beta$, $\rho$}}{
    $\gamma \gets \emptyset$\;
    \ForEach{variable $X \in V$}{
      \lIf{$\delta_c(X) \in \dom(\rho)$ {\bf and} $\rho(\delta_c(X)) \ne \delta_d(\beta(X))$}{\Return{\normalfont\texttt{null}}}
      \lIf{$\delta_c(X) \not\in \dom(\gamma)$}{$\gamma \gets \gamma \cup \{\, \delta_c(X) \mapsto \delta_d(\beta(X)) \,\}$}
      \lElseIf{$\gamma(\delta_c(X)) \ne \delta_d(\beta(X))$}{\Return{\normalfont\texttt{null}}}
    }
    \Return{$\gamma$}\;
  }
\end{algorithm}

% Cache $C$ is used to partition all previously-encountered formulas based on
% their hash codes.
\Cref{alg:trycache} describes the compilation rule for creating $\Reff$ nodes.
For every formula $\psi$ s.t. $\#\psi = \#\phi$ that we have encountered so far,
function \texttt{identifyRecursion} is called to check whether a recursive call
is feasible. If it is, the function returns a (total) map
$\rho\colon \Doms(\psi) \to \Doms(\phi)$ that shows how $\psi$ can be
transformed into $\phi$ by replacing each domain $\Omega \in \Doms(\psi)$ with
$\rho(\Omega) \in \Doms(\phi)$. Otherwise, \texttt{identifyRecursion} returns
\texttt{null} to signify that $\phi$ and $\psi$ are too different for recursion
to work. This happens if $\phi$ and $\psi$ (or their subformulas explored in
recursive calls) are structurally different (i.e., the numbers of clauses or the
hash codes fail to match) or if a clause of $\psi$ cannot be paired with a
sufficiently similar clause of $\phi$.

Function \texttt{identifyRecursion} iterates over pairs of clauses of $\phi$ and
$\psi$ that have the same hash codes. It uses the function \texttt{generateMaps}
to check whether the two clauses are sufficiently similar. If so, the function
calls itself on the remaining clauses until the map
$\rho\colon \Doms(\psi) \pfun \Doms(\phi)$ becomes total, and all clauses are
successfully coupled.

Given two clauses $c \in \psi$ and $d \in \phi$, \texttt{generateMaps} considers
all possible bijections\footnote{Although the number of bijections between two
  sets of cardinality $n$ is $n!$, this part of the algorithm is unlikely to
  cause performance issues for two reasons. First, in practice, $n$ is usually
  at most two or three. Second, due to how formulas are modified by compilation
  rules, if any bijection results in a successfully identified recursive
  relationship, it is almost always the identity bijection.}
$\beta\colon \Vars(c) \twoheadrightarrowtail \Vars(d)$ and calls
\texttt{constructDomainMap}, which then attempts to construct a map
$\gamma\colon \Doms(c) \to \Doms(d)$ consistent with both $\beta$ and (the as
yet partial map) $\rho\colon \Doms(\psi) \pfun \Doms(\phi)$. The \textbf{yield}
keyword in \texttt{generateMaps} works as in programming languages such as C\#,
JavaScript, and Python, and lazily returns a sequence of values, computing each
element of the sequence as needed.

Diagrammatically, \texttt{constructDomainMap} attempts to find a
$\gamma\colon \Doms(c) \to \Doms(d)$ s.t.
\begin{equation}\label[diagram]{eq:commute}
  \begin{tikzcd}
    V = \Vars(c) \ar[r, tail, two heads, "\beta"] \arrow[d, swap, "\delta_c"] & \Vars(d) \ar[d, "\delta_d"] \\
    \Doms(c) \ar[r, dashed, "\gamma"] \ar[d, hookrightarrow] & \Doms(d) \ar[d, hookrightarrow] \\
    \Doms(\psi) \ar[r, swap, "\rho", "|" marking, outer sep=5pt] & \Doms(\phi).
  \end{tikzcd}
\end{equation}
commutes (and returns \texttt{null} if such a function does not exist). Indeed,
for every variable in $V = \Vars(c)$, the function returns \texttt{null} if
either the top rectangle from $V$ to $\Doms(d)$ or the outer rectangle from $V$
to $\Doms(\phi)$ fails to commute. These checks also ensure that
$\rho \cup \gamma$ is possible on \cref{line:recursion} of the algorithm, i.e.,
$\rho|_{\dom(\rho)\cap\dom(\gamma)} = \gamma|_{\dom(\rho)\cap\dom(\gamma)}$.

\begin{example}\label{example}

  % definitions of formulas and intro
  As in \cref{example:first}, let $\psi \coloneqq \{\, c_1, c_2 \,\}$ be a
  formula with clauses
  \begin{align*}
    c_1 &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\}), \\
    c_2 &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Gamma \,\}).
  \end{align*}
  Let formula
  $\phi \coloneqq \psi[\id, \{\, \Gamma \mapsto \Gamma', \Delta \mapsto \Delta^\bot \,\}]$
  be just like $\psi$ but with different domains. In other words,
  $\phi = \{\, d_1, d_2 \,\}$, where
  \begin{align*}
    d_1 &\coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto \Gamma', Y \mapsto \Delta^\bot, Z \mapsto \Delta^\bot \,\}),\\
    d_2 &\coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto \Gamma', Y \mapsto \Delta^\bot, Z \mapsto \Gamma' \,\}).
  \end{align*}
  Note that $\#\phi = \#\psi$ and assume that $(\psi, v) \in C(\#\phi)$ for some
  node $v$. We shall see how \cref{alg:trycache} identifies that the FCG for
  $\psi$ can be reused for $\phi$ as well.

  Since both formulas are non-empty, the algorithm proceeds with the for-loops
  on \cref{line:for1,line:for2,line:generateMaps}. Suppose $c = c_1$ and
  $d = d_1$ get picked. Since both clauses have three variables, in the worst
  case, function \texttt{generateMaps} would have $3!=6$ bijections to check.
  Suppose the identity bijection is picked first. Then
  \texttt{constructDomainMap} is called with the following parameters:
  \begin{itemize}
    \item $V = \{\, X, Y, Z \,\}$,
    \item
          $\delta_c = \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Delta \,\}$,
    \item
          $\delta_d = \{\, X \mapsto \Gamma', Y \mapsto \Delta^\bot, Z \mapsto \Delta^\bot \,\}$,
    \item $\beta = \id = \{\, X \mapsto X, Y \mapsto Y, Z \mapsto Z \,\}$,
    \item $\rho = \emptyset$.
  \end{itemize}
  Since $\delta_c(Y) = \delta_c(Z)$, and $\delta_d(Y) = \delta_d(Z)$,
  \texttt{constructDomainMap} returns
  $\gamma = \{\, \Gamma \mapsto \Gamma', \Delta \mapsto \Delta^\bot \,\}$. Thus,
  \texttt{generateMaps} yields its first pair of maps $(\beta, \gamma)$ to
  \cref{line:generateMaps}. Furthermore, this pair satisfies
  $c[\beta, \gamma] = d$. On \cref{line:recursion}, a recursive call to
  \texttt{identifyRecursion($\{\,c_2\,\}$, $\{\,d_2\,\}$, $\gamma$)} is made.

  In this subproblem where both formulas are left with a single clause each,
  again we have two non-empty formulas with equal hash codes. Thus
  \texttt{generateMaps} is called with $c = c_2$, $d = d_2$, and
  $\rho = \{\, \Gamma \mapsto \Gamma', \Delta \mapsto \Delta^\bot \,\}$. Suppose
  \cref{line:bijection} picks the identity bijection gain. Then
  \texttt{constructDomainMap} is called with the following parameters:
  \begin{itemize}
    \item $V = \{\, X, Y, Z \,\}$,
    \item
          $\delta_c = \{\, X \mapsto \Gamma, Y \mapsto \Delta, Z \mapsto \Gamma \,\}$,
    \item
          $\delta_d = \{\, X \mapsto \Gamma', Y \mapsto \Delta^\bot, Z \mapsto \Gamma' \,\}$,
    \item $\beta = \id = \{\, X \mapsto X, Y \mapsto Y, Z \mapsto Z \,\}$,
    \item $\rho = \{\, \Gamma \mapsto \Gamma', \Delta \mapsto \Delta^\bot \,\}$.
  \end{itemize}
  Since $\beta$ and $\rho$ commute (as in \cref{eq:commute}), and there are no
  new domains in $\Doms(c)$ and $\Doms(d)$, $\gamma$ exists and is equal to
  $\rho$. Again, the returned pair $(\beta, \gamma)$ satisfies
  $c[\beta, \gamma] = d$. \Cref{line:recursion} calls
  \texttt{identifyRecursion($\emptyset$, $\emptyset$, $\rho$)}, which
  immediately returns
  $\rho = \{\, \Gamma \mapsto \Gamma', \Delta \mapsto \Delta^\bot \,\}$ as the
  final answer. Therefore, one can indeed reuse an FCG for $\psi$ to compute the
  model count of $\phi$.
\end{example}

\subsection{Compilation as Search}\label{sec:search}

% intro
Given a formula $\phi$, we want to find an FCG that encodes a way to compute the
model count of $\phi$. While \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11} uses greedy search, \textsc{Crane}
has a new search algorithm---a combination of greedy and breadth-first search.

% greedy and non-greedy rules
We split all compilation rules into \emph{greedy} and \emph{non-greedy}. Greedy
rules represent indisputable choices in the compilation process. They are
applied to each encountered formula as soon and as many times as possible (in a
predefined order). Most rules are greedy, i.e., those that produce a sink node
with no leftover formula, those that simplify the formula without changing the
FCG, and those that split the formula into parts that can be solved
independently. The CR rule described in \cref{sec:cr} is greedy. On the other
hand, non-greedy rules signify uncertain choices that we may want to retract.
They also correspond to edges in the implicit search tree; thus, the first
solution found by the search algorithm always has the fewest applications of
non-greedy rules. These rules include the $\GDR$ and $\Reff$ rules described in
\cref{sec:dr,sec:ref}, respectively, and some rules from previous work
\citep{DBLP:conf/ijcai/BroeckTMDR11} such as atom counting, inclusion-exclusion,
independent partial grounding, and shattering.

% states and actions
Search can be conceptualised as traversing a directed graph composed of states
and actions that lead from one state to the next. We define a \emph{state} as a
triple $(G, L, C)$, where $(G, L)$ is a chip, and $C$ is a cache. The actions
that can be taken in such a state are applications of compilation rules that
remove the first formula from $L$ and potentially add something to $G$, $L$, and
$C$.

\begin{algorithm}[t]
  \caption{The (main part of the) search algorithm.}\label{alg:search}
  \KwIn{a formula $\phi_0$}
  \KwResult{all found FCGs for $\phi_0$ are in set $S$} $S \gets \emptyset$\;
  $(G_0, L_0, C_{0}) \gets \applyGreedyRules{$\phi_0$, $\emptyset$}$\;\label{line:greedy}
  \lIf{$L_0 = \langle\rangle$}{$S \gets \{\, G_0 \,\}$}
  \Else{
    $q \gets \text{a empty queue of states}$\;\label{line:q1}
    $q.\put{$ (G_0, L_0, C_0) $}$\;\label{line:q2}
    \While{{\bf not} $q.\emptyy{}$\label{line:while}}{
      \ForEach{state $(G, L, C) \in \applyAllRules{$q.\get{}$}$}{
        \lIf{$L = \langle\rangle$}{$S \gets S \cup \{\, G \,\}$}
        \lElse{$q.\put{$ (G, L, C) $}$}
      }
    }
  }
\end{algorithm}

\begin{algorithm}[t]
  \caption{The function for applying non-greedy rules.}\label{alg:applyallrules}
  \Fn{\applyAllRules{state $s = (G, L, C)$}}{
    $(G', L', C') \gets \text{a copy of } s$\;
    $\phi : T \gets L$\tcc*{separate the first formula from the rest}\label{line:separate}
    \ForEach{non-greedy rule $r$}{
      \ForEach{chip $(G'', L'') \in r(\phi)$}{
        \lIf{$G'' = \star$}{\KwRet{\applyAllRules{$(G', L'' \mdoubleplus T, C')$}}}\label{line:nullfcg}
        \Else{
          $C' \gets \updateCache{$C'$, $\phi$, $G''$}$\;
          $(G'', L'', C') \gets \applyGreedyRulesToFormulas{$G''$, $L''$, $C'$}$\;
          \KwRet{$(\mergeFcgs{$G'$, $G''$}, C', L'' \mdoubleplus T)$}\;
        }
      }
      $(G', L', C') \gets \text{a copy of } s$\;
    }
  }
\end{algorithm}

\begin{algorithm}[t]
  \captionsetup{singlelinecheck=off}
  \caption[Helper functions that apply greedy rules to a single formula and all formulas in a state.]{Helper functions that apply greedy rules to
    \begin{enumerate*}[label=\alph*)]
    \item a single formula and
    \item all uncompiled formulas in a state.
    \end{enumerate*}
  }\label{alg:apply}

  \Fn{\applyGreedyRules{formula $\phi$, cache $C$}}{
    \ForEach{greedy rule $r$ s.t. $r(\phi) \ne \emptyset$}{
      $(G, L) \gets \text{the only chip in } r(\phi)$\;
      \lIf{$G = \star$}{\Return{\applyGreedyRules{the formula in $L$, $C$}}}
      \Return{\applyGreedyRulesToFormulas{$G$, $L$, \updateCache{$C$, $\phi$, $G$}}}\;\label{line:callgreedy}
    }
    \Return{$(\star, \langle\phi\rangle, C)$}\;
  }

  \Fn{\applyGreedyRulesToFormulas{$(V, s, N^+, \tau)$, list $L$, cache $C$}}{
    \lIf{$L = \langle\rangle$}{\Return{$((V, s, N^+, \tau), L, C)$}}
    $L' \gets \langle\rangle$\;
    \ForEach{formula $\phi \in L$}{
      $(G', L'', C) \gets \applyGreedyRules{$\phi$, $C$}$\;
      $L' \gets L' \mdoubleplus L''$\;
      \If{$G' = (V', s', N', \tau') \ne \star$}{
        $(V, N^{+}, \tau) \gets (V \cup V', N^{+} \cup N', \tau \cup \tau')$\;\label{line:cup}
        replace the corresponding $\star$ in $N^{+}(s)$ with $s'$\;
      }
    }
    \Return{$((V, s, N^+, \tau), L', C)$}\;
  }
\end{algorithm}

\begin{algorithm}[t]
  \caption{Helper functions for updating a cache and merging
    FCGs.}\label{alg:helpers}
  \Fn{\updateCache{cache $C$, formula $\phi$, FCG $(V, s, N^+, \tau)$}}{
    \lIf{$\tau(s) = \textsc{Ref}$}{\Return{$C$}}
    \lIf{$\#\phi \not\in \dom(C)$}{\Return{$C \cup \{\, \#\phi \mapsto (\phi, s) \,\}$}}
    \lIf{there is no $(\phi', v) \in C(\#\phi)$ s.t. $v = s$}{$C(\#\phi) \gets \langle(\phi, s)\rangle \mdoubleplus C(\#\phi)$}
    \Return{$C$}\;
  }

  \Fn{\mergeFcgs{$G = (V, s, N^+, \tau)$, $G' = (V', s', N', \tau')$, $r = s$}}{
    \lIf{$G = \star$}{\Return{$G'$}}
    \lIf{$\tau(r) = \textsc{Ref}$}{\Return{\normalfont\texttt{null}}}
    \ForEach{$t \in N^+(r)$}{
      \If{$\tau(t) = \star$}{
        replace $t$ with $s'$ in $N^+(r)$\;
        \Return{$(V \cup V', s, N^+ \cup N', \tau \cup \tau')$}\;
      }
      $G'' \gets \mergeFcgs{$G$, $G'$, $t$}$\;
      \lIf{$G'' \ne {\normalfont \texttt{null}}$}{\Return{$G''$}}
    }
    \Return{\normalfont\texttt{null}}\;
  }
\end{algorithm}

The search algorithm is described as
\cref{alg:search,alg:applyallrules,alg:apply,alg:helpers}, with the main
procedure in \cref{alg:search}. Since for most formulas we find several FCGs (of
various complexities), the algorithm maintains a set $S$ of found solutions,
i.e., complete FCGs. We begin by applying all suitable greedy rules on
\cref{line:greedy}. If greedy rules are enough to find a complete FCG, the
algorithm stops. Otherwise, \cref{line:q1,line:q2} set up a queue for
breadth-first search. The algorithm continues to take a state from the queue,
call \texttt{applyAllRules} on it, and place the resulting states back on the
queue while filtering out complete FCGs and adding them to $S$ instead. Since
GDR can be applied to almost all formulas, the search is infinite. In our
implementation, we stop searching when one of the following conditions is
satisfied:
\begin{enumerate*}[label=(\emph{\alph*})]
  \item the desired number of solutions is found,
  \item the search tree reaches a certain height, or
  \item the algorithm times out.
\end{enumerate*}

Function \texttt{applyAllRules} (see \cref{alg:applyallrules}) takes a state and
generates a sequence of new states created by applying one non-greedy rule
followed by all applicable greedy rules. We assume that the input state contains
at least one formula (otherwise it would be a complete solution) and that all
applicable greedy rules have already been applied. The algorithm iterates over
all non-greedy rules and all chips generated by these rules when applied to
$\phi$. If the FCG is $\star$, then $|L''| = 1$, and $L''$ contains a modified
version of $\phi$---in this case, we rerun \texttt{applyAllRules} on the same
state but with the updated formula. Otherwise, we update the cache, call another
function to apply greedy rules, and merge $(G'', L'')$ with a copy of the input
state. In doing so, $\phi$ is replaced by $L''$, preserving the implicit
bijection between the ordering of the list and the structure of $\star$'s in the
FCG\@.

\Cref{alg:apply} defines two functions that work together to handle the
application of greedy rules. Function \texttt{applyGreedyRules} takes a formula
and returns the maximal chip that can be constructed by the application of
greedy rules (and updates the cache whenever the application of a rule results
in a new node). The implementation of this function is simplified by three
assumptions about greedy rules. First, we assume that greedy rules can be
applied in any order. Second, we assume that the set of chips returned by a
greedy rule has at most one element. Third, if a rule returns an empty FCG,
i.e., $G = \star$, then $L$ has exactly one formula, i.e., the rule simply
transforms the input formula. In such a case, we continue the application of
greedy rules to the new formula. Otherwise, \cref{line:callgreedy} updates the
cache and calls the second function in \cref{alg:apply},
\texttt{applyGreedyRulesToFormulas}, on the new chip $(G, L)$ that has $|L|$ new
formulas that could benefit from greedy rules. Finally, if none of the greedy
rules is applicable, \texttt{applyGreedyRules} returns the same formula $\phi$
formatted as a state. Function \texttt{applyGreedyRulesToFormulas} takes a state
and updates it by running \texttt{applyGreedyRules} on all formulas in $L$ and
incorporating the resulting chips as direct successors of the source node $s$.
Hence, we assume that the input FCG (which comes directly from applying a single
greedy rule) has just one non-$\star$ node, $s$, and $N^+(s)$ contains exactly
$|L|$ $\star$'s.

% If the chip is complete, return the state as-is.
% Otherwise, we apply greedy rules to the formulas in $L$, incorporating each
% resulting state into the input state.
% In particular, we replace the formulas in $L$ with the formulas returned by
% greedy rules. Furthermore, each FCG returned by \texttt{applyGreedyRules} is
% connected to the input FCG by drawing an edge from $s$ to $s'$ and copying over
% all nodes, edges, and labels.

Finally, \cref{alg:helpers} describes two helper functions: \texttt{updCache}
for updating the cache and \texttt{mergeFcgs} for merging two FCGs. Note that
$\Reff$ nodes are not placed in the cache because the relation identified by the
compilation rule for $\Reff$ (see \cref{alg:trycache}) is transitive. In other
words, instead of calling a function $f(\mathbf{n}) \coloneqq g(\mathbf{m})$
(where $\mathbf{n}$ and $\mathbf{m}$ are integer parameter vectors, and
$\mathbf{m}$ is constructed from $\mathbf{n}$), we can always directly call
function $g$. Function \texttt{mergeFcgs} finds a $\star$ in $G$ and replaces it
with $G'$. Note that the order in which the nodes of $G$ are visited must be the
pre-order traversal of the underlying tree of $G$. Hence, the algorithm skips
$\Reff$ nodes and, for each directed edge, considers the source before
considering the target. Parameter $r$, initially set to the source of $G$, keeps
track of the root of the subtree that needs to be explored. Recursive calls
return \texttt{null} if there are no $\star$'s in the subtree rooted at $r$.
However, we only call \texttt{mergeFcgs} with $G$'s that have at least one
$\star$, so the return value of the initial call to the function is never
\texttt{null}.

\begin{claim}\label{claim:recursion}
  Using the new compilation rules and search algorithm, \textsc{Crane} is able
  to construct an FCG for the problem of counting partial injections described
  in \cref{example:first}. Moreover, this FCG encodes a solution that can be
  evaluated in $\Theta(mn)$ time, where $m = |\Gamma|$ and $n = |\Delta|$.
\end{claim}

In \cref{sec:results}, we provide experimental evidence that proves
\cref{claim:recursion} as well as similar results on some other
function-counting problems. None of the previous (W)FOMC algorithms
\citep{DBLP:conf/ijcai/BroeckTMDR11,DBLP:journals/cacm/GogateD16,DBLP:conf/kr/KazemiP16}
can solve these newly liftable instances.

\section{How to Interpret an FCG}\label{sec:interpret}

When \textsc{ForcLift} \citep{DBLP:conf/ijcai/BroeckTMDR11} compiles a WFOMC
instance into a circuit, each node type encodes an arithmetic operation on its
inputs and parameters. These operations are then immediately performed while
traversing the circuit and using domain sizes and weights as the initial inputs.
With \textsc{Crane}, the interpretation of an FCG is a collection of functions.
Each function has (some) domain sizes as parameters and may contain recursive
calls to other functions, including itself. While there may be any number of
subsidiary functions, there is always one main function that can be called with
the sizes of the domains of the input formula as arguments. Henceforth, this
function is always called $f$, and it is defined by the source node.

The interpretation of a node is decided by its type. Here we describe the
interpretations of new (or significantly changed) types and refer the reader to
previous work \citep{DBLP:conf/ijcai/BroeckTMDR11} for information on other
types. Both $\CR$ and $\GDR$ nodes do not contribute anything to the definitions
of functions---the interpretation of such a node is simply the interpretation of
its only direct successor. Obviously, $\star$ nodes also have no interpretation,
although for a different reason: incomplete FCGs are not meant to be
interpreted. The interpretation of a $\Reff$ node is a function call. The direct
successor of the $\Reff$ node (say, $v$) then must introduce a function. The
parameters of this function are the sizes of all domains used by nodes reachable
from $v$.

\begin{example}\label{example:interpretation}
  Consider the FCG from \cref{fig:examplefcg}. The input formula (i.e., the
  formula from \cref{example:first}) has two domains: $\Gamma$ and $\Delta$.
  Thus, the interpretation of the FCG is a function
  $f\colon \mathbb{N}_{0} \times \mathbb{N}_{0} \to \mathbb{R}_{\ge 0}$. Let
  $m \coloneqq |\Gamma|$, and $n \coloneqq |\Delta|$. The node labelled
  $\bigvee_{\Delta^{\top} \subseteq \Delta}$ tells us that
  $f(m, n) = \sum_{l = 0}^{n} \binom{n}{l} \square$, where $\square$ is the
  interpretation of the remaining subgraph, and $l$ iterates over all possible
  sizes of $\Delta^{\top}$. It also creates two subdomains
  $\Delta^{\top}, \Delta^{\bot} \subseteq \Delta$ that partition $\Delta$, i.e.,
  as the size of $\Delta^{\top}$ increases, the size of $\Delta^{\bot}$
  correspondingly decreases. Nodes labelled $\land$ correspond to
  multiplication. Therefore,
  $f(m, n) = \sum_{l = 0}^{n} \binom{n}{l} \diamondsuit \times \heartsuit$,
  where $\diamondsuit$ is the interpretation of the contradiction (i.e., $\bot$)
  node, and $\heartsuit$ is the interpretation of the $\Reff$ node.

  A contradiction node with clause $c$ as a parameter is interpreted as one if
  the clause has groundings and zero otherwise. In this case,
  $c = (\emptyset, \{\, (X, Y) \,\}, \{\, X \mapsto \Delta^\top, Y \mapsto \Delta^\top \,\})$,
  which can be read as $\forall X, Y \in \Delta^{\top}\text{. }X \ne Y \implies \bot$, i.e., $\forall X, Y \in \Delta^{\top}\text{. }X = Y$. This
  latter sentence is true if and only if $|\Delta^{\top}| < 2$. Therefore, we can use
  the Iverson bracket notation to write
  \[
    \diamondsuit = [l < 2] \coloneqq
    \begin{cases}
      1 & \text{if } l < 2 \\
      0 & \text{otherwise.}
    \end{cases}
  \]

  It remains to interpret the $\Reff$ node. Parameter
  $\{\, \Gamma \mapsto \Gamma', \Delta \mapsto \Delta^\bot \,\}$ tells us that
  the interpretation of the $\Reff$ node should be the same as that of the
  source node, but with domains $\Gamma$ and $\Delta$ replaced with $\Gamma'$
  and $\Delta^{\bot}$, respectively. Domain $\Gamma'$ was created by the CR rule
  applied on $\Gamma$, so $|\Gamma'| = m - 1$. Now
  $\Delta^{\bot} = \Delta \setminus \Delta^{\top}$, and $|\Delta^{\top}| = l$,
  so $|\Delta^{\bot}| = n - l$. Thus, the interpretation of the $\Reff$ node is
  a recursive call to $f(m - 1, n - l)$. Therefore,
  \begin{equation}\label{eq:solution}
    f(m, n) = \sum_{l = 0}^{n} \binom{n}{l} [l < 2] f(m-1, n-l) = f(m-1, n) + n f(m-1, n-1).
  \end{equation}
  To use this recursive function to compute the model count of the input formula
  for any domain sizes, one just needs to find the base cases $f(0, n)$ and
  $f(m, 0)$ for all $m, n \in \mathbb{N}_{0}$.
\end{example}

\section{Empirical Results}\label{sec:results} % Newly Domain-Liftable Formulas

We compare \textsc{Crane} and \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11} on their ability to count various kinds of
functions. This class of instances is chosen because of its simplicity and
ubiquity and the inability of state-of-the-art WFOMC algorithms to solve many
such instances. Note that other WFOMC algorithms---\textsc{L2C}
\citep{DBLP:conf/kr/KazemiP16} and probabilistic theorem proving
\citep{DBLP:journals/cacm/GogateD16}---are unable to solve any of the instances
that \textsc{ForcLift} fails on. We begin by describing how such
function-counting problems can be expressed in FOL\@. \textsc{ForcLift} then
translates these sentences in FOL to formulas as defined in \cref{def:formula}.

% Describe what kind of instances we're investigating
Let $p \in \Gamma \times \Delta$ be a predicate. To restrict all relations
representable by $p$ to just functions from $\Gamma$ to $\Delta$, in FOL one
might write
\[
  \forall X \in \Gamma\text{. }\forall Y \in \Delta\text{. }\forall Z \in \Delta\text{. }p(X, Y) \land p(X, Z) \implies Y = Z
\]
and
\begin{equation}\label{eq:def2}
  \forall X \in \Gamma\text{. }\exists Y \in \Delta\text{. }p(X, Y).
\end{equation}
The former sentence says that one element of $\Gamma$ can map to at \emph{most}
one element of $\Delta$, and the latter sentence says that each element of
$\Gamma$ must map to at \emph{least} one element of $\Delta$. One can then add
\[
  \forall X,Z \in \Gamma\text{. }\forall Y \in \Delta\text{. }p(X, Y) \land p(Z, Y) \implies X = Z
\]
to restrict $p$ to injections or
\[
  \forall Y \in \Delta\text{. }\exists X \in \Gamma\text{. }p(X, Y)
\]
to ensure surjectivity or remove \cref{eq:def2} to consider partial functions.
Lastly, one can replace all occurrences of $\Delta$ with $\Gamma$ to model
endofunctions (i.e., functions with the same domain and codomain) instead.

% the process: both for running algorithms and for determining complexities
In our experiments, we consider all sixteen combinations of these properties,
i.e., injectivity, surjectivity, partiality, and endo-. \textsc{ForcLift} is
always run until it terminates. \textsc{Crane} is run until either five
solutions are found or the search tree reaches height six.\footnote{The search
  tree has a high branching factor, so exploring all nodes at depth five takes
  at most a few seconds, whereas doing the same for depth six can be
  computationally infeasible in some cases.} If successful, \textsc{ForcLift}
generates a circuit, and \textsc{Crane} generates one or more (complete) FCGs.
In both cases, we manually convert the resulting graphs into definitions of
functions as described in \cref{sec:interpret}. We then assess the complexity of
each solution and pick the best if \textsc{Crane} returns several solutions of
varying complexities. When assessing the complexity of each such definition, we
make two assumptions. First, we can compute the binomial coefficient
$\binom{n}{k}$ in $\Theta(nk)$ time. Second, techniques such as dynamic
programming and memoization are used to avoid recomputing the same binomial
coefficient or function call multiple times.

\begin{table}[t]
  \centering
  \begin{tabular}{cccccc}
    \toprule
    \multicolumn{3}{c}{Function Class} & \multicolumn{3}{c}{Asymptotic Complexity of Counting} \\
    Partial & Endo- & Class & Best Known & With \textsc{ForcLift} & With \textsc{Crane} \\
    \midrule
    \rowcolor{gray!25}\cmark/\xmark & \cmark/\xmark & Functions & $\log m$ & $m$ & $m$ \\
    \xmark & \xmark & \multirow{4}{*}{Surjections} & $n \log m$ & $m^{3}+n^{3}$ & $m^{3}+n^{3}$ \\
    \xmark & \cmark & & $m \log m$ & $m^{3}$ & $m^{3}$ \\
    \cmark & \xmark & & \multicolumn{3}{c}{Same as injections from $\Delta$ to $\Gamma$} \\
    \cmark & \cmark & & \multicolumn{3}{c}{Same as endo-injections} \\
    \rowcolor{gray!25}\xmark & \xmark & & $m$ & --- & $mn$ \\
    \rowcolor{gray!25}\xmark & \cmark & & $m$ & --- & $m^3$ \\
    \rowcolor{gray!25}\cmark & \xmark & & $\min\{\, m, n \,\}^2$ & --- & $mn$ \\
    \rowcolor{gray!25}\cmark & \cmark & \multirow{-4}{*}{Injections} & $m^2$ & --- & --- \\
    \xmark & \xmark & \multirow{3}{*}{Bijections} & $m$ & --- & $m$ \\
    \xmark & \cmark & & \multicolumn{3}{c}{\multirow{2}{*}{Same as (partial) (endo-)injections}} \\
    \cmark & \cmark/\xmark & & \multicolumn{3}{c}{} \\
    \bottomrule
  \end{tabular}
  \caption{The worst-case complexity of counting various types of functions.
    Here, $m$ is the size of domain $\Gamma$, and $n$ is the size of domain
    $\Delta$. All asymptotic complexities are in $\Theta(\cdot)$. A dash means
    that no complete solution was found.}\label{tbl:results}
\end{table}

The experimental results are in \cref{tbl:results}. Previous work often compares
WFOMC algorithms by running them on a few instances with increasing domain sizes
and measuring runtime
\citep{DBLP:conf/nips/Broeck11,DBLP:conf/ijcai/BroeckTMDR11,DBLP:conf/aaai/BroeckD12}.
However, we can do better than that and identify the exact worst-case asymptotic
complexity of a solution produced by either \textsc{Crane} or \textsc{ForcLift}.
The best-known asymptotic complexity for computing total surjections is by
\citet{30049}. All other best-known complexity results are inferred from the
formulas and programs on the on-line encyclopedia of integer sequences
\citep{oeis}. On instances that could already be solved by \textsc{ForcLift},
the two algorithms perform equally well. However, \textsc{Crane} can also solve
all but one instances that \textsc{ForcLift} fails on in at most cubic time.

Let us examine the case of counting partial (non-endomorphic) injections more
closely. The FCG in \cref{fig:examplefcg,example:interpretation} counts partial
injections and is responsible for the $mn$ entry in the table. For a complete
solution, \cref{eq:solution} must be combined with the base case $f(0, n) = 1$
for all $n \in \mathbb{N}_{0}$. This base case says that the empty partial map
is the only partial injection with an empty domain. Finally, note that $f(m, n)$
can be evaluated in $\Theta(mn)$ time by a dynamic programming algorithm that
computes $f(i, j)$ for all $i = 0, \dots, m$ and $j = 0, \dots, n$.

\section{Conclusion and Future Work}

% A summary of what's been done/achieved and how

In this chapter, we showed how a state-of-the-art (W)FOMC algorithm can be
empowered by generalising domain recursion and adding support for cycles in the
graph that encodes a solution. To construct such graphs, \textsc{Crane}
supplements \textsc{ForcLift} \citep{DBLP:conf/ijcai/BroeckTMDR11} with three
new compilation rules and a hybrid search algorithm. Our experiments revealed a
range of counting problems that are liftable to \textsc{Crane} but not to any
other (W)FOMC algorithm. The common thread across these newly liftable problems
is (partial) injectivity. Thus, we can formulate the following conjecture.

\begin{conjecture}
  Let \IFO{} be the class of formulas in FOL that contain clauses with at most
  two variables as well as any number of copies of
  \begin{align*}
    (\forall X \in \Gamma\text{. }\forall Y \in \Delta\text{. }\forall Z \in \Delta\text{. }Y \ne Z &\implies \neg p(X, Y) \lor \neg p(X, Z)) \land \\
    (\forall X \in \Gamma\text{. }\forall Y \in \Delta\text{. }\forall Z \in \Gamma\text{. }X \ne Z &\implies \neg p(X, Y) \lor \neg p(Z, Y))
  \end{align*}
  for some predicate $p$ and domains $\Gamma$ and $\Delta$. Then \IFO{} is
  liftable by \textsc{Crane}.
\end{conjecture}

Recall that \Ctwo{} is the class of formulas with counting quantifiers and at
most two variables. \Ctwo{} was recently shown to be liftable
\citep{DBLP:journals/jair/Kuzelka21} but without providing a usable (W)FOMC
algorithm. Since the tasks of counting injections and bijections fall into the
\Ctwo{} fragment, we can conjecture the following.

\begin{conjecture}
  \Ctwo{} is liftable by \textsc{Crane} by either reformulating formulas in
  \Ctwo{} to avoid counting quantifiers or extending \textsc{Crane} to support
  them.
\end{conjecture}

An idea pivotal to our work is the generalisation of circuits to graphs. Despite
the wide variety of circuits that are used in artificial intelligence
\citep{DBLP:series/faia/Darwiche21}, this is the first time that the addition of
cycles is shown to make a class of circuits more powerful. An important strand
for future work is in developing an algorithm that learns FCGs from data
similarly to the way \textsc{ForcLift} has been utilised in learning Markov
logic networks \citep{DBLP:conf/aaai/BroeckMD13,DBLP:journals/ml/HaarenBMD16}.
One could also consider whether some of the many recent applications of circuits
are suitable for FCGs as well. These applications include the verification and
explainability of neural networks \citep{DBLP:conf/pods/Darwiche20}, causal
inference \citep{DBLP:journals/corr/abs-2202-02891}, computing the expectations
of kernel functions \citep{DBLP:conf/uai/LiZVB21}, and variational inference in
discrete graphical models \citep{DBLP:conf/nips/ShihE20}.

However, the most important direction for future work is to fully automate this
new way of computing the (W)FOMC of a formula. First, we need an algorithm that
transforms FCGs into definitions of functions. Formalising this process would
also allow us to prove the correctness of the new compilation rules in
constructing FCGs that indeed compute the right WMC\@. Second, these definitions
must be simplified before they can be used, perhaps by a computer algebra
system. Third, most importantly, we need a way to find the base cases for the
recursive definitions provided by \textsc{Crane}. Fourth, since the first
solution found by \textsc{Crane} is not always optimal in terms of its
complexity, an automated way to determine the asymptotic complexity of a
solution would be helpful as well. Achieving these goals would make
\textsc{Crane} capable of automatically constructing efficient ways to compute a
function (e.g., a sequence) of interest. In addition to the potential impact on
areas of artificial intelligence (AI) such as statistical relational AI
\citep{DBLP:series/synthesis/2016Raedt}, \textsc{Crane} could be beneficial to
research in combinatorics as well \citep{DBLP:conf/ilp/BarvinekB0ZK21}.

% What makes this problem non-trivial is that the number of base cases is not
% constant for functions of arity greater than one (i.e., formulas that mention
% more than one domain). On the other hand, assuming that a domain is empty can
% greatly simplify a problem.
