\SetKw{KwRet}{yield}
\SetKwProg{Fn}{Function}{:}{}

\SetKwData{solutions}{solutions}

\SetKwFunction{applyAllRules}{applyAllRules}
\SetKwFunction{applyGreedyRules}{applyGreedyRules}
\SetKwFunction{applyGreedyRulesToAllFormulas}{applyGreedyRulesToFormulas}

\SetKwFunction{emptyy}{empty}
\SetKwFunction{get}{get}
\SetKwFunction{put}{put}

\SetKwFunction{constructDomainMap}{constructDomainMap}
\SetKwFunction{identifyRecursion}{identifyRecursion}
\SetKwFunction{generateMaps}{generateMaps}
\SetKwFunction{mergeFcgs}{mergeFcgs}
\SetKwFunction{updateCache}{updCache}

\chapter{Recursive Solutions to FOMC} \label{chapter:wfomc}

\paragraph{Abstract.}
First-order model counting (FOMC) is a \#\P-complete computational problem that asks to count the models of a sentence in first-order logic. Despite being around for more than a decade, practical FOMC algorithms are still unable to compute functions as simple as a factorial. We argue that the capabilities of FOMC algorithms are severely limited by their inability to express arbitrary recursive computations. To enable arbitrary recursion, we relax the restrictions that typically accompany domain recursion and generalise circuits used to express a solution to an FOMC problem to graphs that may contain cycles. To this end, we enhance the most well-established (weighted) FOMC algorithm ForcLift with new compilation rules and an algorithm to check whether a recursive call is feasible. These improvements allow us to find efficient solutions to counting fundamental structures such as injections and bijections.

\clearpage
\section{Introduction}

\todo[inline]{Introduce Crane and explain that it's modus operandi is very different.}

\todo[inline]{Introduce the acronym for GDR?}

\todo[inline]{Maybe rename the DR command to GDR?}

% Definition and scope of the topic: FOMC

\emph{First-order model counting} (FOMC) is the problem of computing the number of models of a sentence in first-order logic given the size(s) of its domain(s) \citep{DBLP:conf/ijcai/BroeckTMDR11}. The main application of FOMC (or, rather, its \emph{weighted} variant WFOMC) is in probabilistic inference, particularly for statistical relational models such as Markov logic networks that define probabilities over sets of objects and relations thereof \citep{DBLP:conf/ijcai/BroeckTMDR11,DBLP:journals/cacm/GogateD16}.

Over slightly more than a decade, research on (W)FOMC advanced on both theoretical and empirical fronts. Several WFOMC algorithms such as ForcLift \citep{DBLP:conf/ijcai/BroeckTMDR11}, probabilistic theorem proving \citep{DBLP:journals/cacm/GogateD16}, and L2C \citep{DBLP:conf/kr/KazemiP16} were developed. More and more classes of formulas were shown to be \emph{liftable}, i.e., solvable in polynomial time with respect to the size(s) of the domain(s) \citep{DBLP:conf/kr/BremenK21,DBLP:conf/nips/KazemiKBP16,DBLP:conf/lics/KuusistoL18,DBLP:journals/jair/Kuzelka21}. Much of the researchers' attention was devoted to developing efficient solutions to formulas with up to two variables \citep{DBLP:conf/uai/BremenK21,DBLP:journals/corr/abs-2110-05992}.

% The problem you are to focus on the topic: recursion

However, none of the publicly available (W)FOMC algorithms can efficiently compute functions as simple as a factorial.\footnote{The problem of computing the factorial can be described using two variables and counting quantifiers, so it belongs to a fragment of first-order logic which is known to be liftable \citep{DBLP:journals/jair/Kuzelka21}.} We claim that this shortcoming is due to the inability of these algorithms to construct recursive solutions.

% If the problem was faced before, describe the state of the art.

The topic of recursion in the context of WFOMC has been studied before but in very limited ways. \Citet{DBLP:conf/ilp/BarvinekB0ZK21} use WFOMC to generate numerical data which is then used to conjecture recurrence relations that explain that data. \Citet{DBLP:conf/nips/Broeck11} introduced the idea of \emph{domain recursion}. Intuitively, domain recursion partitions a domain of size $n$ into a single explicitly named constant and the remaining domain of size $n-1$. However, many stringent conditions are enforced to ensure that the search for a tractable solution always terminates.

%1) But their code only conjectures stuff on data. My conjectures are guaranteed always true.
%2) everything has to be expressible in $\mathbf{C}^2$, i.e., the two-variable fragment of first-order logic with counting quantifiers on one domain.
%3) They only consider P-recursive functions, which means that, e.g., $f(n) = f(n-1)f(n-2)$ would not be allowed.

% Discuss the methods and novel techniques to be employed

\begin{figure}
\centering
\begin{subfigure}{0.49\textwidth}
\begin{tikzpicture}[triangle/.style = {regular polygon, regular polygon sides=3},edge from parent/.style={draw,-{Latex[length=2mm]}}]
\node[draw,circle] {}
child {node[draw,ellipse] (b) {$\phi(n)$}
child {node[draw,triangle] {}}
}
child {node[draw,circle] {}
child {node[draw,ellipse] (a) {$\phi(n)$}}
}
;
\draw[-{Latex[length=2mm]}] (a) -- (b);
\end{tikzpicture}
\caption{Before}
\label{fig:before}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
\centering
\begin{tikzpicture}[triangle/.style = {regular polygon, regular polygon sides=3}]
\node[draw,ellipse] (a) at (0, 0) {$\phi(n)$};
\node[draw,ellipse] (b) at (0, -2) {$\psi(n-1)$};
\node[draw,ellipse] (c) at (-1, -4) {$\phi(n-1)$};
\node[draw,triangle] (d) at (1, -4) {};
\draw[-{Latex[length=2mm]}] (a) -- (b) node [midway,xshift=50] {Domain recursion};
\draw[-{Latex[length=2mm]}] (b) -- (c);
\draw[-{Latex[length=2mm]}] (b) -- (d);
\draw[-{Latex[length=2mm]}] (c) to [bend left=45] node [midway,xshift=-30] () {$n \mapsto n-1$} (a);
\end{tikzpicture}
\caption{After}
\label{fig:after}
\end{subfigure}
\caption{Non-tree-like edges in first-order knowledge compilation}
\end{figure}

\todo[inline]{Informally introduce what a compilation rule is.}

\todo[inline]{Vertex or node?}

In this work, we show how new tractable solutions can be found by dispensing with these restrictions. With additional compilation rules and an algorithm for checking whether a `recursive call' is possible, ForcLift \citep{DBLP:conf/ijcai/BroeckTMDR11} is adapted to be able to construct recursive functions that efficiently solve counting problems that used to be beyond its reach. The main conceptual difference from the original algorithm is that the input formula is now compiled to a labelled directed graph rather than a circuit (i.e., cycles are allowed). This idea is illustrated in \cref{fig:after}. Suppose the original formula $\phi$ depended on a domain of size $n \in \mathbb{N}$. Domain recursion transforms $\phi$ into a different formula $\psi$ that depends on a domain of size $n-1$. After some number of subsequent transformations, the algorithm identifies that a solution to $\psi$ can be constructed in part by finding a solution to a version of $\phi$ where the domain of size $n$ is replaced by a domain of size $n-1$. Recognising $\phi$ from before, we can add a cycle-forming edge to the graph, which can be interpreted as function $f$ relying on $f(n-1)$ to compute $f(n)$.

%% \begin{itemize}
%% \item one can then extract the (potentially recursive) definitions of functions from the graph
%% \item simplify the algebraic expressions, e.g.:
%%   \begin{itemize}
%%   \item adding and subtracting the same thing
%%   \item $\sum_{i=0}^n[i < 2]f(i) = f(0) + f(1)$
%%   \end{itemize}
%% \item evaluate the functions
%% \item definition of an FCG
%% \item maybe example of an FCG for injections
%% \item new compilation rules
%%   \begin{itemize}
%%   \item (generalised) domain recursion (via example)
%%   \item constraint removal (via example)
%%   \item recursion checking algorithm (sketch it)
%%   \end{itemize}
%% \item combining BFS and greedy search
%% \item smoothing needs to be adapted so as to not get stuck in an infinite loop
%% \item dynamic programming may be necessary to compute in polynomial time
%% \end{itemize}

% Highlights of the results obtained

In our experiments, we consider variations of the function-counting problem. These functions vary in:
\begin{itemize}
\item whether they are full or partial,
\item whether they are injective/surjective/bijective or not,
\item and whether the domain and the codomain are the same.
\end{itemize}
Many versions of this problem were previously unsolvable by any available (W)FOMC algorithm, whereas we can find recursive solutions (that can be evaluated in polynomial time) to all except one of these problems.

% Possible future enhancements and further work in progress

Further work is necessary to fully automate this new way of computing the (W)FOMC of a formula. Crane produces a graph which then needs to be transformed to definitions of (potentially recursive) functions. In some cases, it is necessary to simplify the algebraic expressions in these definitions (e.g., reducing $x-x$ to zero for some expression $x$). Most importantly, the algorithm only gives us the recursive calls but not the base cases. What makes the problem of finding these base cases non-trivial is that the number of base cases is not constant for functions of arity greater than one (i.e., formulas that mention more than one domain). Nonetheless, these remaining challenges are minuscule compared to the broader goal of expanding the capabilities of (W)FOMC to new classes of instances.

%% \begin{itemize}
%% \item open questions:
%%   \begin{itemize}
%%     \item what kind of sequences are computable in this way?
%%     \item would using a different logic extend the capabilities of FOMC even further?
%%   \end{itemize}
%% \end{itemize}

\subsection{Notes}

In a way, we're dividing the idea of domain recursion between the IDR and the Ref nodes, thus also generalising it.

[Insert motivation for smoothing from Section 3.4. of the ForcLift paper.] Originally, smoothing was (and still is) a two-step process. First, atoms that are still accounted for in the circuit are propagated upwards. Then, at vertices of certain types, missing atoms are detected and additional sinks are created to account for them. If left unchanged, the first step of this process would result in an infinite loop whenever a cycle is encountered. \Cref{alg:smoothing} outlines how the first step can be adapted to an arbitrary directed graph.

\section{Preliminaries}

\subsection{First-Order Logic}

In this section, we describe a variation of function-free first-order logic with equality. For a more complete exposition of first-order logic, see the book by \citet{DBLP:books/daglib/0023546}.

In first-order logic, an \emph{atom} (i.e., an atomic formula) is either $t_1 = t_2$ or $P(t_1, \dots, t_n)$ for some predicate $P$ and terms $(t_i)_{i=1}^n$. Here, $n \in \mathbb{N}_0$ is the \emph{arity} of $P$. A \emph{term} is either a constant or a variable (we also call terms \emph{arguments}). An atom is \emph{ground} if all of its terms are constants.

A \emph{formula} is a well-formed expression that connects atoms using the previously described logical operators as well as universal ($\forall x \in D. \phi$) and existential ($\exists x \in D. \phi$) quantifiers. Here, $x$ is a variable, $D$ is a domain, and $\phi$ is a formula. A variable occurrence is \emph{bound} if it is within the scope of a quantifier for that variable, otherwise it is \emph{free}. A formula is a \emph{sentence} if all of its variable occurrences are bound.\footnote{In the rest of this chapter, all formulas in first-order logic are assumed to be sentences.}

\subsubsection{How to Interpret a Sentence}

Let $\phi$ be a sentence. Since each variable in $\phi$ is introduced by a quantifier, each variable is linked to a unique domain. As is done implicitly in previous work \citep{DBLP:phd/basesearch/VandenBroeck13}, we make the following assumption.

\begin{assumption}
  Each constant can be mapped to a domain, and each $n$-ary predicate can be mapped to a sequence of $n$ domains such that:
  \begin{enumerate}
  \item ...
  \item ...
  \end{enumerate}
\end{assumption}

First, we assume that each $n$-ary predicate can be associated with a sequence of $n$ domains, one for each of its terms. Second, we assume that each constant can be similarly linked to a unique domain. Third, we assume that equality is only checked between terms that have the same domain.

\todo[inline]{Describe this more formally. Maybe just two rules: whenever two terms are compared, they have the same domain, the domain of a term is always the same as the $k$-th domain of the predicate.}

\begin{itemize}
\item Interpretation
  \begin{itemize}
  \item domains as sets
  \item constants as specific elements of domains (different constant names $\implies$ different elements). If the domain is not big enough, then the formula is unsat.)
  \item variables (indicated during quantification)
  \item Variables are always uppercase, constants are always lowercase.
  \item predicates are interpreted as relations
  \end{itemize}
\item models are defined very differently: all combinations of relations that satisfy the sentence.
\item (multiple) (finite) domains (of discourse). This makes, e.g., satisfiability decidable and a FO formula can always be expanded to a propositional one.
\end{itemize}

more on first-order logic: \citep{DBLP:books/daglib/0023546}. The MLN paper also has a description

\subsection{Everything Else}

\paragraph{Things I might need to explain.}
\begin{itemize}
\item atom, (positive/negative) literal, constant, predicate, variable, clause, unit clause, first-order logic
\item subformula
\item two parts: compilation and inference (see the slide about workflow: before and after).
\item During inference, there is a domain size map $\size\colon \mathcal{D} \to \mathbb{N}_0$.
\item My formalisation of constraints is more restrictive than the original (e.g., in the thesis).
\item \textsc{Crane/ForcLift} works by always having a formula as input and adding nodes to the circuit/FCG that constitute the solution the that formula.
\item $\sqcup$ for both sets and functions
\item injectivity is similar to the all-different constraint
\end{itemize}

\paragraph{Notation.}
\begin{itemize}
\item We write $\to$ for functions, $\pfun$ for partial functions, $\twoheadrightarrowtail$ for bijections, and $\hookrightarrow$ for set inclusion. Let $\id$ denote the identity function (on any domain). For any function $f$, let $\Imm f$ be the image of $f$.
\end{itemize}

Most of the definitions here are adaptations/formalisations of \citep{DBLP:conf/ijcai/BroeckTMDR11} and the corresponding code.

\begin{definition}
  A \emph{domain} is a symbol for a finite set.\footnote{In the context of functions, the domain of a function $f$ retains its usual meaning and is denoted $\dom(f)$.}
\end{definition}

\begin{definition}
  An \emph{(inequality) constraint} is a pair $(a, b)$, where $a$ is a variable, and $b$ is either a variable or a constant.
\end{definition}

\todo[inline]{V: It might be worth emphasising that you are introducing new notation in new concepts to provide a metatheory to the existing literature on listed reasoning.}
\begin{definition}
  A \emph{clause} is a triple $c = (L, C, \delta_c)$, where $L$ is a set of literals, $C$ is a set of constraints, and $\delta_c$ is a function that maps all variables in $c$ to their domains such that (s.t.) if $(x, y) \in C$ for some variables $x$ and $y$, then $\delta_c(x) = \delta_c(y)$. Note that for convenience sometimes we write $\delta_c$ for the domain map of $c$ without unpacking $c$ into its three constituents.

  Also, let $\Vars$ be a function that maps clauses and sets of literals and inequalities to the set of variables contained within. In particular, $\Vars(c) \coloneqq \Vars(L) \cup \Vars(C)$.
\end{definition}

A \emph{formula} is a set of clauses. All variables in a clause are implicitly universally quantified (but note that variables are never shared among clauses), and all clauses in a formula are implicitly linked by conjunction. This way, one can read formulas as defined here as sentences in first-order logic.

\todo[inline]{Note: we will reuse this several times.}
\begin{example} \label{example:first}
  Let $\phi \coloneqq \{\, c_1, c_2 \,\}$ be a formula, where
  \[
    c_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto b \,\}),
  \]
  and
  \[
    c_2 \coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto a \,\}),
  \]
  for some predicate $p$, variables $X$, $Y$, $Z$, and domains $a$ and $b$. Then in first-order logic $\phi$ could be read as
  \begin{align*}
    (\forall X \in a. \forall Y \in b. \forall Z \in b. Y \ne Z &\implies \neg p(X, Y) \lor \neg p(X, Z)) \land \\
    (\forall X \in a. \forall Y \in b. \forall Z \in a. X \ne Z &\implies \neg p(X, Y) \lor \neg p(Z, Y)).
  \end{align*}
\end{example}

\paragraph{Notation for lists.}
Let $\langle\rangle$ and $\langle x \rangle$ denote an empty list and a list with one element $x$, respectively. We write $\in$ for (in-order) enumeration, $\mdoubleplus$ for concatenation, and $|\cdot|$ for the length of a list. Let $h : t$ denote a list with first element (a.k.a. head) $h$ and remaining list (a.k.a. tail) $t$. We also use list comprehensions written equivalently to set comprehensions. For example, let $L \coloneqq \langle 1 \rangle$ and $M \coloneqq \langle 2 \rangle$ be two lists. Then $M = \langle 2x \mid x \in L \rangle$, $L \mdoubleplus M = 1 : \langle 2 \rangle$, and $|M| = 1$.

\section{Methods}

% Generalising Circuits to Labelled Graphs

A \emph{first-order deterministic decomposable negation normal form computational graph} (FCG) is a (weakly connected) directed graph with a a single source, vertex labels, and ordered outgoing edges.\footnote{Note that imposing an ordering on outgoing edges is just a limited version of edge labelling.} We denote an FCG as $G = (V, s, N^+, \tau)$, where $V$ is the set of vertices, and $s \in V$ is the unique source. Also, $N^+$ is the direct successor function that maps each vertex in $V$ to a \emph{list} that contains either other vertices in $V$ or a special symbol $\star$. This symbol means that the target of the edge is yet to be determined.

\todo[inline,caption={}]{
\begin{itemize}
\item Many $\star$'s, not one. They are counted as nodes (and change the text at the beginning of Section 5.3.1 appropriately).
\item Maybe star should be considered a type? I would need to modify the algorithms.
\item When visualising FCGs, we omit node labels and/or parameters when they are immaterial to what is being discussed. Propagate this change to figures and their descriptions.
\end{itemize}
}

Vertex labels consist of two parts: the \emph{type} and the \emph{parameters}. To avoid clutter, we leave the parameters implicit and let $\tau$ denote the vertex-labelling function that maps each vertex in $V$ to its type. The types are as described in previous work \citep{DBLP:conf/nips/Broeck11,DBLP:conf/ijcai/BroeckTMDR11} as well as the source code of \textsc{ForcLift}\footnote{\url{https://dtai.cs.kuleuven.be/drupal/wfomc}} but with one new type for \emph{constraint removal} (denoted by $\CR$) and two revamped types for domain recursion (denoted by $\DR$) and non-tree-like edges that can encode recursive calls (denoted by $\Reff$). For each vertex $v \in V$, the length of the list $N^+(v)$ (i.e., the out-degree of $v$) is determined by its type $\tau(v)$.

\begin{figure}[t]
  \centering
  \begin{tikzpicture}[every node/.style={draw,ellipse},edge from parent/.style={draw,-latex},sibling distance=2cm,level 6/.style={sibling distance=6cm}]
    \node (dr) {$\DR_{a \gets a \setminus \{\, x \,\}}$}
    child {node {$\bigvee_{b^\top \subseteq b}$}
      child {node[circle] {$\wedge$}
        child {node[circle] {$1$}} % _{(\{\, p(x, X) \,\}, \emptyset, \{\, X \mapsto b^\top \,\})}
        child {node[circle] {$\wedge$}
          child {node[circle] {$1$}} % _{(\{\, \neg p(x, X) \,\}, \emptyset, \{\, X \mapsto b^\bot \,\})}
          child {node[circle] {$\wedge$}
            child {node[circle] {$1$}} % _{(\{\, \neg p(X, Y) \,\}, \{\, (X, x) \,\}, \{\, X \mapsto a, Y \mapsto b^\top \,\})}
            child {node {$\CR_{a \mapsto a'}$}
              child {node[circle] {$\wedge$}
                child {node {$\bot_{(\emptyset, \{\, (X, Y) \,\}, \{\, X \mapsto b^\top, Y \mapsto b^\top \,\})}$}}
                child {node (ref) {$\Reff_{\{\, a \mapsto a', b \mapsto b^\bot \,\}}$}}
              }}}}}};
    \draw[-latex, bend right] (ref) to (dr);
  \end{tikzpicture}
  \caption{An example FCG constructed by Crane. Node labels are written directly on the nodes. Some parameters are omitted for brevity. Outgoing edges are ordered from left to right.}
  \label{fig:examplefcg}
\end{figure}

\begin{example}
The FCG in \cref{fig:examplefcg} has twelve nodes. The source vertex has out-degree 1 (i.e., $|N^+(s)| = 1$), label $\DR_{a \gets a \setminus \{\, x \,\}}$, and type $\DR$ (i.e., $\tau(s) = \DR$). See previous work \citep{DBLP:conf/ijcai/BroeckTMDR11} for an explanation of other node types and how they are to be evaluated. \todo[inline]{How does my notation differ from previous work? Does it need explaining?}
\end{example}

\todo[inline]{This is probably the right place to discuss how an FCG is to be evaluated.}

Similarly to previous work \citep{DBLP:conf/ijcai/BroeckTMDR11}, we write $T_p$ for an FCG that has one vertex with label $T_p$ (i.e., type $T$ and parameter(s) $p$) and with $\star$ as the target of all of its outgoing edges. We also write $T_p(v)$ for an FCG with two vertices and an edge between them (and no edges incident with $\star$). Here, $v$ is the target of the edge, and $T_p$ is the label of the source.

%% Here, the type of the vertex (e.g., $\Reff$) is `applied' to its direct successors (e.g., some vertex $v$) like a function and provided with its parameter(s) (e.g., $\rho$) in the subscript.

\paragraph{Hashing.}
We use (integer-valued) hash functions to efficiently discard pairs of formulas that are too different for recursion to be established. The hash code of a clause $c = (L, C, \delta)$ (denoted by $\# c$) combines the hash codes of the sets of constants and predicates in $c$, the numbers of positive and negative literals, the number of inequality constraints $|C|$, and the number of variables $|\Vars(c)|$. The hash code of a formula $\phi$ combines the hash codes of all its clauses and is denoted by $\#\phi$.

\paragraph{Caching.}
Previously, a cache was used to check if a formula is identical to one of the formulas that have already been fully compiled. If that is the case, then the circuit already contains the subcircuit for this formula. Instead of duplicating this subcircuit, one would draw an edge that creates an undirected (but not a directed) cycle (see \cref{fig:before}). Now, to facilitate recursion, we extend the caching scheme to include formulas that have been encountered but not fully compiled yet. Hence, the same procedure can now create directed cycles in the graph. Formally, we define a \emph{cache} to be a map from integers (e.g., hash codes) to sets of pairs of the form $(\phi, v)$, where $\phi$ is a formula, and $v$ is an FCG node.

\todo[inline]{Clearly explain what we mean by `encodes' and `for'.}

\subsection{New Compilation Rules} \label{sec:rules}

\begin{figure}
\centering
\begin{subfigure}{0.49\textwidth}
\centering
\begin{tikzpicture}[edge from parent/.style={draw,-{Latex[length=2mm]}}]
\node[draw,circle,label={[text=blue]1}] (top) {}
child {node[draw,circle,label={[text=blue,xshift=-1mm]2}] {}
child {node[draw,ellipse] (ref) {$\Reff$}}
child {node[label={[text=blue,xshift=1mm,yshift=-1mm]3}] {$\star$}}
}
child {node[label={[text=blue,xshift=1mm,yshift=-1mm]4}] {$\star$}}
;
\draw[-{Latex[length=2mm]}] (ref) to [bend left=45] (top);
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
\centering
\begin{tikzpicture}[edge from parent/.style={draw,-{Latex[length=2mm]}}]
\node[draw,circle,label={[text=blue]1}] (top) {}
child {node[draw,circle,label={[text=blue,xshift=-1mm]2}] {}
child {node[label={[text=blue,xshift=2mm,yshift=-1mm]3}] {$\star$}}
}
child {node[label={[text=blue,xshift=1mm,yshift=-1mm]4}] {$\star$}}
;
\end{tikzpicture}
\end{subfigure}
\caption{An FCG (on the left) and its underlying tree (on the right). The integers in blue denote the pre-order traversal of the underlying tree.}
\label{fig:ordering}
\end{figure}

A \emph{(compilation) rule} takes a formula and returns a set of $(G, L)$ pairs, where $G$ is a (potentially \texttt{null}) FCG, and $L$ is a list of formulas such that $|L|$ is equal to the number of $\star$'s in $G$. Let the \emph{underlying tree} of an FCG $G$ be the induced subgraph of $G$ that omits all $\Reff$ nodes (subsequently presented algorithms ensure that it is always a tree). Then we can define an implicit bijection between the formulas in $L$ and the $\star$'s in $G$ according to the order in which elements of $L$ are listed and the pre-order traversal of the underlying tree of $G$. For example, if the FCG in \cref{fig:ordering} were to be returned by a compilation rule, its corresponding list of formulas $L$ would have two elements. These elements would then be implicitly associated with the $\star$'s that have labels `3' and `4' next to them, respectively.

Let $\mathcal{D}$ be the set of all domains. Note that this set expands during the compilation.

\subsubsection{Generalised Domain Recursion} \label{sec:dr}

\paragraph{Notation.}
Let $S$ be a set of constraints or literals, $V$ a set of variables, and $x$ either a variable or a constant. We write $S[x/V]$ to denote $S$ with all occurrences of all variables in $V$ replaced with $x$.\footnote{Note that if $(v, w)$ is a two-variable constraint, substituting a constant $c$ for $v$ would result in $(c, w)$, which would have to be rewritten as $(w, c)$ to fit the definition of a constraint.}
\todo[inline]{Short example?}

\todo[inline,caption={}]{Feedback for the paragraph below:
\begin{itemize}
\item introduce the algo in the first sentence: The Domain recursion algorithm (Van den Broeck, 2011) takes as input a formula and outputs an equivalent formula, which is formed by the following process.
\item omit the power-of-two stuff
\item should not refer to intermediary formula as the resulting formula. what you could do is describe the algorithms in two steps: As an preliminary/intermediate step DR .... , Then you can refer to it as `the intermediate step results in ....'
\item clarify `original rule'
\item explain DR before GDR
\end{itemize}
}

\todo[inline,caption={}]{After a description of the algorithm, compare with the original \citep{DBLP:conf/nips/Broeck11}. Invite the reader to look up the original paper for more details.
The original rule for domain recursion by \citet{DBLP:conf/nips/Broeck11} requires three conditions to be satisfied:
\begin{itemize}
\item the formula is shattered,
\item the formula has no independent subformulas,
\item and there exists a root binding class.
\end{itemize}
Domain recursion by \citet{DBLP:conf/nips/Broeck11} then splits the...

\begin{itemize}
\item They create three sets of clauses instead of just one. They are independent and their conjunction is decomposable.
\begin{itemize}
\item the part with only variables $v$
\item the part with only constants $x$
\item the part with both constants and variables $r$
\end{itemize}
\item During evaluation, $v$ is ignored, and the WMCs of $x$ and $r$ can be computed independently. Note that the WMC of $x$ is independent of the size of $D$---this further simplifies the matters.
\end{itemize}
}

The main idea of domain recursion (both the original version by \citet{DBLP:conf/nips/Broeck11} and the one presented here) is as follows. Let $d \in \mathcal{D}$ be a domain. Assuming that $d \ne \emptyset$, it can be partitioned into a singleton set (say, $\{\, x \,\}$) and a set of cardinality $|d| - 1$. Then, for every variable $X$ associated with domain $d$ that occurs in a literal, we want to investigate two possibilities: $X = x$ and $X \ne x$. Note that the total number of such possibilities is not necessarily a power of two: some combinations produce clearly unsatisfiable formulas that can be immediately discarded. We can combine all of these possibilities into a single formula equivalent to the original one. The differences between domain recursion and GDR are in the preconditions for the rule to be applicable and in how the resulting formula (or parts thereof) are handled. The original rule ensures that the remaining formula can be handled efficiently and without the risk of the search algorithm running forever at the expense of more stringent preconditions.

\begin{algorithm}
  \caption{The compilation rule for $\DR$ nodes}
  \label{alg:domainrecursion}
  \KwIn{formula $\phi$}
  \KwOut{set $S$}
  $S \gets \emptyset$\;
  \ForEach{domain $d \in \mathcal{D}$ s.t. there is a $c \in \phi$ and a $v \in \Vars(L_c)$ s.t. $\delta_c(v) = d$\label{line:condition}}{
    $\phi' \gets \emptyset$\;
    $x \gets \text{a new constant associated with domain } d$\;
    \ForEach{clause $c = (L, C, \delta) \in \phi$\label{line:forclause}}{
      $V \gets \{\, v \in \Vars(L) \mid \delta(v) = d \,\}$\;
      \ForEach{subset $W \subseteq V$ s.t. $W^2 \cap C = \emptyset$ {\bf and} $W \cap \{\, v \in \Vars(C) \mid (v, y) \in C \text{ for some constant } y \,\} = \emptyset$\label{line:conditions}}{
        \tcc{$\delta'$ restricts $\delta$ to the new set of variables}
        $\phi' \gets \phi' \cup \{\, (L[x/W], C[x/W] \cup \{\, (v, x) \mid (v \in V \setminus W) \,\}, \delta') \,\}$\;\label{line:generation}
      }
    }
    $S \gets S \cup \{\, (\DR_{d \gets d \setminus \{\, x \,\}}, \langle\phi'\rangle) \,\}$\;
  }
\end{algorithm}

The algorithm for GDR is summarised as \cref{alg:domainrecursion}, and it features only one precondition. Namely, \cref{line:condition} says that for GDR to be applicable on domain $d \in \mathcal{D}$, there must be at least one variable with domain $d$ that is featured in a literal (and not just in constraints). Without such variables, GDR would have no effect on the formula.

\begin{example}
Let $\phi = \{\, c_1, c_2 \,\}$ be a formula, where
\begin{align*}
c_1 &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Z, Y) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto b \}), \\
c_2 &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (Z, X) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto a \}).
\end{align*}
While domain recursion is possible on both domains, here we illustrate how it works on $a$. Having chosen a domain, the algorithm iterates over the clauses of $\phi$. Suppose \cref{line:forclause} picks $c = c_1$ as the first clause. Then, set $V$ is constructed to contain all variables with domain $d = a$ that occur in the literals of clause $c$. In this case, $V = \{\, X \,\}$. 

\todo[inline]{What does it mean to generate a clause?}

\Cref{line:conditions} iterates over all subsets $W \subseteq V$ of variables that can be replaced by a constant without resulting in formulas that are evidently unsatisfiable. We impose two restrictions on $W$. First, $W^2 \cap C = \emptyset$ ensures that there are no pairs of variables in $W$ that are constrained to be distinct, since that would result in a $x \ne x$ constraint after substitution. Similarly, we want to avoid variables in $W$ that have inequality constraints with constants: after substitution, such constraints would transform into inequality constraints between two constants. In this case, both subsets of $V$ satisfy these conditions, and \cref{line:generation} generates two clauses for the output formula:
\[
(\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Z, Y), (X, x) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto b \}),
\]
(from $W = \emptyset$) and
\[
(\{\, \neg p(x, Y), \neg p(x, Z) \,\}, \{\, (Z, Y) \,\}, \{ Y \mapsto b, Z \mapsto b \})
\]
(from $W = V$).

When \cref{line:forclause} picks $c = c_2$, then $V = \{\, X, Z \,\}$. The subset $W = V$ fails to satisfy the conditions on \cref{line:conditions} because of the $Z \ne X$ constraint. The other three subsets of $V$ all generate clauses for $\phi'$:
\[
(\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (Z, X), (X, x), (Z, x) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto a \})
\]
(from $W = \emptyset$),
\[
(\{\, \neg p(x, Y), \neg p(Z, Y) \,\}, \{\, (Z, x) \,\}, \{ Y \mapsto b, Z \mapsto a \})
\]
(from $W = \{\, X \,\}$), and
\[
(\{\, \neg p(X, Y), \neg p(x, Y) \,\}, \{\, (X, x) \,\}, \{ X \mapsto a, Y \mapsto b, \})
\]
(from $W = \{\, Z \,\}$).
\end{example}

\subsubsection{Constraint Removal} \label{sec:cr}

\begin{algorithm}
  \caption{The compilation rule for $\CR$ nodes}
  \label{alg:constraintremoval}
  \KwIn{formula $\phi$, set of domains $\mathcal{D}$}
  \KwOut{set $S$}
  $S \gets \emptyset$\;
  \ForEach{domain $d \in \mathcal{D}$ and element $e \in d$ s.t. $e$ does not occur in any literal of any clause of $\phi$ {\bf and} for each clause $ c = (L, C, \delta_c) \in \phi$ and variable $v \in \Vars(c)$, either $\delta_c(v) \ne d$ {\bf or} $(v, e) \in C$}{
    add a new domain $d'$ to $\mathcal{D}$\;
    $\phi' \gets \emptyset$\;
    \ForEach{clause $(L, C, \delta) \in \phi$}{
      $C' \gets \{\, (x, y) \in C \mid y \ne e \,\}$\;
      $\delta' \gets \emptyset$\;
      \ForEach{variable $v \in \Vars(L) \cup \Vars(C')$}{
        \lIf{$\delta(v) = d$}{$\delta' \gets \delta' \cup \{\, v \mapsto d' \,\}$}
        \lElse{$\delta' \gets \delta' \cup \{\, v \mapsto \delta(v) \,\}$}
      }
      $\phi' \gets \phi' \cup \{\, (L, C', \delta') \,\}$\;
    }
    $S \gets S \cup \{\, (\CR_{d \mapsto d'}, \langle\phi'\rangle) \,\}$\;
  }
\end{algorithm}

\todo[inline]{Describe \cref{alg:constraintremoval} and rewrite the example below. Highlight changes, more intuitive explanations and references to the inner workings of the algorithm.}

\begin{example}
  Let $\phi = \{\, c_1, c_2, c_3 \,\}$ be a formula with clauses
  \begin{align*}
    c_1 &= (\emptyset, \{\, (Y, X) \,\}, \{\, X \mapsto b^\top, Y \mapsto b^\top \,\}), \\
    c_2 &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (X, x), (Y, Z) \,\}, \{\, X \mapsto a, Y \mapsto b^\bot, Z \mapsto b^\bot \,\}), \\
    c_3 &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, x), (Z, X), (Z, x) \,\}, \{\, X \mapsto a, Y \mapsto b^\bot, Z \mapsto a \,\}).
  \end{align*}
  Domain $a$ and with its element $x \in a$ satisfy the preconditions for constraint removal. The operator introduces a new domain $a'$ and transforms $\phi$ to $\phi' = (c_1', c_2', c_3')$, where
  \begin{align*}
    c_1' &= c_1 \\
    c_2' &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto b^\bot \,\}) \\
    c_3' &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (Z, X) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto a' \,\}).
  \end{align*}
\end{example}

\subsubsection{Identifying Opportunities for Recursion} \label{sec:ref}

% Notation

Let $\Doms$ be a function that maps any clause or formula to the set of domains used within. Specifically, $\Doms(c) \coloneqq \Imm \delta_c$ for any clause $c$, and $\Doms(\phi) \coloneqq \bigcup_{c \in \phi} \Doms(c)$ for any formula $\phi$.

For partial functions $\alpha, \beta\colon A \pfun B$ s.t. $\alpha|_{\dom(\alpha) \cap \dom(\beta)} = \beta|_{\dom(\alpha) \cap \dom(\beta)}$, we write $\alpha \cup \beta$ for the unique partial function s.t. $\alpha \cup \beta|_{\dom(\alpha)} = \alpha$, and $\alpha \cup \beta|_{\dom(\beta)} = \beta$.

For any clause $c = (L, C, \delta_c)$, bijection $\beta\colon \Vars(c) \twoheadrightarrowtail V$ (for some set of variables $V$), and function $\gamma\colon \Doms(c) \to \mathcal{D}$, let $c[\beta, \gamma] = d$ be the clause $c$ with all occurrences of any variable $v \in \Vars(c)$ in $L$ and $C$ replaced with $\beta(v)$ (so $\Vars(d) = V$) and $\delta_d\colon V \to \mathcal{D}$ defined as $\delta_d \coloneqq \gamma \circ \delta_c \circ \beta^{-1}$. In other words, $\delta_d$ is the unique function that makes
\[
\begin{tikzcd}
  \Vars(c) \ar[r, tail, two heads, "\beta"] \arrow[d, swap, "\delta_c"] & V = \Vars(d) \ar[d, dashed, "\exists!\delta_d"] \\
  \Doms(c) \ar[r, swap, "\gamma"] & \mathcal{D}
\end{tikzcd}
\]
commute. For example, if clause $c_1$ is as in \cref{example:first}, then
\begin{multline*}
  c_1[\{\, X \mapsto A, Y \mapsto B, Z \mapsto C \,\}, \{\, a \mapsto b, b \mapsto c \,\}] = \\
  (\{\, \neg p(A, B), \neg p(A, C) \,\}, \{\, (B, C) \,\}, \{\, A \mapsto b, B \mapsto c, C \mapsto c \,\}).
\end{multline*}

% Everything Else

\begin{algorithm}
  \caption{The compilation rule for $\Reff$ nodes}
  \label{alg:trycache}
  \KwIn{formula $\phi$, cache $C$}
  \KwOut{a set}

  \ForEach{$(\psi, v) \in C(\#\phi)$}{
    $\rho \gets \identifyRecursion{$\phi$, $\psi$}$\;
    \lIf{$\rho \ne {\normalfont \texttt{null}}$}{\Return{$\{\, (\Reff_\rho(v), \langle\rangle) \,\}$}}
  }
  \Return{$\emptyset$}\;

  \Fn{\identifyRecursion{formula $\phi$, formula $\psi$, map $\rho = \emptyset$}}{
    \lIf{$|\phi| \ne |\psi|$ {\bf or} $\#\phi \ne \#\psi$}{\Return{\normalfont \texttt{null}}}
    \lIf{$\phi = \emptyset$}{\Return{$\rho$}}
    \ForEach{clause $c \in \phi$\label{line:for1}}{
      \ForEach{clause $d \in \psi$ s.t. $\#d = \#c$\label{line:for2}} {
        \ForEach{$(\beta, \gamma) \in \generateMaps{$c$, $d$, $\rho$}$ s.t. $c[\beta, \gamma] = d$\label{line:generateMaps}}{
          $\rho' \gets \identifyRecursion{$\phi \setminus \{\, c \,\}$, $\psi \setminus \{\, d \,\}$, $\rho \cup \gamma$}$\;\label{line:recursion}
          \lIf{$\rho' \ne {\normalfont \texttt{null}}$}{\Return{$\rho'$}}
        }
      }
      \Return{\normalfont \texttt{null}}\;
    }
  }

  \Fn{\generateMaps{clause $c$, clause $d$, map $\rho$}}{
    \ForEach{bijection $\beta\colon \Vars(c) \to \Vars(d)$\label{line:bijection}}{
      $\gamma \gets \constructDomainMap{$\Vars(c)$, $\delta_c$, $\delta_d$, $\beta$, $\rho$}$\;
      \lIf{$\gamma \ne {\normalfont \texttt{null}}$}{\KwRet{$(\beta, \gamma)$}}
    }
  }

  \Fn{\constructDomainMap{set $V$, maps $\delta_c$, $\delta_d$, $\beta$, $\rho$}}{
    $\gamma \gets \emptyset$\;
    \ForEach{$v \in V$}{
      \lIf{$\delta_c(v) \in \dom(\rho)$ {\bf and} $\rho(\delta_c(v)) \ne \delta_d(\beta(v))$}{\Return{\normalfont \texttt{null}}}
      \lIf{$\delta_c(v) \not\in \dom(\gamma)$}{$\gamma \gets \gamma \cup \{\, \delta_c(v) \mapsto \delta_d(\beta(v)) \,\}$}
      \lElseIf{$\gamma(\delta_c(v)) \ne \delta_d(\beta(v))$}{\Return{\normalfont \texttt{null}}}
    }
    \Return{$\gamma$}\;
  }
\end{algorithm}

\todo[inline,caption={}]{
\begin{itemize}
\item Give a general overview of \cref{alg:trycache}.
\item explain why $\rho \cup \gamma$ is possible
\item \texttt{identifyRecursion}: explain what the second return statement is about and why a third one is not necessary. Function \texttt{identifyRecursion} returns \texttt{null} if formulas $\phi$ and $\psi$ are too different for recursion to work. This happens if $\phi$ and $\psi$ (or their subformulas explored in recursive calls) are structurally different (i.e., the numbers of clauses or the hash codes fail to match) or if a clause of $\phi$ cannot be paired with a sufficiently similar clause of $\psi$. Otherwise, \texttt{identifyRecursion} returns...
\item explain the yield keyword
\item explicitly mention the algorithm
\end{itemize}
}

Diagrammatically, \texttt{constructDomainMap} attempts to find a $\gamma\colon \Doms(c) \to \Doms(d)$ s.t.
\begin{equation} \label{eq:commute}
\begin{tikzcd}
  \Vars(c) \ar[r, tail, two heads, "\beta"] \arrow[d, swap, "\delta_c"] & \Vars(d) \ar[d, "\delta_d"] \\
  \Doms(c) \ar[r, dashed, "\gamma"] \ar[d, hookrightarrow] & \Doms(d) \ar[d, hookrightarrow] \\
  \Doms(\phi) \ar[r, swap, "\rho", "|" marking, outer sep=5pt] & \Doms(\psi).
\end{tikzcd}
\end{equation}
commutes (and returns \texttt{null} if such a function does not exist).

\begin{example} \label{example}

% definitions of formulas and intro
Let formula $\phi \coloneqq \{\, c_1, c_2 \,\}$ be as in \cref{example:first}, i.e., with
\[
c_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto b \,\})
\]
and
\[
c_2 \coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto a \,\}).
\]
Let formula $\psi \coloneqq \phi[\id, \{\, a \mapsto a', b \mapsto b^\bot \,\}]$ be just like $\phi$ but with different domains. In other words, $\psi = \{\, d_1, d_2 \,\}$, where
\[
d_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto b^\bot \,\}),
\]
and
\[
d_2 \coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto a' \,\}).
\]
Note that $\#\phi = \#\psi$ and assume that $(\psi, v) \in C(\#\phi)$ for some node $v$. We shall see how \cref{alg:trycache} identifies that the FCG for $\psi$ can be reused for $\phi$ as well.

Since both formulas are non-empty, the algorithm proceeds with the for-loops on \cref{line:for1,line:for2,line:generateMaps}. Suppose $c = c_1$ and $d = d_1$ get picked. Since both clauses have three variables, in the worst case, function \texttt{generateMaps} would have $3!=6$ bijections to check. Suppose the identity bijection is picked first. Then \texttt{constructDomainMap} is called with the following parameters:
\begin{itemize}
\item $V = \{\, X, Y, Z \,\}$,
\item $\delta_c = \{\, X \mapsto a, Y \mapsto b, Z \mapsto b \,\}$,
\item $\delta_d = \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto b^\bot \,\}$,
\item $\beta = \{\, X \mapsto X, Y \mapsto Y, Z \mapsto Z \,\}$,
\item $\rho = \emptyset$.
\end{itemize}
Since $\delta_i(Y) = \delta_i(Z)$ for $i \in \{\, c, d \,\}$, \texttt{constructDomainMap} returns $\gamma = \{\, a \mapsto a', b \mapsto b^\bot \,\}$. Thus, \texttt{generateMaps} yields its first pair of maps $(\beta, \gamma)$ to \cref{line:generateMaps}. Furthermore, the pair satisfies $c[\beta, \gamma] = d$. On \cref{line:recursion}, a recursive call to \texttt{identifyRecursion($\{\,c_2\,\}$, $\{\,d_2\,\}$, $\gamma$)} is made.

Again we have two non-empty formulas with equal hash codes, so \texttt{generateMaps} is called with $c = c_2$, $d = d_2$, and $\rho = \{\, a \mapsto a', b \mapsto b^\bot \,\}$. Suppose \cref{line:bijection} picks the identity bijection gain. Then \texttt{constructDomainMap} is called with the following parameters:
\begin{itemize}
\item $V = \{\, X, Y, Z \,\}$,
\item $\delta_c = \{\, X \mapsto a, Y \mapsto b, Z \mapsto a \,\}$,
\item $\delta_d = \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto a' \,\}$,
\item $\beta = \{\, X \mapsto X, Y \mapsto Y, Z \mapsto Z \,\}$,
\item $\rho = \{\, a \mapsto a', b \mapsto b^\bot \,\}$.
\end{itemize}
Since $\beta$ and $\rho$ commute (as in \cref{eq:commute}), and there are no new domains in $\Doms(c)$ and $\Doms(d)$, $\gamma$ exists and is equal to $\rho$. Again, the returned pair $(\beta, \gamma)$ satisfies $c[\beta, \gamma] = d$. \Cref{line:recursion} calls \texttt{identifyRecursion($\emptyset$, $\emptyset$, $\rho$)}, which immediately returns $\rho = \{\, a \mapsto a', b \mapsto b^\bot \,\}$ as the final answer. Therefore, one can indeed reuse an FCG for $\phi$ to compute the model count of $\psi$.
\end{example}

\subsection{Compilation as Search}
% why is it important for tryCache to be non-greedy?

Given a formula $\phi$, we want to find an FCG that encodes how the model count of $\phi$ can be computed. \textsc{ForcLift} tackles this search problem using a greedy algorithm.\footnote{The algorithm is not described in any paper on \textsc{ForcLift} but can be found in its source code.} In this section, we describe a new search algorithm which is a combination of greedy and breadth-first search.

We split all rules into \emph{greedy} and \emph{non-greedy}. Greedy rules represent indisputable choices in the compilation process. They are applied to each encountered formula as soon and as many times as possible (in a predefined order). Most rules are greedy, i.e., those that produce a sink node with no leftover formula, those that simplify the formula without changing the FCG, and those that split the formula into parts that can be solved independently. The constraint removal rule describe in \cref{sec:cr} is greedy. On the other hand, non-greedy rules signify uncertain choices that we may want to retract. They also correspond to edges in our implicit search tree; thus, the first solution found by the search algorithm is always the one with fewest applications of non-greedy rules. These rules include the domain recursion and recursive call rules described in \cref{sec:dr,sec:ref}, respectively, and some rules from previous work \citep{DBLP:conf/ijcai/BroeckTMDR11} such as atom counting, inclusion-exclusion, independent partial grounding, and shattering.

\todo[inline]{Mention that the implicit bijection is the same as in the definition of a compilation rule at the beginning of \cref{sec:rules}.}

\begin{definition}
  A \emph{state} (of the search for an FCG) is a triple $(G, C, L)$, where $G$ is an FCG (or \texttt{null}), $C$ is a cache, and $L$ is a list of formulas.
\end{definition}

% TODO: start here

The actions that can be taken in this kind of state are applications of compilation rules that remove one (e.g., the first) formula from $L$ and potentially add something to $G$, $C$, and $L$.

%% Each node in an FCG $G$ is created by... We say that `$G$ is an FCG for formula $\phi$'

(that are yet to be compiled). (Note that the order is crucial!)

TODO: describe how the algorithm describes an infinite search that can be stopped when some number of solutions is hit, or after some depth of the search tree is exhausted, or after a timeout.

% TODO: end here

We assume that if there is a pair $(\texttt{null}, L)$ in the set returned by a rule, then $|L| = 1$, i.e., the rule transformed the formula without creating any vertices.

NOTE: if a non-greedy rule is not applicable, it returns an empty set, and \cref{alg:applyallrules} skips it.

\begin{algorithm}
  \caption{The (main part of the) search algorithm}
  \label{alg:search}
  \KwIn{a formula $\phi_0$}
  \KwResult{all found FCGs for $\phi_0$ are in the set \solutions}
  $\solutions \gets \emptyset$\;
  $(G_0, C_0, L_0) \gets \applyGreedyRules{$\phi_0$, $\emptyset$}$\;
  \lIf{$L_0 = \langle\rangle$}{$\solutions \gets \{\, G_0 \,\}$}
  \Else{
    $q \gets \text{a empty queue of states}$\;
    $q.\put{$(G_0, C_0, L_0)$}$\;
    \While{{\bf not} $q.\emptyy{}$}{
      \ForEach{state $(G, C, L) \in \applyAllRules{$q.\get{}$}$}{
        \lIf{$L = \langle\rangle$}{$\solutions \gets \solutions \cup \{\, G \,\}$}
        \lElse{$q.\put{$(G, C, L)$}$}
      }
    }
  }
\end{algorithm}

% assumptions:
% greedy rules have already been applied to the initial state s
\begin{algorithm}
  \caption{Return a list of new states created by applying one non-greedy rule followed by all applicable greedy rules}
  \label{alg:applyallrules}
  \Fn{\applyAllRules{state $s$}}{
    $(G, C, L) \gets s$\;
    $\phi : T \gets L$\tcc*{separate the first formula from the rest}
    $(G', C', L') \gets \text{a copy of } s$\;
    $S \gets \langle\rangle$\tcc*{direct successors of $s$}
    \ForEach{non-greedy rule $r$}{
      \ForEach{$(G'', L'') \in r(\phi)$}{
        \lIf{$G'' = {\normalfont \texttt{null}}$}{$S \gets S \mdoubleplus \applyAllRules{$(G', C', L'')$}$}
        \Else{
          $(V, s', N^+, \tau) \gets G''$\;
          $C' \gets \updateCache{$C'$, $\phi$, $G''$}$\;
          $(G'', C', L'') \gets \applyGreedyRulesToAllFormulas{$G''$, $C'$, $L''$}$\;
          \lIf{$G' = {\normalfont \texttt{null}}$}{$S \gets S \mdoubleplus \langle(G'', C', L'' \mdoubleplus T)\rangle$}
          \lElse{$S \gets S \mdoubleplus \langle(\mergeFcgs{$G'$, $G''$}, C', L'' \mdoubleplus T)\rangle$}
        }
      }
      $(G', C', L') \gets \text{a copy of } s$\;
    }
    \Return{$S$}\;
  }
\end{algorithm}

\begin{algorithm}
  \captionsetup{singlelinecheck=off}
  \caption[Helper functions that apply greedy rules to a single formula and all formulas in a state.]{Helper functions that apply greedy rules to
    \begin{enumerate*}[label=\alph*)]
    \item a single formula and
    \item all uncompiled formulas in a state.
    \end{enumerate*}
  }
  \label{alg:apply}
  \Fn{\applyGreedyRules{formula $\phi$, cache $C$}}{
    \ForEach{greedy rule $r$ s.t. $r(\phi) \ne \emptyset$}{
      $(G, L) \gets \text{any element of } r(\phi)$\;
      \lIf{$G = {\normalfont \texttt{null}}$}{\Return{\applyGreedyRules{the element of $L$, $C$}}}
      \Return{\applyGreedyRulesToAllFormulas{$G$, \updateCache{$C$, $\phi$, $G$}, $L$}}\;
    }
    \Return{$({\normalfont \texttt{null}}, C, \langle\phi\rangle)$}\;
  }
  \Fn{\applyGreedyRulesToAllFormulas{$(V, s, N^+, \tau)$, cache $C$, list $L$}}{
    \lIf{$L = \langle\rangle$}{\Return{$((V, s, N^+, \tau), C, L)$}}
    $L' \gets \langle\rangle$; $N^+(s) \gets \langle\rangle$\;
    \ForEach{formula $\phi \in L$}{
      $(G', C, L'') \gets \applyGreedyRules{$\phi$, $C$}$\;
      $L' \gets L' \mdoubleplus L''$\;
      \lIf{$G' = {\normalfont \texttt{null}}$}{$N^+(s) \gets N^+(s) \mdoubleplus \langle\star\rangle$}
      \Else{
        $(V', s', N', \tau') \gets G'$\;
        $V \gets V \sqcup V'$\;
        $N^+ \gets N^+ \sqcup N'$\;
        $N^+(s) \gets N^+(s) \mdoubleplus \langle s' \rangle$\;
        $\tau \gets \tau \sqcup \tau'$\;
      }
    }
    \Return{$((V, s, N^+, \tau), C, L')$}\;
  }
\end{algorithm}

\begin{algorithm}
  \caption{Helper functions for updating a cache and merging FCGs}
  \label{alg:helpers}
  \Fn{\updateCache{cache $C$, formula $\phi$, FCG $(V, s, N^+, \tau)$}}{
    \lIf{$\tau(s) = \textsc{Ref}$}{\Return{$C$}}
    \lIf{$\#\phi \not\in \dom(C)$}{\Return{$C \cup \{\, \#\phi \mapsto (\phi, s) \,\}$}}
    \lIf{there is no $(\phi', v) \in C(\#\phi)$ s.t. $v = s$}{$C(\#\phi) \gets \langle(\phi, s)\rangle \mdoubleplus C(\#\phi)$}
    \Return{$C$}\;
  }
  \Fn{\mergeFcgs{$G = (V, s, N^+, \tau)$, $G' = (V', s', N', \tau')$, $r = s$}}{
    \lIf{$\tau(r) = \textsc{Ref}$}{\Return{\normalfont \texttt{null}}}
    \ForEach{$t \in N^+(r)$}{
      \If{$t = \star$}{
        replace $t$ with $s'$ in $N^+(r)$\;
        \Return{$(V \cup V', s, N^+ \cup N', \tau \cup \tau')$}\;
      }
      $G'' \gets \mergeFcgs{$G$, $G'$, $t$}$\;
      \lIf{$G'' \ne {\normalfont \texttt{null}}$}{\Return{$G''$}}
    }
    \Return{\normalfont \texttt{null}}\;
  }
\end{algorithm}

\todo[inline]{Explain the `tail' part of the algorithm, i.e., that the first formula is replaced by some vertices and some formulas. And explain why we don't want to have \textsc{Ref} vertices in the cache.}

Note: At the end, \texttt{mergeFcgs} will never return \texttt{null} because there is going to be at least one $\star$ in $G$ and the function will find it.

\section{How to Evaluate an FCG} \label{sec:evaluation}

\todo[inline]{Explain how the new types are evaluated. Then have an example evaluation. Maybe move this to the beginning of the previous section?}

\section{Examples of Newly Domain-Liftable Formulas}

\begin{table}
  \centering
  \begin{tabular}{cccccc}
    \toprule
    \multicolumn{3}{c}{Function Class} & \multicolumn{3}{c}{Asymptotic Complexity of Counting} \\
    Partial & Endo & Class & Best Known & With Circuits & With Graphs \\
    \midrule
    \rowcolor{gray!10}\cmark/\xmark & \cmark/\xmark & Functions & $\log m$ & $m$ & $m$ \\
    \xmark & \xmark & \multirow{4}{*}{Surjections} & $n \log m$ \citet{30049} & ? & ? \\
    \xmark & \cmark & & $n \log m$ \citet{30049} & ? & ? \\
    \cmark & \xmark & & \multicolumn{3}{c}{Same as injections from $b$ to $a$} \\
    \cmark & \cmark & & \multicolumn{3}{c}{Same as endo-injections} \\
    \rowcolor{gray!10}\xmark & \xmark & & $\log m$ & - & $mn$ \\
    \rowcolor{gray!10}\xmark & \cmark & & $\log m$ & - & $m^3$ \\
    \rowcolor{gray!10}\cmark & \xmark & & $\min\{\, m, n \,\}^2$ & - & $n^2$ \\
    \rowcolor{gray!10}\cmark & \cmark & \multirow{-4}{*}{Injections} & $m^2$ & - & - \\
    \xmark & \xmark & \multirow{3}{*}{Bijections} & $\log m$ & - & $m$ \\
    \xmark & \cmark & & \multicolumn{3}{c}{\multirow{2}{*}{Same as (partial) (endo-)injections}} \\
    \cmark & \cmark/\xmark & & \multicolumn{3}{c}{} \\
    \bottomrule
  \end{tabular}
  \caption{Here, $m$ is the size of $a$, and $n$ is the size of $b$. All asymptotic complexities are in $\Theta(\cdot)$. This is for unweighted counting. A hyphen means that no solution was found. Assuming all arithmetic operations to take constant time. Maybe a better solution could be found with more search. TODO: explain assumptions for the counts to not be zero. TODO: double check. TODO: transfer the citations to text.}
\end{table}

\todo[inline,caption={}]{
\begin{itemize}
\item \Cref{fig:examplefcg} counts injections and partial injections between two sets.
\item Explain the algebraic notation that I'm using here (e.g., that $f$ is always the main function)
\item Explain the importance of comparing domain sizes to 2. FCGs that compare the size of a domain to an integer can be constructed automatically using compilation rules, although $n$ is upper bounded by the maximum number of variables in any clause of the input formula since there is no rule that would introduce new variables.
\item Mention that it only takes a few seconds to find these solutions. Going beyond depth 6 (or sometimes even completing depth 6) is computationally infeasible with the current implementation, but depth at most 5 can be searched within at most a few seconds.
\item Combine the tikz and the algebraic notation into one, so I don't need to have two versions. But how? Maybe associate a symbol with each type and only to the types that I use?
\item the exponential solutions can be computed in quadratic time with dynamic programming!
\item Can't explain how formulas are translated into (my definition of) clauses without explaining Skolemization, which is out of scope.
\item Note that in some cases different descriptions of the same problem lead to different solutions (with different complexities).
\item Maybe we are actually guaranteed that the solution is always polynomial-time. Except... running time could be infinite?
\item Could also try involutions and other examples from the recent paper on recursion.
\end{itemize}
}

Let $p$ be a predicate of arity two s.t. the first argument is associated with domain $a$, and the second argument is associated with domain $b$ (i.e., $p$ represents a relation between sets $a$ and $b$). Then, to restrict all relations representable by $p$ to just functions from $a$ to $b$, in first-order logic one might write
\begin{gather}
  \forall X \in a. \forall Y \in b. \forall Z \in b. p(X, Y) \land p(X, Z) \implies Y = Z \label{eq:def1} \\
  \forall X \in a. \exists Y \in b. p(X, Y). \label{eq:def2}
\end{gather}
The former says that one element of $a$ can map to at \emph{most} one element of $b$, and the latter says that each element of $a$ must map to at \emph{least} one element of $b$. One might add
\begin{equation} \label{eq:injectivity}
  \forall W \in a. \forall X \in a. \forall Y \in b. p(W, Y) \land p(X, Y) \implies W = X
\end{equation}
to restrict $p$ to injections or
\begin{equation}
  \forall Y \in b. \exists X \in a. p(X, Y)
\end{equation}
to ensure surjectivity or remove \cref{eq:def2} to consider partial functions. Lastly, one can replace all occurrences of $b$ with $a$ so as to model endofunctions instead.

\paragraph{Notes.}
\begin{itemize}
\item \textsc{ForcLift} fails on all of these.
\item Functions, surjections, and their partial counterparts are/were already liftable. It seems like lifting injectivity (which is a fairly general property) is the main accomplishment. (But this is just the one I noticed. There may be many others as well.)
\item Here, $[\cdot]$ is the Iverson bracket.
\end{itemize}

\paragraph{Results.}
\begin{itemize}
\item 1d bijections and 1d injections (note that it's the same problem). Depth 3 solution:
  \begin{align*}
    f(n) &= \sum_{m=0}^n \binom{n}{m} (-1)^{n-m}g(n, m) \\
    g(n, m) &= \sum_{l=0}^n \binom{n}{l}[l < 2]g(n-l, m-1) \\
    &= g(n, m - 1) + ng(n - 1, m - 1),
  \end{align*}
  which works with base case $g(n, 0) = 1$.
\item 1d partial injections. 2 solutions at depth 6, but they're too complicated to check by hand. A contradiction with $X \ne x$ constraints makes things complicated.
\item 2d bijections. Depth 3:
  \begin{align*}
    f(m, n) &= \sum_{l=0}^m \binom{m}{l} [l < 2] (1 - [l < 1])f(m-l, n-1) \\
    &= mf(m-1, n-1),
  \end{align*}
  which works with base cases $f(0, 0) = 1$, $f(0, n) = 0$, $f(m, 0) = 0$.
\item 2d injections. Depth 2:
  \begin{align*}
    f(m, n) &= \sum_{l=0}^m \binom{m}{l}[l<2]f(m-l, n-1) \\
    &= f(m, n-1) + mf(m-1, n-1),
  \end{align*}
  which works with base cases $f(0, 0) = 1$ and $f(m, 0) = 0$.
\item 2d partial injections, depth 2. Exactly the same circuit as above but with base case $f(m, 0) = 1$.
\end{itemize}

\section{Discussion}

\begin{itemize}
\item new rules that don't create vertices (e.g., duplicate removal, unconditional contradiction detection, etc.)
\item some notes on halting
  \begin{itemize}
  \item Search is infinite. Some rules increase the size of the formula(s), but most reduce it.
  \item Inference is guaranteed to terminate if at least one domain shrinks by at least one. But note that allowing recursive calls with the same domain sizes (e.g., $f(n) = f(n) + \dots$) could be useful because these problematic terms might cancel out.
  \item It's impossible for $n \gets n - 1$ and $\texttt{for } n \in \dots$ to combine in a way that results in an infinite loop.
  \end{itemize}
\item care should be taken when cloning to preserve the validity of the cache and avoid infinite cycles (we use a separate (node $\to$ node) cache for this)
\item My examples for 1 domain are expressible using 2 variables and counting quantifiers, so they're already known to be liftable.
\end{itemize}

\section{Conclusions and Future Work}

\paragraph{Conclusions and observations.}
\begin{itemize}
\item $\CR$ must be separate from $\DR$ because initially the requirement to not have the newly introduced constant in the literals is not satisfied.
\end{itemize}

\paragraph{Future work.}
\begin{itemize}
\item Transform FCGs to definitions of (possibly recursive) functions on integers. Use a computer algebra system to simplify them.
\item Design an algorithm to infer the necessary base cases. (Note that there can be an infinite amount of them when functions have more than one parameter.)
\item Observation: -1 (and powers thereof) appear in every solution to a formula if and only if the formula has existential quantification. That's not very smart! By classifying unit propagation as a greedy rule, these powers are pushed to the outer layers of the solution (i.e., `early' in the FCG). It's likely that removing this restriction would enable the algorithm to find asymptotically optimal solutions.
\end{itemize}
