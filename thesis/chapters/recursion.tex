\SetKw{KwRet}{yield}
\SetKwProg{Fn}{Function}{:}{}

\SetKwFunction{applyAllRules}{applyAllRules}
\SetKwFunction{applyGreedyRules}{applyGreedyRules}
\SetKwFunction{applyGreedyRulesToFormulas}{applyGreedyRulesToFormulas}

\SetKwFunction{emptyy}{empty}
\SetKwFunction{get}{get}
\SetKwFunction{put}{put}

\SetKwFunction{constructDomainMap}{constructDomainMap}
\SetKwFunction{identifyRecursion}{identifyRecursion}
\SetKwFunction{generateMaps}{generateMaps}
\SetKwFunction{mergeFcgs}{mergeFcgs}
\SetKwFunction{updateCache}{updCache}

\chapter{Recursive Solutions to FOMC}\label{chapter:wfomc}

\section{Introduction}

\paragraph{References.}
\begin{enumerate}
  \item \textsc{ForcLift} \citep{DBLP:conf/ijcai/BroeckTMDR11}
  \item probabilistic theorem proving (Alchemy) \citep{DBLP:journals/cacm/GogateD16}
  \item L2C \citep{DBLP:conf/kr/KazemiP16}
  \item new liftable classes \citep{DBLP:conf/kr/BremenK21}
  \item new liftable classes \citep{DBLP:conf/nips/KazemiKBP16}
  \item new liftable classes \citep{DBLP:conf/lics/KuusistoL18}
  \item new liftable classes \citep{DBLP:journals/jair/Kuzelka21}
  \item two variable fragment \citep{DBLP:conf/uai/BremenK21}
  \item two variable fragment (closed formula) \citep{DBLP:journals/corr/abs-2110-05992}
  \item recursion \citep{DBLP:conf/ilp/BarvinekB0ZK21}
  \item domain recursion and completeness \citep{DBLP:conf/nips/Broeck11}
  \item first-order logic \citep{DBLP:books/daglib/0023546}
  \item thesis \citep{DBLP:phd/basesearch/VandenBroeck13}
  \item StackExchange \citep{30049}
  \item OEIS \citep{oeis}
  \item lifted probabilistic inference \citep{DBLP:conf/ijcai/BrazAR05}
  \item lifted probabilistic inference \citep{DBLP:conf/uai/BrazO17}
  \item lifted probabilistic inference \citep{DBLP:conf/aaai/KazemiP14}
  \item lifted probabilistic inference \citep{DBLP:conf/ecai/Kersting12}
  \item lifted probabilistic inference \citep{DBLP:conf/nips/JhaGMS10}
  \item lifted variable elimination \citep{DBLP:conf/aistats/TaghipourFBDB13}
  \item lifted graphical models \citep{DBLP:journals/ml/KimmigMG15}
  \item probabilistic logic programming \citep{DBLP:journals/ml/RaedtK15}
  \item statistical relational artificial intelligence \citep{DBLP:series/synthesis/2016Raedt}
  \item probabilistic databases \citep{DBLP:journals/pvldb/GatterbauerS15}
  \item probabilistic databases \citep{DBLP:journals/debu/GribkoffSB14}
  \item complexity \citep{DBLP:conf/pods/BeameBGS15}
  \item approximate ForcLift \citep{DBLP:conf/uai/BroeckCD12}
  \item \textsc{ApproxMC3} \citep{DBLP:conf/ijcai/BremenK20}
  \item learning MLNs \citep{DBLP:journals/ml/HaarenBMD16}
\end{enumerate}

% In a way, we're dividing the idea of domain recursion between the GDR and the
% Ref nodes, thus also generalising it.

\todo[inline,caption={}]{
  \begin{itemize}
    \item Emphasise exactness
    \item Introduce Crane and explain that it's modus operandi is very
          different.
    \item Introduce the acronym for GDR
    \item Explain what we mean by $X \in d$ and $x \in d$ for domain $d$,
          variable $X$, and constant $x$. Then use this notation instead of
          using phrases such as `associated with'.
    \item Do I ever interpret a clause as a sentence? I shouldn't do that:
          sometimes their role is different.
    \item Make sure to mention how $b^{\bot}$ is created alongside $b^{\top}$
          whenever I use either of them.
    \item In the introduction, make sure to mention that our focus is unweighted
          counting, although everything should work with weights as well.
    \item NOTE: Alchemy is both exact and approximate.
    \item Explain
          \textsc{ForcLift}\footnote{\url{https://dtai.cs.kuleuven.be/drupal/wfomc}}
          \begin{itemize}
            \item two parts: compilation and inference (see the slide about
                  workflow: before and after).
            \item \textsc{Crane/ForcLift} works by always having a formula as
                  input and adding nodes to the circuit/FCG that constitute the
                  solution the that formula.
          \end{itemize}
    \item Minimise the number of references to the \textsc{ForcLift} paper.
  \end{itemize}
}

First-order model counting (FOMC) is a \#\P-complete computational problem that
asks to count the models of a sentence in first-order logic. Despite being
around for more than a decade, practical FOMC algorithms are still unable to
compute functions as simple as a factorial. We argue that the capabilities of
FOMC algorithms are severely limited by their inability to express arbitrary
recursive computations. To enable arbitrary recursion, we relax the restrictions
that typically accompany domain recursion and generalise circuits used to
express a solution to an FOMC problem to graphs that may contain cycles. To this
end, we enhance the most well-established (weighted) FOMC algorithm
\textsc{ForcLift} \citep{DBLP:conf/ijcai/BroeckTMDR11} with new compilation
rules and an algorithm to check whether a recursive call is feasible. These
improvements allow us to find efficient solutions to counting fundamental
structures such as injections and bijections.

% Definition and scope of the topic: FOMC

\emph{First-order model counting} (FOMC) is the problem of computing the number
of models of a sentence in first-order logic (FOL) given the size(s) of its
domain(s) \citep{DBLP:conf/ijcai/BroeckTMDR11}. The main application of FOMC
(or, rather, its \emph{weighted} variant WFOMC) is in probabilistic inference,
particularly for statistical relational models such as Markov logic networks
that define probabilities over sets of objects and relations thereof
\citep{DBLP:conf/ijcai/BroeckTMDR11,DBLP:journals/cacm/GogateD16}.

Over slightly more than a decade, research on (W)FOMC advanced on both
theoretical and empirical fronts. Several WFOMC algorithms such as
\textsc{ForcLift} \citep{DBLP:conf/ijcai/BroeckTMDR11}, probabilistic theorem
proving \citep{DBLP:journals/cacm/GogateD16}, and \textsc{L2C}
\citep{DBLP:conf/kr/KazemiP16} were developed. More and more classes of formulas
were shown to be \emph{liftable}, i.e., solvable in polynomial time with respect
to the size(s) of the domain(s)
\citep{DBLP:conf/kr/BremenK21,DBLP:conf/nips/KazemiKBP16,DBLP:conf/lics/KuusistoL18,DBLP:journals/jair/Kuzelka21}.
Much of the researchers' attention was devoted to developing efficient solutions
to formulas with up to two variables
\citep{DBLP:conf/uai/BremenK21,DBLP:journals/corr/abs-2110-05992}.

% The problem you are to focus on the topic: recursion

However, none of the publicly available (W)FOMC algorithms can efficiently
compute functions as simple as a factorial.\footnote{The problem of computing
  the factorial can be described using two variables and counting quantifiers,
  so it belongs to a fragment of FOL which is known to be liftable
  \citep{DBLP:journals/jair/Kuzelka21}.} We claim that this shortcoming is due
to the inability of these algorithms to construct recursive solutions.

% If the problem was faced before, describe the state of the art.

The topic of recursion in the context of WFOMC has been studied before but in
very limited ways. \Citet{DBLP:conf/ilp/BarvinekB0ZK21} use WFOMC to generate
numerical data which is then used to conjecture recurrence relations that
explain that data. \Citet{DBLP:conf/nips/Broeck11} introduced the idea of
\emph{domain recursion}. Intuitively, domain recursion partitions a domain of
size $n$ into a single explicitly named constant and the remaining domain of
size $n-1$. However, many stringent conditions are enforced to ensure that the
search for a tractable solution always terminates.

% 1) But their code only conjectures stuff on data. My conjectures are
% guaranteed always true. 2) everything has to be expressible in $\mathbf{C}^2$,
% i.e., the two-variable fragment of FOL with counting quantifiers
% on one domain. 3) They only consider P-recursive functions, which means that,
% e.g., $f(n) = f(n-1)f(n-2)$ would not be allowed.

% Discuss the methods and novel techniques to be employed

\begin{figure}
  \centering
  \begin{subfigure}{0.49\textwidth}
    \begin{tikzpicture}[triangle/.style = {regular polygon, regular polygon
        sides=3},edge from parent/.style={draw,-{Latex[length=2mm]}}]
      \node[draw,circle] {} child {node[draw,ellipse] (b) {$\phi(n)$} child
        {node[draw,triangle] {}} } child {node[draw,circle] {} child
        {node[draw,ellipse] (a) {$\phi(n)$}} } ; \draw[-{Latex[length=2mm]}] (a)
      -- (b);
    \end{tikzpicture}
    \caption{Before}
    \label{fig:before}
  \end{subfigure}
  \begin{subfigure}{0.49\textwidth}
    \centering
    \begin{tikzpicture}[triangle/.style = {regular polygon, regular polygon
        sides=3}]
      \node[draw,ellipse] (a) at (0, 0) {$\phi(n)$}; \node[draw,ellipse] (b) at
      (0, -2) {$\psi(n-1)$}; \node[draw,ellipse] (c) at (-1, -4) {$\phi(n-1)$};
      \node[draw,triangle] (d) at (1, -4) {}; \draw[-{Latex[length=2mm]}] (a) --
      (b) node [midway,xshift=50] {Domain recursion};
      \draw[-{Latex[length=2mm]}] (b) -- (c); \draw[-{Latex[length=2mm]}] (b) --
      (d); \draw[-{Latex[length=2mm]}] (c) to [bend left=45] node
      [midway,xshift=-30] () {$n \mapsto n-1$} (a);
    \end{tikzpicture}
    \caption{After}
    \label{fig:after}
  \end{subfigure}
  \caption{Non-tree-like edges in first-order knowledge compilation}
\end{figure}

\todo[inline]{Informally introduce what a compilation rule is.}

In this work, we show how new tractable solutions can be found by dispensing
with these restrictions. With additional compilation rules and an algorithm for
checking whether a `recursive call' is possible, \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11} is adapted to be able to construct
recursive functions that efficiently solve counting problems that used to be
beyond its reach. The main conceptual difference from the original algorithm is
that the input formula is now compiled to a labelled directed graph rather than
a circuit (i.e., cycles are allowed). This idea is illustrated in
\cref{fig:after}. Suppose the original formula $\phi$ depended on a domain of
size $n \in \mathbb{N}$. Domain recursion transforms $\phi$ into a different
formula $\psi$ that depends on a domain of size $n-1$. After some number of
subsequent transformations, the algorithm identifies that a solution to $\psi$
can be constructed in part by finding a solution to a version of $\phi$ where
the domain of size $n$ is replaced by a domain of size $n-1$. Recognising $\phi$
from before, we can add a cycle-forming edge to the graph, which can be
interpreted as function $f$ relying on $f(n-1)$ to compute $f(n)$.

%% \begin{itemize}
           %%      \item one can then extract the (potentially recursive)
           %%      definitions of functions from the graph
           %%      \item simplify the algebraic expressions, e.g.:
           %%            \begin{itemize}
           %%      \item adding and subtracting the same thing
           %%      \item $\sum_{i=0}^n[i < 2]f(i) = f(0) + f(1)$
           %%    \end{itemize}
           %%      \item evaluate the functions
           %%      \item definition of an FCG
           %%      \item maybe example of an FCG for injections
           %%      \item new compilation rules
           %%            \begin{itemize}
           %%      \item (generalised) domain recursion (via example)
           %%      \item constraint removal (via example)
           %%      \item recursion checking algorithm (sketch it)
           %%    \end{itemize}
           %%      \item combining BFS and greedy search
           %%      \item smoothing needs to be adapted so as to not get stuck in
           %%      an infinite loop
           %%      \item dynamic programming may be necessary to compute in
           %%      polynomial time
           %%    \end{itemize}

           %    Highlights of the results obtained

In our experiments, we consider variations of the function-counting problem.
These functions vary in:
\begin{itemize}
  \item whether they are full or partial,
  \item whether they are injective/surjective/bijective or not,
  \item and whether the domain and the codomain are the same.
\end{itemize}
Many versions of this problem were previously unsolvable by any available
(W)FOMC algorithm, whereas we can find recursive solutions (that can be
evaluated in polynomial time) to all except one of these problems.

% Possible future enhancements and further work in progress

Further work is necessary to fully automate this new way of computing the
(W)FOMC of a formula. Crane produces a graph which then needs to be transformed
to definitions of (potentially recursive) functions. In some cases, it is
necessary to simplify the algebraic expressions in these definitions (e.g.,
reducing $x-x$ to zero for some expression $x$). Most importantly, the algorithm
only gives us the recursive calls but not the base cases. What makes the problem
of finding these base cases non-trivial is that the number of base cases is not
constant for functions of arity greater than one (i.e., formulas that mention
more than one domain). Nonetheless, these remaining challenges are minuscule
compared to the broader goal of expanding the capabilities of (W)FOMC to new
classes of instances.

%% \begin{itemize}
%%   \item open questions:
%%   \begin{itemize}
%%     \item what kind of sequences are computable in this way?
%%     \item would using a different logic extend the capabilities
%%     of FOMC even further?
%%   \end{itemize}
%% \end{itemize}

\section{Preliminaries}

In this section, we describe our format for FOMC instances, which is heavily
based on the format used internally by \textsc{ForcLift}, some aspects of which
are described in the corresponding paper \citep{DBLP:conf/ijcai/BroeckTMDR11}.
\textsc{ForcLift} is able to translate sentences in a variation of function-free
FOL with equality to this internal format.

An \emph{atom} is $p(t_1, \dots, t_n)$ for some predicate $p$ and terms
$t_{1}, \dots, t_{n}$. Here, $n \in \mathbb{N}_0$ is the \emph{arity} of $p$. A
\emph{term} is either a constant or a variable. A \emph{literal} is either an
atom or the negation of an atom (denoted by $\neg p(t_1, \dots, t_n)$). Let
$\mathcal{D}$ be the set of all domains; note that this set expands during
compilation.

\begin{definition}[Constraint]\label{def:constraint}
  An \emph{(inequality) constraint} is a pair $(a, b)$, where $a$ is a variable,
  and $b$ is either a variable or a constant.
\end{definition}

\begin{definition}[Clause]\label{def:clause}
  A \emph{clause}\footnote{\citet{DBLP:conf/ijcai/BroeckTMDR11} refer to clauses
    as c-clauses.} is a triple $c = (L, C, \delta_c)$, where $L$ is a set of
  literals, $C$ is a set of constraints, and $\delta_c$ is the domain map of
  $c$. Let $\Vars$ be the function that maps clauses and sets of either literals
  or constraints to the set of variables contained within. In particular,
  $\Vars(c) \coloneqq \Vars(L) \cup \Vars(C)$. \emph{Domain map}
  $\delta_{c}\colon \Vars(c) \to \mathcal{D}$ is a function that maps all
  variables in $c$ to their domains such that (s.t.) if $(X, Y) \in C$ for some
  variables $X$ and $Y$, then $\delta_c(X) = \delta_c(Y)$. For convenience, we
  sometimes write $\delta_c$ for the domain map of $c$ without unpacking $c$
  into its three constituents.
\end{definition}

Similarly to variables in \cref{def:clause}, all constants are (implicitly)
mapped to domains, and each $n$-ary predicate is implicitly mapped to a sequence
of $n$ domains.

\begin{definition}[Formula]\label{def:formula}
  A \emph{formula} (called a c-theory by \citet{DBLP:conf/ijcai/BroeckTMDR11})
  is a set of clauses such that all constraints and atoms `type check' with
  respect to domains.
\end{definition}

\begin{example}\label{example:first}
  Let $\phi \coloneqq \{\, c_1, c_2 \,\}$ be a formula, where
  \[
    c_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto b \,\}),
  \]
  and
  \[
    c_2 \coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto a \,\}),
  \]
  for some predicate $p$, variables $X$, $Y$, $Z$, and domains $a$ and $b$. Then $\Vars(\{\, (Y, Z) \,\}) = \{\, Y, Z \,\}$ and $\Vars(c_{1}) = \Vars(c_{2}) = \{\, X, Y, Z \,\}$. Based on the domain maps of $c_{1}$ and $c_{2}$, we can infer that $p$ is associated with domains $a$ and $b$ (in that order). All variables (in both clauses) that occur as the first argument to $p$ are in $a$, and likewise all variables that occur as the second argument to $p$ are in $b$. Therefore, $\phi$ `type checks' as a valid formula.
\end{example}

There are two major differences between
\cref{def:constraint,def:clause,def:formula} and the corresponding concepts
introduced by \citet{DBLP:conf/ijcai/BroeckTMDR11}. First, we decouple
variable-to-domain assignments from constraints and move them to a separate
function $\delta_{c}$ in \cref{def:clause}. Formalising these assignments as a
function unveils the (previously implicit) assumption that each variable must be
assigned to a domain. Second, while \citet{DBLP:conf/ijcai/BroeckTMDR11} allow
for equality constraints and constraints of the form $X \not\in d$ for some
variable $X$ and domain $d$, we exclude such constraints simply because they are
not needed.

One can read a formula as in \cref{def:formula} as a sentence in a FOL\@.
All variables in a
clause are implicitly universally quantified (but note that variables are never
shared among clauses), and all clauses in a formula are implicitly linked by
conjunction. Thus, we can read formula $\phi$ from \cref{example:first} as
\begin{align*}
  (\forall X \in a\text{. }\forall Y \in b\text{. }\forall Z \in b\text{. }Y \ne Z &\implies \neg p(X, Y) \lor \neg p(X, Z)) \land \\
  (\forall X \in a\text{. }\forall Y \in b\text{. }\forall Z \in a\text{. }X \ne Z &\implies \neg p(X, Y) \lor \neg p(Z, Y)).
\end{align*}

Once domains are mapped to finite sets and constants to specific (and different)
elements in those sets, a formula can be viewed as a set of conditions that the
predicates (interpreted as relations) have to satisfy.\footnote{If some domain
  is not big enough to contain all of its constants, the formula is
  unsatisfiable.} Hence, FOMC is the problem of counting the number of
combinations of relations that satisfy these conditions.

\begin{example}
  Let $\phi$ be as in \cref{example:first} and let $|a| = |b| = 2$. There are
  $2^{2 \times 2} = 16$ possible relations between $a$ and $b$. Let us count how
  many of them satisfy the conditions imposed on predicate $p$. The empty
  relation does. All four relations of cardinality one do too. Finally, there
  are two relations of cardinality two that satisfy the conditions as well.
  Thus, the FOMC of $\phi$ (when $|a| = |b| = 2$) is seven. Incidentally, the
  FOMC of $\phi$ counts partial injections.
\end{example}

\paragraph{Notation for functions.}
We write $\to$ for functions, $\pfun$ for partial functions,
$\twoheadrightarrowtail$ for bijections, and $\hookrightarrow$ for set
inclusion. Let $\id$ denote the identity function (on any domain). For any
function $f$, let $\dom(f)$ be its domain, and $\Imm f$ be its image.

\paragraph{Notation for lists.}
Let $\langle\rangle$ and $\langle x \rangle$ denote an empty list and a list
with one element $x$, respectively. We write $\in$ for (in-order) enumeration,
$\mdoubleplus$ for concatenation, and $|\cdot|$ for the length of a list. Let
$h : t$ denote a list with first element (i.e., head) $h$ and remaining list
(i.e., tail) $t$. We also use list comprehensions written equivalently to set
comprehensions. For example, let $L \coloneqq \langle 1 \rangle$ and
$M \coloneqq \langle 2 \rangle$ be two lists. Then
$M = \langle 2x \mid x \in L \rangle$,
$L \mdoubleplus M = 1 : \langle 2 \rangle$, and $|M| = 1$.

\section{Methods}

% Generalising Circuits to Labelled Graphs

\paragraph{From circuits to graphs.}
A \emph{first-order deterministic decomposable negation normal form
  computational graph} (FCG) is a (weakly connected) directed graph with a
single source, node labels, and ordered outgoing edges.\footnote{Note that
  imposing an ordering on outgoing edges is just a limited version of edge
  labelling.} We denote an FCG as $G = (V, s, N^+, \tau)$, where $V$ is the set
of nodes, and $s \in V$ is the unique source. Also, $N^+$ is the direct
successor function that maps each node in $V$ to a \emph{list} that contains
other nodes in $V$.

\paragraph{Node labels.}
Node labels consist of two parts: the \emph{type} and the \emph{parameters}.
To avoid clutter, we leave the parameters implicit and let $\tau$ denote the
node-labelling function that maps each node in $V$ to its type. For each
node $v \in V$, the length of list $N^+(v)$ (i.e., the out-degree of $v$) is
determined by its type $\tau(v)$.

\paragraph{Node types.}
Most of the types are as in previous work
\citep{DBLP:conf/nips/Broeck11,DBLP:conf/ijcai/BroeckTMDR11}. The type for
non-tree-like edges (denoted by $\Reff$), while used before, is extended to
contain the information necessary to support recursive calls. We also add three
new types:
\begin{itemize}
  \item a type for constraint removal denoted by $\CR$,
  \item a type for GDR denoted by $\GDR$ (both with out-degree one),
  \item and $\star$---a placeholder type (with out-degree zero) for nodes that are going to be replaced.
\end{itemize}

\begin{figure}[t]
  \centering
  \begin{tikzpicture}[every node/.style={draw,ellipse},edge from
    parent/.style={draw,-latex},sibling distance=2cm,level 2/.style={sibling
      distance=6cm}]
    \node (dr) {$\GDR_{b \gets b \setminus \{\, x \,\}}$} child {node
      {$\bigvee_{a^\top \subseteq a}$} child {node {$\CR_{b \mapsto b'}$} child
        {node[circle] {$\wedge$} child {node
            {$\bot_{(\emptyset, \{\, (X, Y) \,\}, \{\, X \mapsto a^\top, Y \mapsto a^\top \,\})}$}}
          child {node (ref)
            {$\Reff_{\{\, a \mapsto a^{\bot}, b \mapsto b' \,\}}$}} }}};
    \draw[-latex, bend right] (ref) to (dr);
  \end{tikzpicture}
  \caption{An example FCG constructed by Crane. Label
    $\bigvee_{a^\top \subseteq a}$ denotes set-disjunction, $\land$ denotes
    conjunction, and $\bot$ denotes a contradiction---see the work by
    \citet{DBLP:conf/ijcai/BroeckTMDR11} for the descriptions of these node
    types.}\label{fig:examplefcg}
\end{figure}

\todo[inline]{Check every reference to \cref{fig:examplefcg} to make sure
  they're up-to-date.}

\paragraph{Drawing an FCG.}
When drawing FCGs:
\begin{itemize}
  \item outgoing edges are ordered from left to right,
  \item node labels are written directly on the nodes,
  \item and irrelevant labels and/or parameters are omitted.
\end{itemize}
For example, the FCG in \cref{fig:examplefcg} has twelve nodes. The source
node has out-degree 1 (i.e., $|N^+(s)| = 1$), label
$\GDR_{a \gets a \setminus \{\, x \,\}}$, and type $\GDR$ (i.e.,
$\tau(s) = \GDR$).

\paragraph{Some notational conventions.}
Similarly to previous work \citep{DBLP:conf/ijcai/BroeckTMDR11}, we write $T_p$
for an FCG that has a node with label $T_p$ (i.e., type $T$ and parameter(s)
$p$) and $\star$'s as all of its direct successors. For instance, as an FCG,
$\star$ denotes
$(\{\, s \,\}, s, \{\, s \mapsto \langle\rangle \,\}, \{\, s \mapsto \star \,\})$,
i.e., an FCG with just one node of type $\star$ and no edges. We also write
$T_p(v)$ for an FCG with two nodes and an edge between them (and no edges
incident with $\star$). Here, $v$ is the target of the edge, and $T_p$ is the
label of the source.

\begin{figure}
  \centering
  \begin{subfigure}{0.49\textwidth}
    \centering
    \begin{tikzpicture}[edge from parent/.style={draw,-{Latex[length=2mm]}}]
      \node[draw,circle,label={[text=blue]1}] (top) {} child
      {node[draw,circle,label={[text=blue,xshift=-1mm]2}] {} child
        {node[draw,ellipse] (ref) {$\Reff$}} child
        {node[draw,circle,label={[text=blue,xshift=1mm,yshift=-1mm]3}] {$\star$}} } child
      {node[draw,circle,label={[text=blue,xshift=1mm,yshift=-1mm]4}] {$\star$}} ;
      \draw[-{Latex[length=2mm]}] (ref) to [bend left=45] (top);
    \end{tikzpicture}
    \caption{An example FCG}\label{fig:smallexample1}
  \end{subfigure}
  \begin{subfigure}{0.49\textwidth}
    \centering
    \begin{tikzpicture}[edge from parent/.style={draw,-{Latex[length=2mm]}}]
      \node[draw,circle,label={[text=blue]1}] (top) {} child
      {node[draw,circle,label={[text=blue,xshift=-1mm]2}] {} child
        {node[draw,circle,label={[text=blue,xshift=2mm,yshift=-1mm]3}] {$\star$}} } child
      {node[draw,circle,label={[text=blue,xshift=1mm,yshift=-1mm]4}] {$\star$}} ;
    \end{tikzpicture}
    \caption{The underlying tree of \cref{fig:smallexample1}}\label{fig:smallexample2}
  \end{subfigure}
  \caption{An FCG and its underlying tree. The integers in blue denote the
    pre-order traversal of the underlying tree.}
  \label{fig:ordering}
\end{figure}

\todo[inline,caption={}]{
  \begin{itemize}
    \item Make sure I'm using the word `full' (also `partial') everywhere and
          that I'm not using the word `solution' instead of `chip'.
  \end{itemize}
}

\paragraph{Connecting FCGs with formulas.} We introduce a structure that
represents a solution to a FOMC problem while it is still being built. A
\emph{chip} is a pair $(G, L)$, where $G$ is an FCG, and $L$ is a list of
formulas, such that $|L|$ is equal to the number of $\star$'s in $G$. The
intuition behind this definition is that $L$ contains formulas that still need
to be compiled. Once a formula is compiled, it replaced one of the $\star$'s in
$G$. We say that a chip is \emph{full} if $L = \langle \rangle$ or,
equivalently, there are no $\star$'s in $G$. Let the \emph{underlying tree} of
$G$ be the induced subgraph of $G$ that omits all $\Reff$
nodes.\footnote{Subsequently presented algorithms ensure that the underlying
  tree is guaranteed to be a tree.} Then we can define an implicit bijection
between the formulas in $L$ and the $\star$'s in $G$ according to the order in
which elements of $L$ are listed and the pre-order traversal of the underlying
tree of $G$. For example, if $G$ is as in \cref{fig:smallexample1} (with its
underlying tree in \cref{fig:smallexample2}), then $|L| = 2$. Moreover, the
first element of $L$ is associated with the $\star$ labelled 3, and the second
with the one labelled 4.

\paragraph{Hashing.}
We use (integer-valued) hash functions to efficiently discard pairs of formulas
that are too different for recursion to be established. The hash code of a
clause $c = (L, C, \delta)$ (denoted by $\# c$) combines the hash codes of the
sets of constants and predicates in $c$, the numbers of positive and negative
literals, the number of inequality constraints $|C|$, and the number of
variables $|\Vars(c)|$. The hash code of a formula $\phi$ combines the hash
codes of all its clauses and is denoted by $\#\phi$.

\paragraph{Caching.}
Previously, a cache was used to check if a formula is identical to one of the
formulas that have already been fully compiled. If that is the case, then the
circuit already contains the subcircuit for this formula. Instead of duplicating
this subcircuit, one would draw an edge that creates an undirected (but not a
directed) cycle (see \cref{fig:before}). Now, to facilitate recursion, we extend
the caching scheme to include formulas that have been encountered but not fully
compiled yet. Hence, the same procedure can now create directed cycles in the
FCG\@. Formally, we define a \emph{cache} to be a map from integers (e.g., hash
codes) to sets of pairs of the form $(\phi, v)$, where $\phi$ is a formula, and
$v$ is an FCG node.

\todo[inline]{Clearly explain what we mean by `encodes' and `for'.}

\todo[inline]{Be clear about how nodes relate to formulas.}

\subsection{New Compilation Rules}\label{sec:rules}

A \emph{(compilation) rule} takes a formula and returns a set of chips. The
cardinality of this set is the number of different ways in which the rule can be
applied to the input formula. While \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11} heuristically chooses one of them, in an
attempt to not miss a solution, \textsc{Crane} returns them all. In particular,
if a rule returns an empty set, then that rule is not applicable to the formula,
and the algorithm continues with the next rule.

\subsubsection{Generalised Domain Recursion}\label{sec:dr}

\paragraph{Notation.}
Let $S$ be a set of constraints or literals, $V$ a set of variables, and $x$
either a variable or a constant. We write $S[x/V]$ to denote $S$ with all
occurrences of all variables in $V$ replaced with $x$.\footnote{Note that if
  $(v, w)$ is a two-variable constraint, substituting a constant $c$ for $v$
  would result in $(c, w)$, which would have to be rewritten as $(w, c)$ to fit
  the definition of a constraint.} \todo[inline]{Short example?}

\todo[inline,caption={}]{Feedback for the paragraph below:
  \begin{itemize}
    \item introduce the algo in the first sentence: The Domain recursion
          algorithm (Van den Broeck, 2011) takes as input a formula and outputs
          a formula, which is formed by the following process.
    \item omit the power-of-two stuff
    \item should not refer to intermediary formula as the resulting formula.
          what you could do is describe the algorithms in two steps: As an
          preliminary/intermediate step DR .... , Then you can refer to it as
          `the intermediate step results in ....'
    \item clarify `original rule'
    \item explain DR before GDR
  \end{itemize}
}

\todo[inline,caption={}]{After a description of the algorithm, compare with the
  original \citep{DBLP:conf/nips/Broeck11}. Invite the reader to look up the
  original paper for more details. The original rule for domain recursion by
  \citet{DBLP:conf/nips/Broeck11} requires three conditions to be satisfied:
  \begin{itemize}
    \item the formula is shattered,
    \item the formula has no independent subformulas,
    \item and there exists a root binding class.
  \end{itemize}
  Domain recursion by \citet{DBLP:conf/nips/Broeck11} then splits the...

  \begin{itemize}
    \item They create three sets of clauses instead of just one. They are
          independent and their conjunction is decomposable.
          \begin{itemize}
            \item the part with only variables $v$
            \item the part with only constants $x$
            \item the part with both constants and variables $r$
          \end{itemize}
    \item During evaluation, $v$ is ignored, and the WMCs of $x$ and $r$ can be
          computed independently. Note that the WMC of $x$ is independent of the
          size of $D$---this further simplifies the matters.
  \end{itemize}
}

The main idea of domain recursion (both the original version by
\citet{DBLP:conf/nips/Broeck11} and the one presented here) is as follows. Let
$d \in \mathcal{D}$ be a domain. Assuming that $d \ne \emptyset$, it can be
partitioned into a singleton set (say, $\{\, x \,\}$) and a set of cardinality
$|d| - 1$. Then, for every variable $X$ associated with domain $d$ that occurs
in a literal, we want to investigate two possibilities: $X = x$ and $X \ne x$.
Note that the total number of such possibilities is not necessarily a power of
two: some combinations produce clearly unsatisfiable formulas that can be
immediately discarded. We can combine all of these possibilities into a single
formula equivalent to the original one. The differences between domain recursion
and GDR are in the preconditions for the rule to be applicable and in how the
resulting formula (or parts thereof) are handled. The original rule ensures that
the remaining formula can be handled efficiently and without the risk of the
search algorithm running forever at the expense of more stringent preconditions.

\begin{algorithm}
  \caption{The compilation rule for $\GDR$ nodes}\label{alg:domainrecursion}
  \KwIn{formula $\phi$}
  \KwOut{set of chips $S$}
  $S \gets \emptyset$\;
  \ForEach{domain $d \in \mathcal{D}$ s.t.\ there is a $c \in \phi$ and a $v \in \Vars(L_c)$ s.t. $\delta_c(v) = d$\label{line:condition}}{
    $\phi' \gets \emptyset$\;
    $x \gets \text{a new constant associated with domain } d$\;
    \ForEach{clause $c = (L, C, \delta) \in \phi$\label{line:forclause}}{
      $V \gets \{\, v \in \Vars(L) \mid \delta(v) = d \,\}$\;
      \ForEach{subset $W \subseteq V$ s.t. $W^2 \cap C = \emptyset$ {\bf and} $W \cap \{\, v \in \Vars(C) \mid (v, y) \in C \text{ for some constant} y \,\} = \emptyset$\label{line:conditions}}{
        \tcc{$\delta'$ restricts $\delta$ to the new set of variables}
        $\phi' \gets \phi' \cup \{\, (L[x/W], C[x/W] \cup \{\, (v, x) \mid (v \in V \setminus W) \,\}, \delta') \,\}$\;\label{line:generation}
      }
    }
    $S \gets S \cup \{\, (\GDR_{d \gets d \setminus \{\, x \,\}}, \langle\phi'\rangle) \,\}$\;
  }
\end{algorithm}

The algorithm for GDR is summarised as \cref{alg:domainrecursion}, and it
features only one precondition. Namely, \cref{line:condition} says that for GDR
to be applicable on domain $d \in \mathcal{D}$, there must be at least one
variable with domain $d$ that is featured in a literal (and not just in
constraints). Without such variables, GDR would have no effect on the formula.

\begin{example}
  Let $\phi = \{\, c_1, c_2 \,\}$ be a formula, where
  \begin{align*}
    c_1 &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Z, Y) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto b \}), \\
    c_2 &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (Z, X) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto a \}).
  \end{align*}
  While domain recursion is possible on both domains, here we illustrate how it
  works on $a$. Having chosen a domain, the algorithm iterates over the clauses
  of $\phi$. Suppose \cref{line:forclause} picks $c = c_1$ as the first clause.
  Then, set $V$ is constructed to contain all variables with domain $d = a$ that
  occur in the literals of clause $c$. In this case, $V = \{\, X \,\}$.

  \Cref{line:conditions} iterates over all subsets $W \subseteq V$ of variables
  that can be replaced by a constant without resulting in formulas that are
  evidently unsatisfiable. We impose two restrictions on $W$. First,
  $W^2 \cap C = \emptyset$ ensures that there are no pairs of variables in $W$
  that are constrained to be distinct, since that would result in a $x \ne x$
  constraint after substitution. Similarly, we want to avoid variables in $W$
  that have inequality constraints with constants: after substitution, such
  constraints would transform into inequality constraints between two constants.
  In this case, both subsets of $V$ satisfy these conditions, and
  \cref{line:generation} generates two clauses for the output formula:
  \[
    (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Z, Y), (X, x) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto b \}),
  \]
  (from $W = \emptyset$) and
  \[
    (\{\, \neg p(x, Y), \neg p(x, Z) \,\}, \{\, (Z, Y) \,\}, \{ Y \mapsto b, Z \mapsto b \})
  \]
  (from $W = V$).

  When \cref{line:forclause} picks $c = c_2$, then $V = \{\, X, Z \,\}$. The
  subset $W = V$ fails to satisfy the conditions on \cref{line:conditions}
  because of the $Z \ne X$ constraint. The other three subsets of $V$ all
  generate clauses for $\phi'$:
  \[
    (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (Z, X), (X, x), (Z, x) \,\}, \{ X \mapsto a, Y \mapsto b, Z \mapsto a \})
  \]
  (from $W = \emptyset$),
  \[
    (\{\, \neg p(x, Y), \neg p(Z, Y) \,\}, \{\, (Z, x) \,\}, \{ Y \mapsto b, Z \mapsto a \})
  \]
  (from $W = \{\, X \,\}$), and
  \[
    (\{\, \neg p(X, Y), \neg p(x, Y) \,\}, \{\, (X, x) \,\}, \{ X \mapsto a, Y \mapsto b, \})
  \]
  (from $W = \{\, Z \,\}$).
\end{example}

\subsubsection{Constraint Removal} \label{sec:cr}

\begin{algorithm}
  \caption{The compilation rule for $\CR$ nodes}\label{alg:constraintremoval}
  \KwIn{formula $\phi$, set of domains $\mathcal{D}$}
  \KwOut{set of chips $S$}
  $S \gets \emptyset$\;
  \ForEach{domain $d \in \mathcal{D}$ and element $x \in d$ s.t. $x$ does not occur in any literal of any clause of $\phi$ {\bf and} for each clause $c = (L, C, \delta_c) \in \phi$ and variable $v \in \Vars(c)$, either $\delta_c(v) \ne d$ or $(v, x) \in C$\label{line:crconditions}}{
    add a new domain $d'$ to $\mathcal{D}$\;
    $\phi' \gets \emptyset$\;
    \ForEach{clause $(L, C, \delta) \in \phi$}{
      $C' \gets \{\, (a, b) \in C \mid b \ne x \,\}$\;\label{line:constraintremoval}
      \nosemic$\delta' \gets v \mapsto \begin{cases} d' & \text{if} \delta(v) = d\\ \delta(v) & \text{otherwise;} \end{cases}$\;\label{line:newdelta}
      $\phi' \gets \phi' \cup \{\, (L, C', \delta') \,\}$\;
    }
    $S \gets S \cup \{\, (\CR_{d \mapsto d'}, \langle\phi'\rangle) \,\}$\;
  }
\end{algorithm}

Recall that GDR on a domain $d$ creates constraints of the form $X_i \ne x$ for
some constant $x \in d$ and family of variables $X_i \in d$. Once certain
conditions are satisfied, \cref{alg:constraintremoval} can eliminate these
constraints and replace $d$ with a new domain $d'$, which can be interpreted as
$d \setminus \{\, x \,\}$. These conditions (on \cref{line:crconditions} of the
algorithm) are that a constraint of the form $X \ne e$ exists for all variables
$X \in d$ across all clauses, and such constraints are the only place where $e$
occurs. The algorithm then proceeds to construct the new formula by removing
constraints (on \cref{line:constraintremoval}) and constructing a new domain map
$\delta'$ that replaces $d$ with $d'$ (on \cref{line:newdelta}).

\begin{example}
  Let $\phi = \{\, c_1, c_2, c_3 \,\}$ be a formula with clauses
  \begin{align*}
    c_1 &= (\emptyset, \{\, (Y, X) \,\}, \{\, X \mapsto b^\top, Y \mapsto b^\top \,\}), \\
    c_2 &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (X, x), (Y, Z) \,\}, \{\, X \mapsto a, Y \mapsto b^\bot, Z \mapsto b^\bot \,\}), \\
    c_3 &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, x), (Z, X), (Z, x) \,\}, \{\, X \mapsto a, Y \mapsto b^\bot, Z \mapsto a \,\}).
  \end{align*}
  Domain $a$ and with its element $x \in a$ satisfy the preconditions for
  constraint removal. The rule introduces a new domain $a'$ and transforms
  $\phi$ to $\phi' = (c_1', c_2', c_3')$, where
  \begin{align*}
    c_1' &= c_1 \\
    c_2' &= (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto b^\bot \,\}) \\
    c_3' &= (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (Z, X) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto a' \,\}).
  \end{align*}
\end{example}

\subsubsection{Identifying Opportunities for Recursion}\label{sec:ref}

\paragraph{Notation.}
First, for partial functions $\alpha, \beta\colon A \pfun B$ s.t.
$\alpha|_{\dom(\alpha) \cap \dom(\beta)} = \beta|_{\dom(\alpha) \cap \dom(\beta)}$,
we write $\alpha \cup \beta$ for the unique partial function s.t.
$\alpha \cup \beta|_{\dom(\alpha)} = \alpha$, and
$\alpha \cup \beta|_{\dom(\beta)} = \beta$. Second, let $\Doms$ be a function
that maps any clause or formula to the set of domains used within. Specifically,
$\Doms(c) \coloneqq \Imm \delta_c$ for any clause $c$, and
$\Doms(\phi) \coloneqq \bigcup_{c \in \phi} \Doms(c)$ for any formula $\phi$.
Third, for any clause $c = (L, C, \delta_c)$, bijection
$\beta\colon \Vars(c) \twoheadrightarrowtail V$ (for some set of variables $V$),
and function $\gamma\colon \Doms(c) \to \mathcal{D}$, let $c[\beta, \gamma] = d$
be the clause $c$ with all occurrences of any variable $v \in \Vars(c)$ in $L$
and $C$ replaced with $\beta(v)$ (so $\Vars(d) = V$) and
$\delta_d\colon V \to \mathcal{D}$ defined as
$\delta_d \coloneqq \gamma \circ \delta_c \circ \beta^{-1}$. In other words,
$\delta_d$ is the unique function that makes
\[
  \begin{tikzcd}
    \Vars(c) \ar[r, tail, two heads, "\beta"] \arrow[d, swap, "\delta_c"] & V = \Vars(d) \ar[d, dashed, "\exists!\delta_d"] \\
    \Doms(c) \ar[r, swap, "\gamma"] & \mathcal{D}
  \end{tikzcd}
\]
commute. For example, if clause
\[
  c_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto b \,\})
\]
is as in \cref{example:first}, then
\begin{multline*}
  c_1[\{\, X \mapsto A, Y \mapsto B, Z \mapsto C \,\}, \{\, a \mapsto b, b \mapsto c \,\}] = \\
  (\{\, \neg p(A, B), \neg p(A, C) \,\}, \{\, (B, C) \,\}, \{\, A \mapsto b, B \mapsto c, C \mapsto c \,\}).
\end{multline*}

% Everything Else

\begin{algorithm}
  \caption{The compilation rule for $\Reff$ nodes}
  \label{alg:trycache}
  \KwIn{formula $\phi$, cache $C$}
  \KwOut{a set of chips}

  \ForAll{pairs of formulas and nodes $(\psi, v) \in C(\#\phi)$}{
    $\rho \gets \identifyRecursion{$\phi$, $\psi$}$\;
    \lIf{$\rho \ne {\normalfont \texttt{null}}$}{\Return{$\{\, (\Reff_\rho(v), \langle\rangle) \,\}$}}
  }
  \Return{$\emptyset$}\;

  \Fn{\identifyRecursion{formula $\phi$, formula $\psi$, map $\rho = \emptyset$}}{
    \lIf{$|\phi| \ne |\psi|$ {\bf or} $\#\phi \ne \#\psi$}{\Return{\normalfont\texttt{null}}}
    \lIf{$\phi = \emptyset$}{\Return{$\rho$}}
    \ForEach{clause $c \in \phi$\label{line:for1}}{
      \ForEach{clause $d \in \psi$ s.t. $\#d=\#c$\label{line:for2}}{
        \ForAll{$(\beta, \gamma) \in \generateMaps{$c$, $d$, $\rho$}$ s.t. $c[\beta, \gamma] = d$\label{line:generateMaps}}{
          $\rho' \gets \identifyRecursion{$\phi\setminus\{\, c \,\}$, $\psi\setminus\{\, d \,\}$, $\rho\cup\gamma$}$\;\label{line:recursion}
          \lIf{$\rho' \ne {\normalfont \texttt{null}}$}{\Return{$\rho'$}}
        }
      }
      \Return{\normalfont\texttt{null}}\;
    }
  }

  \Fn{\generateMaps{clause $c$, clause $d$, map $\rho$}}{
    \ForEach{bijection $\beta\colon \Vars(c) \twoheadrightarrowtail \Vars(d)$\label{line:bijection}}{
      $\gamma \gets \constructDomainMap{$\Vars(c)$, $\delta_c$, $\delta_d$, $\beta$, $\rho$}$\;
      \lIf{$\gamma \ne {\normalfont \texttt{null}}$}{\KwRet{$(\beta, \gamma)$}}
    }
  }

  \Fn{\constructDomainMap{set of variables $V$, maps $\delta_c$, $\delta_d$, $\beta$, $\rho$}}{
    $\gamma \gets \emptyset$\;
    \ForEach{variable $v \in V$}{
      \lIf{$\delta_c(v) \in \dom(\rho)$ {\bf and} $\rho(\delta_c(v)) \ne \delta_d(\beta(v))$}{\Return{\normalfont\texttt{null}}}
      \lIf{$\delta_c(v) \not\in \dom(\gamma)$}{$\gamma \gets \gamma \cup \{\, \delta_c(v) \mapsto \delta_d(\beta(v)) \,\}$}
      \lElseIf{$\gamma(\delta_c(v)) \ne \delta_d(\beta(v))$}{\Return{\normalfont\texttt{null}}}
    }
    \Return{$\gamma$}\;
  }
\end{algorithm}

% Cache $C$ is used to partition all previously-encountered formulas based on
% their hash codes.
\Cref{alg:trycache} describes the compilation rule for creating $\Reff$ nodes.
For every formula $\psi$ s.t. $\#\psi = \#\phi$ that we have encountered so far,
function \texttt{identifyRecursion} is called to check whether a recursive call
is actually feasible. If it is, the function returns a (total) map
$\rho\colon \Doms(\phi) \to \Doms(\psi)$ that shows how $\phi$ can be
transformed into $\psi$ by replacing each domain $d \in \Doms(\phi)$ with
$\rho(d) \in \Doms(\psi)$. Otherwise, \texttt{identifyRecursion} returns
\texttt{null} to signify that $\phi$ and $\psi$ are too different for recursion
to work. This happens if $\phi$ and $\psi$ (or their subformulas explored in
recursive calls) are structurally different (i.e., the numbers of clauses or the
hash codes fail to match) or if a clause of $\phi$ cannot be paired with a
sufficiently similar clause of $\psi$.

Function \texttt{identifyRecursion} iterates over pairs of clauses of $\phi$ and
$\psi$ that have the same hash codes. It uses function \texttt{generateMaps} to
check whether the two clauses are sufficiently similar. If so, the function
calls itself on the remaining clauses until the map
$\rho\colon \Doms(\phi) \to \Doms(\psi)$ becomes total, and all clauses are
successfully coupled.

%% If the bijection makes the clauses equal, and the domain map is compatible
           %%             with previously decided domain mappings, move on to another pair of clauses.

Given two clauses $c \in \phi$ and $d \in \psi$, \texttt{generateMaps} considers
all possible bijections\footnote{Although the number of bijections between two
  sets of cardinality $n$ is $n!$, this part of the algorithm is unlikely to
  cause performance issues for two reasons. First, in practice, $n$ is usually
  at most two or three. Second, due to the manner in which formulas are modified
  by compilation rules, if any bijection results in a successfully identified
  recursive relationship, it is almost always the identity bijection.}
$\beta\colon \Vars(c) \twoheadrightarrowtail \Vars(d)$ and calls
\texttt{constructDomainMap}, which then attempts to construct a map
$\gamma\colon \Doms(c) \to \Doms(d)$ `consistent' with both $\beta$ and (the as
yet partial map) $\rho\colon \Doms(\phi) \pfun \Doms(\psi)$. The \textbf{yield}
keyword in \texttt{generateMaps} works as in programming languages such as C\#,
JavaScript, and Python, and lazily returns a sequence of values, computing each
element of the sequence as needed.

Diagrammatically, \texttt{constructDomainMap} attempts to find a
$\gamma\colon \Doms(c) \to \Doms(d)$ s.t.
\begin{equation} \label{eq:commute}
  \begin{tikzcd}
    V = \Vars(c) \ar[r, tail, two heads, "\beta"] \arrow[d, swap, "\delta_c"] & \Vars(d) \ar[d, "\delta_d"] \\
    \Doms(c) \ar[r, dashed, "\gamma"] \ar[d, hookrightarrow] & \Doms(d) \ar[d, hookrightarrow] \\
    \Doms(\phi) \ar[r, swap, "\rho", "|" marking, outer sep=5pt] & \Doms(\psi).
  \end{tikzcd}
\end{equation}
commutes (and returns \texttt{null} if such a function does not exist). Indeed,
for every variable in $V = \Vars(c)$, the function returns \texttt{null} if
either the top rectangle from $V$ to $\Doms(d)$ or the outer rectangle from $V$
to $\Doms(\psi)$ fails to commute. These checks also ensure that
$\rho \cup \gamma$ is possible on \cref{line:recursion} of the algorithm, i.e.,
$\rho|_{\dom(\rho)\cap\dom(\gamma)} = \gamma|_{\dom(\rho)\cap\dom(\gamma)}$.

\begin{example}\label{example}

  % definitions of formulas and intro
  Let formula $\phi \coloneqq \{\, c_1, c_2 \,\}$ be as in \cref{example:first},
  i.e., with
  \[
    c_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto b \,\})
  \]
  and
  \[
    c_2 \coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto a, Y \mapsto b, Z \mapsto a \,\}).
  \]
  Let formula
  $\psi \coloneqq \phi[\id, \{\, a \mapsto a', b \mapsto b^\bot \,\}]$ be just
  like $\phi$ but with different domains. In other words,
  $\psi = \{\, d_1, d_2 \,\}$, where
  \[
    d_1 \coloneqq (\{\, \neg p(X, Y), \neg p(X, Z) \,\}, \{\, (Y, Z) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto b^\bot \,\}),
  \]
  and
  \[
    d_2 \coloneqq (\{\, \neg p(X, Y), \neg p(Z, Y) \,\}, \{\, (X, Z) \,\}, \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto a' \,\}).
  \]
  Note that $\#\phi = \#\psi$ and assume that $(\psi, v) \in C(\#\phi)$ for some
  node $v$. We shall see how \cref{alg:trycache} identifies that the FCG for
  $\psi$ can be reused for $\phi$ as well.

  Since both formulas are non-empty, the algorithm proceeds with the for-loops
  on \cref{line:for1,line:for2,line:generateMaps}. Suppose $c = c_1$ and
  $d = d_1$ get picked. Since both clauses have three variables, in the worst
  case, function \texttt{generateMaps} would have $3!=6$ bijections to check.
  Suppose the identity bijection is picked first. Then
  \texttt{constructDomainMap} is called with the following parameters:
  \begin{itemize}
    \item $V = \{\, X, Y, Z \,\}$,
    \item $\delta_c = \{\, X \mapsto a, Y \mapsto b, Z \mapsto b \,\}$,
    \item
          $\delta_d = \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto b^\bot \,\}$,
    \item $\beta = \{\, X \mapsto X, Y \mapsto Y, Z \mapsto Z \,\}$,
    \item $\rho = \emptyset$.
  \end{itemize}
  Since $\delta_c(Y) = \delta_c(Z)$ and $\delta_d(Y) = \delta_d(Z)$,
  \texttt{constructDomainMap} returns
  $\gamma = \{\, a \mapsto a', b \mapsto b^\bot \,\}$. Thus,
  \texttt{generateMaps} yields its first pair of maps $(\beta, \gamma)$ to
  \cref{line:generateMaps}. Furthermore, this pair satisfies
  $c[\beta, \gamma] = d$. On \cref{line:recursion}, a recursive call to
  \texttt{identifyRecursion($\{\,c_2\,\}$, $\{\,d_2\,\}$, $\gamma$)} is made.

  In this subproblem where both formulas are left with a single clause each,
  again we have two non-empty formulas with equal hash codes. Thus
  \texttt{generateMaps} is called with $c = c_2$, $d = d_2$, and
  $\rho = \{\, a \mapsto a', b \mapsto b^\bot \,\}$. Suppose
  \cref{line:bijection} picks the identity bijection gain. Then
  \texttt{constructDomainMap} is called with the following parameters:
  \begin{itemize}
    \item $V = \{\, X, Y, Z \,\}$,
    \item $\delta_c = \{\, X \mapsto a, Y \mapsto b, Z \mapsto a \,\}$,
    \item $\delta_d = \{\, X \mapsto a', Y \mapsto b^\bot, Z \mapsto a' \,\}$,
    \item $\beta = \{\, X \mapsto X, Y \mapsto Y, Z \mapsto Z \,\}$,
    \item $\rho = \{\, a \mapsto a', b \mapsto b^\bot \,\}$.
  \end{itemize}
  Since $\beta$ and $\rho$ commute (as in \cref{eq:commute}), and there are no
  new domains in $\Doms(c)$ and $\Doms(d)$, $\gamma$ exists and is equal to
  $\rho$. Again, the returned pair $(\beta, \gamma)$ satisfies
  $c[\beta, \gamma] = d$. \Cref{line:recursion} calls
  \texttt{identifyRecursion($\emptyset$, $\emptyset$, $\rho$)}, which
  immediately returns $\rho = \{\, a \mapsto a', b \mapsto b^\bot \,\}$ as the
  final answer. Therefore, one can indeed reuse an FCG for $\psi$ to compute the
  model count of $\phi$.
\end{example}

\subsection{Compilation as Search}

\todo[inline]{Update the text to use the term `chip' where appropriate.}

% intro
Given a formula $\phi$, we want to find an FCG (or a circuit) that encodes a way
to compute the model count of $\phi$. \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11} tackles this search problem using a greedy
algorithm.\footnote{The algorithm is not described in any paper on
  \textsc{ForcLift} but can be found in its source code.} In this section, we
describe a new search algorithm---a combination of greedy and breadth-first
search.

% greedy and non-greedy rules
We split all compilation rules into \emph{greedy} and \emph{non-greedy}. Greedy
rules represent indisputable choices in the compilation process. They are
applied to each encountered formula as soon and as many times as possible (in a
predefined order). Most rules are greedy, i.e., those that produce a sink node
with no leftover formula, those that simplify the formula without changing the
FCG, and those that split the formula into parts that can be solved
independently. The constraint removal rule described in \cref{sec:cr} is greedy.
On the other hand, non-greedy rules signify uncertain choices that we may want
to retract. They also correspond to edges in the implicit search tree; thus, the
first solution found by the search algorithm is always the one with fewest
applications of non-greedy rules. These rules include the $\GDR$ and $\Reff$
rules described in \cref{sec:dr,sec:ref}, respectively, and some rules from
previous work \citep{DBLP:conf/ijcai/BroeckTMDR11} such as atom counting,
inclusion-exclusion, independent partial grounding, and shattering.

% states and actions
Search can be conceptualised as traversing a directed graph composed of states
and actions that lead from one state to the next. We define a \emph{state} as a
triple $(G, L, C)$, where $(G, L)$ is a chip, and $C$ is a cache. The actions
that can be taken in such a state are applications of compilation rules that
remove the first formula from $L$ and potentially add something to $G$, $L$, and
$C$.

\begin{algorithm}
  \caption{The (main part of the) search algorithm}\label{alg:search}
  \KwIn{a formula $\phi_0$}
  \KwResult{all found FCGs for $\phi_0$ are in set $S$} $S \gets \emptyset$\;
  $(G_0, L_0, C_{0}) \gets \applyGreedyRules{$\phi_0$, $\emptyset$}$\;\label{line:greedy}
  \lIf{$L_0 = \langle\rangle$}{$S \gets \{\, G_0 \,\}$}
  \Else{
    $q \gets \text{a empty queue of states}$\;\label{line:q1}
    $q.\put{$ (G_0, L_0, C_0) $}$\;\label{line:q2}
    \While{{\bf not} $q.\emptyy{}$\label{line:while}}{
      \ForEach{state $(G, L, C) \in \applyAllRules{$q.\get{}$}$}{
        \lIf{$L = \langle\rangle$}{$S \gets S \cup \{\, G \,\}$}
        \lElse{$q.\put{$ (G, L, C) $}$}
      }
    }
  }
\end{algorithm}

\begin{algorithm}
  \caption{The function for applying non-greedy rules.}\label{alg:applyallrules}
  \Fn{\applyAllRules{state $s = (G, L, C)$}}{
    $(G', L', C') \gets \text{a copy of } s$\;
    $\phi : T \gets L$\tcc*{separate the first formula from the rest}\label{line:separate}
    \ForEach{non-greedy rule $r$}{
      \ForEach{chip $(G'', L'') \in r(\phi)$}{
        \lIf{$G'' = \star$}{\KwRet{\applyAllRules{$(G', L'' \mdoubleplus T, C')$}}}\label{line:nullfcg}
        \Else{
          $C' \gets \updateCache{$C'$, $\phi$, $G''$}$\;
          $(G'', L'', C') \gets \applyGreedyRulesToFormulas{$G''$, $L''$, $C'$}$\;
          \KwRet{$(\mergeFcgs{$G'$, $G''$}, C', L'' \mdoubleplus T)$}\;
        }
      }
      $(G', L', C') \gets \text{a copy of } s$\;
    }
  }
\end{algorithm}

\begin{algorithm}
  \captionsetup{singlelinecheck=off}
  \caption[Helper functions that apply greedy rules to a single formula and all formulas in a state.]{Helper functions that apply greedy rules to
    \begin{enumerate*}[label=\alph*)]
    \item a single formula and
    \item all uncompiled formulas in a state.
    \end{enumerate*}
  }\label{alg:apply}

  \Fn{\applyGreedyRules{formula $\phi$, cache $C$}}{
    \ForEach{greedy rule $r$ s.t. $r(\phi) \ne \emptyset$}{
      $(G, L) \gets \text{the only chip in } r(\phi)$\;
      \lIf{$G = \star$}{\Return{\applyGreedyRules{the formula in $L$, $C$}}}
      \Return{\applyGreedyRulesToFormulas{$G$, $L$, \updateCache{$C$, $\phi$, $G$}}}\;\label{line:callgreedy}
    }
    \Return{$(\star, \langle\phi\rangle, C)$}\;
  }

  \Fn{\applyGreedyRulesToFormulas{$(V, s, N^+, \tau)$, list $L$, cache $C$}}{
    \lIf{$L = \langle\rangle$}{\Return{$((V, s, N^+, \tau), L, C)$}}
    $L' \gets \langle\rangle$\;
    \ForEach{formula $\phi \in L$}{
      $(G', L'', C) \gets \applyGreedyRules{$\phi$, $C$}$\;
      $L' \gets L' \mdoubleplus L''$\;
      \If{$G' = (V', s', N', \tau') \ne \star$}{
        $(V, N^{+}, \tau) \gets (V \cup V', N^{+} \cup N', \tau \cup \tau')$\;\label{line:cup}
        replace the corresponding $\star$ in $N^{+}(s)$ with $s'$\;
      }
    }
    \Return{$((V, s, N^+, \tau), L', C)$}\;
  }
\end{algorithm}

\begin{algorithm}
  \caption{Helper functions for updating a cache and merging
    FCGs}\label{alg:helpers}
  \Fn{\updateCache{cache $C$, formula $\phi$, FCG $(V, s, N^+, \tau)$}}{
    \lIf{$\tau(s) = \textsc{Ref}$}{\Return{$C$}}
    \lIf{$\#\phi \not\in \dom(C)$}{\Return{$C \cup \{\, \#\phi \mapsto (\phi, s) \,\}$}}
    \lIf{there is no $(\phi', v) \in C(\#\phi)$ s.t. $v = s$}{$C(\#\phi) \gets \langle(\phi, s)\rangle \mdoubleplus C(\#\phi)$}
    \Return{$C$}\;
  }

  \Fn{\mergeFcgs{$G = (V, s, N^+, \tau)$, $G' = (V', s', N', \tau')$, $r = s$}}{
    \lIf{$G = \star$}{\Return{$G'$}}
    \lIf{$\tau(r) = \textsc{Ref}$}{\Return{\normalfont\texttt{null}}}
    \ForEach{$t \in N^+(r)$}{
      \If{$\tau(t) = \star$}{
        replace $t$ with $s'$ in $N^+(r)$\;
        \Return{$(V \cup V', s, N^+ \cup N', \tau \cup \tau')$}\;
      }
      $G'' \gets \mergeFcgs{$G$, $G'$, $t$}$\;
      \lIf{$G'' \ne {\normalfont \texttt{null}}$}{\Return{$G''$}}
    }
    \Return{\normalfont\texttt{null}}\;
  }
\end{algorithm}

The search algorithm is described as
\cref{alg:search,alg:applyallrules,alg:apply,alg:helpers}, with the main
procedure in \cref{alg:search}. Since for most formulas we are able to find
several FCGs (of various complexities), the algorithm maintains set $S$ of found
solutions. We begin by applying all suitable greedy rules on \cref{line:greedy}.
If greedy rules are enough to find a full FCG, the algorithm stops. Otherwise,
\cref{line:q1,line:q2} set up a queue for breadth-first search. The algorithm
continues to take a state from the queue, call \texttt{applyAllRules} on it, and
place the resulting states back on the queue while filtering out full FCGs and
adding them to $S$ instead. Since GDR can be applied to almost all formulas, the
search is infinite. In our implementation, we stop searching when
\begin{itemize}
  \item the desired number of solutions is found,
  \item the search tree reaches a certain height,
  \item or the algorithm times out.
\end{itemize}

Function \texttt{applyAllRules} (see \cref{alg:applyallrules}) takes a state and
generates a sequence of new states created by applying one non-greedy rule
followed by all applicable greedy rules. We assume that the input state contains
at least one formula (otherwise it would be a complete solution) and that all
applicable greedy rules have already been applied. The algorithm iterates over
all non-greedy rules and all pairs of FCGs and lists of formulas generated by
these rules when applied to $\phi$. If the FCG is \texttt{null}, this means that
$|L''| = 1$, and $L''$ contains a modified version of $\phi$---in this case, we
rerun \texttt{applyAllRules} on the same state but with the updated formula.
Otherwise, we update the cache, call another function to apply greedy rules, and
merge $(G'', L'')$ with a copy of the input state. In doing so, $\phi$ is
replaced by $L''$, preserving the implicit bijection between the ordering of the
list and the structure of $\star$'s in the FCG\@.

\Cref{alg:apply} defines two functions that work together to handle the
application of greedy rules. Function \texttt{applyGreedyRules} takes a formula
and returns the maximal chip that can be constructed by the application of
greedy rules (and updates the cache whenever the application of a rule results
in a new node). The implementation of this function is simplified by three
assumptions about greedy rules. First, we assume that greedy rules can be
applied in any order. Second, we assume that the set of chips returned by a
greedy rule has at most one element. Third, if a rule returns an empty FCG,
i.e., $G = \star$, then $L$ has exactly one formula, i.e., the rule simply
transforms the input formula. In such a case, we continue the application of
greedy rules to the new formula. Otherwise, \cref{line:callgreedy} updates the
cache and calls the second function in \cref{alg:apply},
\texttt{applyGreedyRulesToFormulas}, on the new chip $(G, L)$ that has $|L|$ new
formulas that could benefit from greedy rules. Finally, if none of the greedy
rules are applicable, \texttt{applyGreedyRules} returns the same formula $\phi$
formatted as a state. Function \texttt{applyGreedyRulesToFormulas} takes a state
and updates it by running \texttt{applyGreedyRules} on all formulas in $L$ and
incorporating the resulting chips as direct successors of the source node $s$.
Hence, we assume that the input FCG (which comes directly from applying a single
greedy rule) has just one non-$\star$ node, $s$, and $N^+(s)$ contains exactly
$|L|$ $\star$'s.

% If the chip is complete, return the state as-is.
% Otherwise, we apply greedy rules to the formulas in $L$, incorporating each
% resulting state into the input state.
% In particular, we replace the formulas in $L$ with the formulas returned by
% greedy rules. Furthermore, each FCG returned by \texttt{applyGreedyRules} is
% connected to the input FCG by drawing an edge from $s$ to $s'$ and copying over
% all nodes, edges, and labels.

Finally, \cref{alg:helpers} describes two helper functions: \texttt{updCache}
for updating the cache and \texttt{mergeFcgs} for merging two FCGs. Note that
$\Reff$ nodes are not placed in the cache because the relation identified by the
compilation rule for $\Reff$ (see \cref{alg:trycache}) is transitive. In other
words, instead of calling a function $f(\mathbf{n}) \coloneqq g(\mathbf{m})$
(where $\mathbf{n}$ and $\mathbf{m}$ are integer parameter vectors, and
$\mathbf{m}$ is constructed from $\mathbf{n}$), we can always directly call
function $g$. Function \texttt{mergeFcgs} finds a $\star$ in $G$ and replaces it
with $G'$. Note that the order in which the nodes of $G$ are visited must be the
pre-order traversal of the underlying tree of $G$. Hence, the algorithm skips
$\Reff$ nodes and, for each directed edge, considers the source before
considering the target. Parameter $r$, initially set to the source of $G$, keeps
track of the root of the subtree that needs to be explored. Recursive calls
return \texttt{null} if there are no $\star$'s in the subtree rooted at $r$.
However, we only call \texttt{mergeFcgs} with $G$'s that have at least one
$\star$, so the return value of the initial call to the function is never
\texttt{null}.

\subsection{How to Interpret an FCG}

When \textsc{ForcLift} \citep{DBLP:conf/ijcai/BroeckTMDR11} compiles a WFOMC
instance into a circuit, each gate type encodes an arithmetic operation on its
inputs and parameters. These operations are then immediately performed while
traversing the circuit and using domain sizes and weights as the initial inputs.
With \textsc{Crane}, the evaluation of an FCG is a collection of functions. Each
function has (some) domain sizes as parameters and may contain recursive calls
to other functions, including itself. While there may be any number of
subsidiary functions, there is always one main function that can be called with
the sizes of the domains of the input formula as arguments. Henceforth, this
function is always called $f$.

\todo[inline,caption={}]{
  \begin{itemize}
    \item Evaluation vs interpretation: fix terminology.
    \item Refer to previous work for the evaluations/interpretations of other
          node types and for the definition of groundings. Note that my clause
          is their c-expression or something like that.
    \item Finish writing this paragraph. Here we provide an informal
          description... Formalising this into an algorithm is left for future
          work. We shall see a more detailed example of evaluation in
          \cref{sec:results}.
          \begin{itemize}
            \item The source node defines $f$.
            \item $\Reff$ evaluates to a function call. The target of the
                  outgoing edge then must introduce a new function, the
                  parameters of which are the sizes of all domains reachable
                  from it.
            \item $\GDR$ node does not have a particular evaluation. However, it
                  is usually the direct successor of a $\Reff$ node.
            \item $\CR$ nodes have no particular evaluation.
            \item Obviously, $\star$ has no evaluation because incomplete FCGs
                  are not meant to be evaluated.
          \end{itemize}
    \item Double check that I didn't mix up the $m$s and $n$s, i.e., be
          consistent with the next section even if both variations are correct.
  \end{itemize}
}

\todo[inline]{Update the example below to the new version of the figure. And
  simplify the final expression. And explain the importance of simplification.}

\begin{example}\label{example:evaluation}
  Let us use the FCG from \cref{fig:examplefcg} as an example. The input formula
  has two domains: $a$ and $b$. Thus, the interpretation of the FCG is a
  function
  $f\colon \mathbb{N}_{0} \times \mathbb{N}_{0} \to \mathbb{R}_{\ge 0}$. Let
  $m \coloneqq |a|$, and $n \coloneqq |b|$. The node labelled
  $\bigvee_{b^{\top} \subseteq b}$ tells us that
  $f(m, n) = \sum_{l = 0}^{n} \binom{n}{l} \square$, where $\square$ is the
  interpretation of the remaining subgraph, and $l$ iterates over all possible
  sizes of $b^{\top}$. Nodes labelled $\land$ correspond to multiplication.
  Therefore, we now know that
  $f(m, n) = \sum_{l = 0}^{n} \binom{n}{l} \clubsuit \times \spadesuit$, where
  $\clubsuit$ is the interpretation of the direct successor with label 1, and
  $\spadesuit$ is the interpretation of the remaining subgraph. Since our focus
  is on \emph{unweighted} model counting, all unit nodes (i.e., nodes with label
  1) are interpreted simply as one. Hence, we can fast-forward our construction
  of $f$ to
  $f(m, n) = \sum_{l = 0}^{n} \binom{n}{l} 1 \times 1 \times 1 \times \diamondsuit \times \heartsuit$,
  where $\diamondsuit$ is the interpretation of the contradiction (i.e., $\bot$)
  node, and $\heartsuit$ is the interpretation of the $\Reff$ node.

  A contradiction node with clause $c$ as a parameter is interpreted as one if
  the clause has groundings and zero otherwise. In this case,
  $c = (\emptyset, \{\, (X, Y) \,\}, \{\, X \mapsto b^\top, Y \mapsto b^\top \,\})$,
  which can be read as $\forall X, Y \in b^{\top}\text{,
  }X \ne Y \implies \bot$, i.e., $\forall X, Y \in b^{\top}\text{, }X = Y$. This
  latter sentence is true if and only if $|b^{\top}| < 2$. Therefore, we
  can use the Iverson bracket notation to write $\diamondsuit = [l < 2]$.

  It remains to interpret the $\Reff$ node. Parameter
  $\{\, a \mapsto a', b \mapsto b^\bot \,\}$ tells us that the evaluation of the
  $\Reff$ node should be the same as that of the source node, but with domains
  $a$ and $b$ replaced with $a'$ and $b^{\bot}$, respectively. Domain $a'$ was
  created by a constraint removal rule applied on $a$, so $|a'| = m - 1$. Now
  $b^{\bot} = b \setminus b^{\top}$, and $|b^{\top}| = l$, so
  $|b^{\bot}| = n - l$. Thus, the evaluation of the $\Reff$ node is a recursive
  call to $f(m - 1, n - l)$. Therefore,
  \begin{equation}\label{eq:solution}
    f(m, n) = \sum_{l = 0}^{n} \binom{n}{l} [l < 2] f(m-1, n-l).
  \end{equation}
  In order to use this recursive function to compute the model count of the
  input formula for any domain sizes, one just needs to find the base cases
  $f(0, n)$ and $f(m, 0)$ for all $m, n \in \mathbb{N}_{0}$.
\end{example}

\section{Empirical Results}\label{sec:results} % Newly Domain-Liftable Formulas

In this section, we compare \textsc{Crane} and \textsc{ForcLift}
\citep{DBLP:conf/ijcai/BroeckTMDR11} on their ability to count various kinds of
functions. (Other WFOMC algorithms such as \textsc{L2C}
\citep{DBLP:conf/kr/KazemiP16} and probabilistic theorem proving
\citep{DBLP:journals/cacm/GogateD16} are unable to solve any of the instances
that \textsc{ForcLift} fails on.) We begin with a description of how such
functions can be described using FOL\@. \textsc{ForcLift} then translates these
descriptions to formulas as we defined them back in ??.

% Describe what kind of instances we're investigating
Let $p$ be a predicate of arity two s.t.\ its first term is associated with
domain $a$, and the second term is associated with domain $b$ (i.e., $p$
represents a relation between sets $a$ and $b$). Then, to restrict all relations
representable by $p$ to just functions from $a$ to $b$, in FOL one
might write
\begin{gather}
  \forall X \in a. \forall Y \in b. \forall Z \in b. p(X, Y) \land p(X, Z) \implies Y = Z\nonumber \\
  \forall X \in a. \exists Y \in b. p(X, Y). \label{eq:def2}
\end{gather}
The former says that one element of $a$ can map to at \emph{most} one element of
$b$, and the latter says that each element of $a$ must map to at \emph{least}
one element of $b$. One might add
\[
  \forall W \in a. \forall X \in a. \forall Y \in b. p(W, Y) \land p(X, Y) \implies W = X
\]
to restrict $p$ to injections or
\[
  \forall Y \in b. \exists X \in a. p(X, Y)
\]
to ensure surjectivity or remove \cref{eq:def2} to consider partial functions.
Lastly, one can replace all occurrences of $b$ with $a$ so as to model
endofunctions (i.e., functions with the same domain and codomain) instead. In
our experiments, we consider all sixteen combinations of these properties, i.e.,
injectivity, surjectivity, partiality, and endo-.

% the process: both for running algorithms and for determining complexities
We run \textsc{Crane} until the search tree reaches height 6 and examine the
first (i.e., shallowest) five solutions.\footnote{Hence, it is possible that
  better solutions could be found with more search.} If successful, both
algorithms generate a circuit or an FCG, which is then manually converted into
definitions of functions. When assessing the complexity of each such definition,
we assume that:
\begin{itemize}
  \item computing $\binom{n}{k}$ takes $\Theta(nk)$ time,
  \item and techniques such as dynamic programming or memoization are used to
        avoid recomputing the same binomial coefficient or function call
        multiple times.
\end{itemize}

\begin{table}[t]
  \centering
  \begin{tabular}{cccccc}
    \toprule
    \multicolumn{3}{c}{Function Class} & \multicolumn{3}{c}{Asymptotic Complexity of Counting} \\
    Partial & Endo- & Class & Best Known & With \textsc{ForcLift} & With \textsc{Crane} \\
    \midrule
    \rowcolor{gray!10}\cmark/\xmark & \cmark/\xmark & Functions & $\log m$ & $m$ & $m$ \\
    \xmark & \xmark & \multirow{4}{*}{Surjections} & $n \log m$ & $m^{3}+n^{3}$ & $m^{3}+n^{3}$ \\
    \xmark & \cmark & & $m \log m$ & $m^{3}$ & $m^{3}$ \\
    \cmark & \xmark & & \multicolumn{3}{c}{Same as injections from $b$ to $a$} \\
    \cmark & \cmark & & \multicolumn{3}{c}{Same as endo-injections} \\
    \rowcolor{gray!10}\xmark & \xmark & & $m$ & - & $mn$ \\
    \rowcolor{gray!10}\xmark & \cmark & & $m$ & - & $m^3$ \\
    \rowcolor{gray!10}\cmark & \xmark & & $\min\{\, m, n \,\}^2$ & - & $mn$ \\
    \rowcolor{gray!10}\cmark & \cmark & \multirow{-4}{*}{Injections} & $m^2$ & - & - \\
    \xmark & \xmark & \multirow{3}{*}{Bijections} & $m$ & - & $m$ \\
    \xmark & \cmark & & \multicolumn{3}{c}{\multirow{2}{*}{Same as (partial) (endo-)injections}} \\
    \cmark & \cmark/\xmark & & \multicolumn{3}{c}{} \\
    \bottomrule
  \end{tabular}
  \caption{The worst-case complexity of counting various types of functions.
    Here, $m$ is the size of domain $a$, and $n$ is the size of domain $b$. All
    asymptotic complexities are in $\Theta(\cdot)$. A hyphen means that no
    solution was found.}\label{tbl:results}
\end{table}

The results are summarised in \cref{tbl:results}. The best-known asymptotic
complexity for computing total surjections is by \citet{30049}. All other
best-known complexity results are inferred from the formulas and programs on the
on-line encyclopedia of integer sequences \citep{oeis}. On instances that could
already be solved by \textsc{ForcLift}, the two algorithms perform equally well.
However, \textsc{Crane} is also able to solve all but one instances that
\textsc{ForcLift} fails on in at most cubic time.

Let us examine the case of counting (total, non-endomorphic) injections more
closely. The FCG from \cref{fig:examplefcg,example:evaluation} counts injections
and is responsible for the first $mn$ entry in the table.\footnote{A very
  similar solution works for partial injections as well.} For a complete
solution, \cref{eq:solution} must be combined with the following base cases:
$f(0, 0) = 1$, and $f(m, 0) = 0$ for all $m > 0$. Finally, note that $f(m, n)$
can be evaluated in $\Theta(mn)$ time (for any $m, n \in \mathbb{N}_{0}$) by a
dynamic programming algorithm that computes $f(i, j)$ for all $i = 0, \dots, m$
and $j = 0, \dots, n$.

\todo[inline]{Both in the caption of the figure and here, mention that it's a
  bit of a simplification that discards nodes whose only arithmetic effect is
  multiplication by one. Some of these nodes play an important role in WFOMC
  while others are dispensable nodes that result from the interaction between
  compilation rules and the way in which \textsc{ForcLift} handles existential
  quantifiers.}

\todo[inline]{Have a concluding paragraph that describes the importance of these
  results. For example, that injectivity is now liftable and that my
  experimental results are far from conclusive in two ways: further search could
  reveal other solutions (explicitly describe the potential solution for the
  unsolved case that uses GDR in an unusual way), and who knows what kind of
  instances might also have become liftable yet remain undiscovered.}

  % \item The complexities assume that arithmetic operations on number such as
  %       addition and multiplication take constant time.
  % \item In some cases (e.g., when counting injections from... to...), we might
  %       immediately recognize that the answer must be zero. Whether such cases
  %       can be handled efficiently or not by our approach depends on the
  %       definitions of functions and the order of evaluation. (We still get the
  %       right answer, though.)
  % \item All complexity results are for the worst case. In particular, optimal
  %       best-case complexity is usually $\Theta(1)$ (see above for why).

% Other results
% \begin{itemize}
%   \item 1d bijections and 1d injections (note that it's the same problem). Depth
%         3 solution:
%         \begin{align*}
%           f(n) &= \sum_{m=0}^n \binom{n}{m} (-1)^{n-m}g(n, m) \\
%           g(n, m) &= \sum_{l=0}^n \binom{n}{l}[l < 2]g(n-l, m-1) \\
%                &= g(n, m - 1) + ng(n - 1, m - 1),
%         \end{align*}
%         which works with base case $g(n, 0) = 1$.
%   \item 1d partial injections. 2 solutions at depth 6, but they're too
%         complicated to check by hand. A contradiction with $X \ne x$ constraints
%         makes things complicated.
%   \item 2d bijections. Depth 3:
%         \begin{align*}
%           f(m, n) &= \sum_{l=0}^m \binom{m}{l} [l < 2] (1 - [l < 1])f(m-l, n-1) \\
%                   &= mf(m-1, n-1),
%         \end{align*}
%         which works with base cases $f(0, 0) = 1$, $f(0, n) = 0$, $f(m, 0) = 0$.
%   \item 2d partial injections, depth 2. Exactly the same circuit as for injections but with base case $f(m, 0) = 1$.
% \end{itemize}

\section{Discussion}

\begin{itemize}
  \item Functions, surjections, and their partial counterparts are/were already
        liftable. It seems like lifting injectivity (which is a fairly general
        property) is the main accomplishment. (But this is just the one I
        noticed. There may be many others as well.)
  \item My examples for 1 domain are expressible using 2 variables and counting
        quantifiers, so they're already known to be liftable.
  \item Recursion is guaranteed to terminate if at least one domain shrinks by
        at least one. But note that allowing recursive calls with the same
        domain sizes (e.g., $f(n) = f(n) + \dots$) could be useful because these
        problematic terms might cancel out.
  \item Explain the importance of comparing domain sizes to 2. FCGs that compare
        the size of a domain to an integer can be constructed automatically
        using compilation rules, although $n$ is upper bounded by the maximum
        number of variables in any clause of the input formula since there is no
        rule that would introduce new variables.
  \item Mention that it only takes a few seconds to find these solutions. Going
        beyond depth 6 (or sometimes even completing depth 6) is computationally
        infeasible with the current implementation, but depth at most 5 can be
        searched within at most a few seconds.
  \item Note that in some cases different descriptions of the same problem lead
        to different solutions (with different complexities).
  \item Explain why these solutions are always computable in polynomial time.
\end{itemize}

\section{Conclusions and Future Work}

\paragraph{Future work.}
\begin{itemize}
  \item Transform FCGs to definitions of (possibly recursive) functions on
        integers. Use a computer algebra system to simplify them.
  \item Design an algorithm to infer the necessary base cases. (Note that there
        can be an infinite amount of them when functions have more than one
        parameter.)
  \item Observation: -1 (and powers thereof) appear in every solution to a
        formula if and only if the formula has existential quantification.
        That's not very smart!
\end{itemize}

% By classifying unit propagation (but we don't mention unit propagation by
% name) as a greedy rule, these powers are pushed to the outer layers of the
% solution (i.e., `early' in the FCG). It's likely that removing this
% restriction would enable the algorithm to find asymptotically optimal
% solutions.
