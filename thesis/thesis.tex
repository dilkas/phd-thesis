%%%%
%% Load the class. Put any options that you want here (see the documentation
%% for the list of options). The following are samples for each type of
%% thesis:
%%
%% Note: you can also specify any of the following options:
%%  logo: put a University of Edinburgh logo onto the title page
%%  frontabs: put the abstract onto the title page
%%  deptreport: produce a title page that fits into a Computer Science
%%      departmental cover [not sure if this actually works]
%%  singlespacing, fullspacing, doublespacing: choose line spacing
%%  oneside, twoside: specify a one-sided or two-sided thesis
%%  10pt, 11pt, 12pt: choose a font size
%%  centrechapter, leftchapter, rightchapter: alignment of chapter headings
%%  sansheadings, normalheadings: headings and captions in sans-serif
%%      (default) or in the same font as the rest of the thesis
%%  [no]listsintoc: put list of figures/tables in table of contents (default:
%%      not)
%%  romanprepages, plainprepages: number the preliminary pages with Roman
%%      numerals (default) or consecutively with the rest of the thesis
%%  parskip: don't indent paragraphs, put a blank line between instead
%%  abbrevs: define a list of useful abbreviations (see documentation)
%%  draft: produce a single-spaced, double-sided thesis with narrow margins
%%
%% For a PhD thesis -- you must also specify a research institute:
\documentclass[phd,aiai,twoside,fullspacing,logo]{infthesis}

\usepackage{hyperref}
\usepackage[table]{xcolor}
\usepackage[ruled,vlined,linesnumbered,algochapter]{algorithm2e}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{mathrsfs}
\usepackage[nounderscore]{syntax}
\usepackage{blkarray}
\usepackage{siunitx}
\usepackage[inline,shortlabels]{enumitem}
\usepackage{capt-of}
%\usepackage[caption=false]{subfig}
\usepackage{booktabs}
\usepackage[misc,geometry]{ifsym}
\usepackage{breakcites}
\usepackage[british]{babel}
\usepackage{complexity}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{subcaption}
\usepackage{sectsty}
\usepackage{stmaryrd}
\usepackage{rotating}
\usepackage{pifont}
\usepackage{listings}
\usepackage{microtype}
\usepackage{csquotes}
\usepackage[capitalise,noabbrev]{cleveref}
%\usepackage{MnSymbol}
\usepackage[color=lightgray]{todonotes} % TODO: temp

\usepackage{natbib}
\usepackage{bibentry}
%% \usepackage[backend=biber]{biblatex}
%% \addbibresource{thesis}
%\bibliographystyle{apalike}
\bibliographystyle{abbrvnat}

\allsectionsfont{\raggedright}

\usetikzlibrary{arrows}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{calc}
\usetikzlibrary{cd}
\usetikzlibrary{fit}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes}
\usetikzlibrary{trees}

\captionsetup[subfigure]{width=\linewidth}

\newtheorem{assumption}{Assumption}
\newtheorem{conjecture}{Conjecture}
\newtheorem{constraint}{Constraint}
\newtheorem{fact}{Fact}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{experiment}{Experiment}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\numberwithin{assumption}{chapter}
\numberwithin{conjecture}{chapter}
\numberwithin{constraint}{chapter}
\numberwithin{fact}{chapter}
\numberwithin{proposition}{chapter}
\numberwithin{theorem}{chapter}
\numberwithin{lemma}{chapter}
\numberwithin{definition}{chapter}
\numberwithin{example}{chapter}
\numberwithin{experiment}{chapter}

\renewcommand\fbox{\fcolorbox{red}{white}}
\newcommand{\hilight}[1]{\setlength{\fboxsep}{1pt}\colorbox{lightgray}{#1}}
\newcommand{\hlitem}{\stepcounter{enumi}\item[\hilight{\theenumi}]}

\newcommand{\logical}[1]{{\normalfont \texttt{#1}}}
\newcommand{\variable}[1]{\texttt{\textup{#1}}}
\newcommand{\arrayd}[3]{\variable{{#1}[}{#2}\variable{]} \in {#3}}
% 1=name, 2=length, 3=type
\newcommand{\arrayt}[3]{\variable{{#3}} : \variable{{#1}[}{#2}\variable{]}}

\newcommand{\predicates}{\mathcal{P}}
\newcommand{\variables}{\mathcal{V}}
\newcommand{\constants}{\mathcal{C}}
\newcommand{\tokens}{\mathcal{T}}
\newcommand{\arities}{\mathcal{A}}
\newcommand{\maxArity}{\mathcal{M}_{\mathcal{A}}}
\newcommand{\maxNumNodes}{\mathcal{M}_{\mathcal{N}}}
\newcommand{\maxNumClauses}{\mathcal{M}_{\mathcal{C}}}

\newcommand{\FOtwo}{$\mathsf{FO}^{2}$}
\newcommand{\FOthree}{$\mathsf{FO}^{3}$}
\newcommand{\SFO}{$\mathsf{S}^{2}\mathsf{FO}^{2}$}
\newcommand{\SRU}{$\mathsf{S}^{2}\mathsf{RU}$}
\newcommand{\Uone}{$\mathsf{U}_{1}$}
\newcommand{\Ctwo}{$\mathsf{C}^{2}$}

\DeclareMathOperator{\alldifferent}{\mathtt{alldifferent}}
\DeclareMathOperator{\Bernoulli}{Bernoulli}
\DeclareMathOperator{\Determined}{\Delta}
\DeclareMathOperator{\Undetermined}{\Upsilon}
\DeclareMathOperator{\AlmostDetermined}{\Gamma}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\CR}{\textsc{CR}}
\DeclareMathOperator{\GDR}{\textsc{GDR}}
\DeclareMathOperator{\IE}{\textsc{IE}}
\DeclareMathOperator{\Reff}{\textsc{Ref}}
\DeclareMathOperator{\wwp}{w}
\DeclareMathOperator{\wwn}{\overline{w}}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Imm}{Im}
\DeclareMathOperator{\Doms}{Doms}
\DeclareMathOperator{\size}{\sigma}
\DeclareMathOperator{\Vars}{Vars}
\DeclareMathOperator{\WMC}{WMC}
\DeclareMathOperator{\gr}{gr}

\DeclareMathOperator{\leftlsquigarrow}{\text{\reflectbox{$\rightsquigarrow$}}}

\Crefname{algocf}{Algorithm}{Algorithms}
\Crefname{constraint}{Constraint}{Constraints}
\Crefname{experiment}{Experiment}{Experiments}
\crefname{line}{line}{lines}

\sisetup{range-phrase=--}
\sisetup{range-units=single}
\newcommand{\crefrangeconjunction}{--}

\makeatletter
\newcommand{\nosemic}{\renewcommand{\@endalgocfline}{\relax}}% Drop semi-colon ;
\newcommand{\dosemic}{\renewcommand{\@endalgocfline}{\algocf@endline}}% Reinstate semi-colon ;
\newcommand{\pushline}{\Indp}% Indent
\newcommand{\popline}{\Indm\dosemic}% Undent
\makeatother

\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
               {\renewcommand\theinnercustomthm{#1}\innercustomthm}
               {\endinnercustomthm}
               \newtheorem{innercustomlemma}{Lemma}
               \newenvironment{customlemma}[1]
                              {\renewcommand\theinnercustomlemma{#1}\innercustomlemma}
                              {\endinnercustomlemma}

\makeatletter
\newcommand\incircbin
    {%
      \mathpalette\@incircbin
    }
    \newcommand\@incircbin[2]
                          {%
                            \mathbin%
                                {%
                                  \ooalign{\hidewidth$#1#2$\hidewidth\crcr$#1\bigcirc$}%
                                }%
                          }
                          \newcommand{\oland}{\incircbin{\land}}
                          \newcommand{\olor}{\incircbin{\lor}}
                          \newcommand{\Contradiction}{\incircbin{\bot}}
                          \newcommand{\Tautology}{\incircbin{\top}}
                          \newcommand{\Smoothing}{\incircbin{}}
                          \newcommand{\Unit}{\incircbin{1}}
                          \makeatother

\newcommand\pfun{\mathrel{\ooalign{\hfil$\mapstochar\mkern5mu$\hfil\cr$\to$\cr}}}
\newcommand\mdoubleplus{\mathbin{+\mkern-10mu+}}
\newcommand*{\twoheadrightarrowtail}{\mathrel{\rightarrowtail\kern-1.9ex\twoheadrightarrow}}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\crefname{enumi}{Condition}{Conditions}
\crefname{enumii}{Condition}{Conditions}

\lstset{
  basicstyle=\ttfamily,
  keepspaces=true
}

\definecolor{color1}{HTML}{1b9e77}
\definecolor{color2}{HTML}{d95f02}
\definecolor{color3}{HTML}{7570b3}

\definecolor{wmc1}{HTML}{1b9e77}
\definecolor{wmc2}{HTML}{d95f02}
\definecolor{wfomc}{HTML}{7570b3}
\definecolor{randomlps}{HTML}{e7298a}
\definecolor{comparison}{HTML}{66a61e}

\title{Generalising Weighted Model Counting}
\author{Paulius Dilkas}

\abstract{% 1-2 (usually 1) pages, <= 300 words (soft constraint)
  % 1. problem: description of the problem
  % 2. context: (same paragraph) mention the applicability of the studied problems (i.e., many areas of impact within and beyond CS)
  % 3. solution: contributions
  % 4. validation: evaluation (e.g., where the instances come from) (maybe: new possibilities opened up by my work)

  Given a formula in propositional or first-order logic and some non-negative weights, weighted model counting (WMC) is a function problem that asks to compute the sum of the weights of the models of the formula. Originally used as a flexible way of performing probabilistic inference on graphical models, WMC has found many applications across artificial intelligence (AI), machine learning, and other domains. Areas of AI that rely on WMC include explainable AI, neuro-symbolic AI, probabilistic programming, and statistical relational AI. WMC also has applications in bioinformatics, data mining, natural language processing, prognostics, and robotics.

  In this work, we are interested in revisiting the foundations of WMC and considering generalisations of some of the key definitions in the interest of conceptual clarity and practical efficiency. We begin by developing a measure-theoretic perspective on WMC, which suggests a new and more general way of defining the weights of an instance. This new representation can be as succinct as standard WMC but can also expand as needed to represent less-structured probability distributions. We demonstrate the performance benefits of the new format by developing a novel WMC encoding for Bayesian networks. We then show how existing WMC encodings for Bayesian networks can be transformed into this more general format and what conditions ensure that the transformation is correct (i.e., preserves the answer). Combining the strengths of the more flexible representation with the tricks used in existing encodings yields further efficiency improvements in Bayesian network probabilistic inference.

  Next, we turn our attention to the first-order setting. Here, we argue that the capabilities of practical model counting algorithms are severely limited by their inability to perform arbitrary recursive computations. To enable arbitrary recursion, we relax the restrictions that typically accompany domain recursion and generalise circuits (used to express a solution to a model counting problem) to graphs that are allowed to have cycles. These improvements enable us to find efficient solutions to counting fundamental structures such as injections and bijections that were previously unsolvable by any available algorithm.

  The second strand of this work is concerned with synthetic data generation. Testing algorithms across a wide range of problem instances is crucial to ensure the validity of any claim about one algorithm's superiority over another. However, benchmarks are often limited and fail to reveal differences among the algorithms. First, we show how random instances of probabilistic logic programs (that typically use WMC algorithms for inference) can be generated using constraint programming. We also introduce a new constraint to control the independence structure of the underlying probability distribution and provide a combinatorial argument for the correctness of the constraint model. This model allows us to, for the first time, experimentally investigate inference algorithms on more than just a handful of instances. Second, we introduce a random model for WMC instances with a parameter that influences primal treewidth---the parameter most commonly used to characterise the difficulty of an instance. We show that the easy-hard-easy pattern with respect to clause density is different for algorithms based on dynamic programming and algebraic decision diagrams than for all other solvers. We also demonstrate that all WMC algorithms scale exponentially with respect to primal treewidth, although at differing rates.
}

\begin{document}
\nobibliography*

\begin{preliminary}

\maketitle

\begin{acknowledgements}
  The first author was supported by the EPSRC Centre for Doctoral Training in Robotics and Autonomous Systems, funded by the UK Engineering and Physical Sciences Research Council (grant EP/L016834/1). This work has made use of the resources provided by the Edinburgh Compute and Data Facility (ECDF) (\url{http://www.ecdf.ed.ac.uk/}).

  We thank the anonymous reviewers for their helpful comments.
\end{acknowledgements}

\standarddeclaration

%% Finally, a dedication (this is optional -- uncomment the following line if
%% you want one).
% \dedication{To my mummy.}

\tableofcontents

%% If you want a list of figures or tables, uncomment the appropriate line(s)
% \listoffigures
% \listoftables

\end{preliminary}

% TODO:
% * !!! incorporate new feedback in ALL sections
% * !!! write lay summary (0.5-1 page at most, must!!!) (there is a bookmarked PDF with more info). Make sure it fits into the form. Position it right after the abstract.
% * Alignment issues.
% * Consider removing all the subfigure/minipage/subfig stuff.
% * references: capitalisation/grouping of names and titles, useless URLs, backslashes (DOIs, URLs)
% ** 'santos costa' may be one of those surnames that require special handling
% * Make sure all table captions are above (?) the table. Full stop at the end of a one-sentence caption?
% * Add additional information from phd_notes and previous versions of some of the papers.
% * Shorten the names of chapters
% * Remove the use of the words: theory, axiom
% * true/false are written in three different fonts in different chapters: texttt, textsc, and textsf
% * maybe: use sf for SAT, WMC, and a few other problems
% * double check what symbols I use for implication and equivalence
% * have theorems, examples, etc. numbering be chapter-specific (or even more densely)
% * consistent spacing around sets, use of coloneqq
% * maybe briefly introduce notation for positive and nonnegative integers, non-negative reals, etc.
% * capitalisation and font for predicates, variables, constants, etc.
% * textsc for algorithm names (e.g., problog)
% * fonts for names of problems (e.g., SAT, WMC) (no font)
% * replace \paragraph with \paragraph*
% * generating random logic programs:
% ** are the definitions of fact/rule the same as in the background section?
% ** replace the citation for stratification in the content chapter with the better one from the background chapter
% ** there's no need for hyphens in 'variable-ordering' and 'value-ordering'
% ** it's first fail (equivalent to dom) rather than fail-first
% * predicates and constants lowercase, variables uppercase
% * incorporate other paragraphs from my year 2 review (on the use of probabilities, WMC, applications of WMC, motivation for my work, probabilistic inference algorithms, knowledge compilation, WMC algorithms)
% * consider using listings for all Prolog and maybe ProbLog code (but then everything becomes sf instead of tt)
% * maybe write Markov network instead of Markov random field
% * all figures/tables/algorithms float to top?
% * primal graphs are also known as moral graphs and i-maps in the case of BNs
% * don't cite anything for Markov networks
% * what should I do with the unpublished part of the KR paper?
% * citations for definitions, theorems, etc. should be citet rather than citep
% * make the arrows (and tree sibling and node distances) all the same
% * check if some arXiv citations can be replaced by their published versions
% * notation for graphs: \mathcal{V}, \mathcal{E}, \mathcal{L}
% * introduction, background,recursion: merge table cells with the same info
% * replace all references to 'this paper' with 'this chapter' or 'this thesis'
% * preserve the section of paper1 in wmc-without-parameters that got deleted in paper2
% * merge Im and im commands
% * merge the two sets of colours
% * eliminate warnings (e.g., overflow, single-spacing)
% * rewrite the last paragraph of section 3.2 (how the UAI paper refers to the SAT paper)
% * background: wmc should be defined at the very beginning
% * 'line' should be lowercase
% * also list contributions at the beginning of each chapter
% * appendices after references? double check
% * intro/conclusion of each chapter should explain how the chapter fits into the bigger story
% * consider splitting the thesis into a section/part on generalisation and a part on random instances
% * random instances chapter
% ** motivation: unclear how algorithms differ
% ** link: the LP approach failed to distinguish the algorithms
% * refer to background sections in main chapters
% * introduction: define / write a bit about pseudo-Boolean functions (necessary for the next chapter). Maybe make a connection with pseudo-Boolean constraints.
% * replace citations of my own papers with references to chapters
% * where do I define 'lifted'?
% * past tense in conclusion: avoid?
% * comparison chapter: do I want to include anything from the 'full' version of the paper?
% * the tikzpicture in the recursion chapter could also be redrawn to be a tree
% * remove unnecessary math operators and packages
% * neuro or neural?
% * in algorithms, write forall if selecting more than one variable
% * Chapter 5 (and maybe elsewhere): tikzcd diagrams should not be referred to as equations
% * recursion chapter: double check the results in the table
% * write acknowledgements
% * make sure to use \text{, } and \text{. } for FOL
% * integrate the proofs from the appendix to the main paper

\include{chapters/introduction} % 5-14 pages (9 on average)
\include{chapters/background} % 11-45 pages (27 on average)
\include{chapters/wmc_for_bns/chapter}
\include{chapters/wmc_without_parameters/chapter}
\include{chapters/recursion}
\include{chapters/random_lps/chapter}
\include{chapters/comparison/chapter}
\include{chapters/conclusion} % 5-28 pages (mean: 8, median: 5)

\appendix
\include{chapters/appendix.tex}
\include{chapters/appendix2.tex}

%% If you want the bibliography single-spaced (which is allowed), uncomment
%% the next line.
\singlespace

\bibliography{thesis}
%\printbibliography

\end{document}
